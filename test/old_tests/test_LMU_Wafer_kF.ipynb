{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures_v1 import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, roc_auc_score\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training/Testing/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Instances: 716\n",
      "x_all: (6448, 152, 1) - y_all: (6448,)\n",
      "x_valid: (716, 152, 1) - y_valid: (716,)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Wafer\"\n",
    "model_name = \"LMU\"\n",
    "\n",
    "x_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_train.npz')))\n",
    "x_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_test.npz')))\n",
    "\n",
    "x_train = np.reshape(x_train_load['arr_0'], [x_train_load['arr_0'].shape[0], x_train_load['arr_0'].shape[1], 1])\n",
    "x_test = np.reshape(x_test_load['arr_0'], [x_test_load['arr_0'].shape[0], x_test_load['arr_0'].shape[1], 1])\n",
    "\n",
    "x_all = np.concatenate((x_train, x_test), axis = 0)\n",
    "\n",
    "n_instances = x_all.shape[0]\n",
    "\n",
    "y_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_train.npz')))\n",
    "y_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_test.npz')))\n",
    "\n",
    "y_train = y_train_load['arr_0']\n",
    "y_test = y_test_load['arr_0']\n",
    "\n",
    "y_all = np.concatenate((y_train, y_test), axis = 0)\n",
    "y_all = np.asarray(y_all, dtype = np.uint64)\n",
    "\n",
    "n_validation = int(0.1*n_instances)\n",
    "print(f\"Validation Instances: {n_validation}\")\n",
    "\n",
    "ind_validation = random.sample(range(0, n_instances), n_validation)\n",
    "x_valid = x_all[ind_validation, :, :]\n",
    "y_valid = y_all[ind_validation]\n",
    "\n",
    "x_all = np.delete(x_all, ind_validation, axis = 0)\n",
    "y_all = np.delete(y_all, ind_validation, axis = 0)\n",
    "\n",
    "print(f\"x_all: {x_all.shape} - y_all: {y_all.shape}\")\n",
    "print(f\"x_valid: {x_valid.shape} - y_valid: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_1 (RNN)                  (None, 212)               165689    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 426       \n",
      "=================================================================\n",
      "Total params: 166,115\n",
      "Trainable params: 100,323\n",
      "Non-trainable params: 65,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "length = x_all.shape[1]\n",
    "n_features = x_all.shape[-1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(RNN(LMUCell(units = 212,\n",
    "            order = 256,\n",
    "            theta = length,\n",
    "            input_encoders_initializer = Constant(1),\n",
    "            hidden_encoders_initializer = Constant(0),\n",
    "            memory_encoders_initializer = Constant(0),\n",
    "            input_kernel_initializer = Constant(0),\n",
    "            hidden_kernel_initializer = Constant(0),\n",
    "            memory_kernel_initializer = \"glorot_normal\"), \n",
    "              input_shape = (length, n_features), return_sequences = False))\n",
    "model.add(Dense(to_categorical(y_train).shape[-1], activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "\n",
      "Train on 5158 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3276 - acc: 0.8553\n",
      "Epoch 00001: val_loss improved from inf to 0.25544, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_1.hdf5\n",
      "5158/5158 [==============================] - 3s 660us/sample - loss: 0.3272 - acc: 0.8556 - val_loss: 0.2554 - val_acc: 0.8994\n",
      "Epoch 2/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9282\n",
      "Epoch 00002: val_loss improved from 0.25544 to 0.19098, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_1.hdf5\n",
      "5158/5158 [==============================] - 3s 591us/sample - loss: 0.1867 - acc: 0.9287 - val_loss: 0.1910 - val_acc: 0.9316\n",
      "Epoch 3/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9594\n",
      "Epoch 00003: val_loss improved from 0.19098 to 0.13401, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_1.hdf5\n",
      "5158/5158 [==============================] - 3s 609us/sample - loss: 0.1153 - acc: 0.9595 - val_loss: 0.1340 - val_acc: 0.9595\n",
      "Epoch 4/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9845\n",
      "Epoch 00004: val_loss improved from 0.13401 to 0.07059, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_1.hdf5\n",
      "5158/5158 [==============================] - 3s 603us/sample - loss: 0.0502 - acc: 0.9843 - val_loss: 0.0706 - val_acc: 0.9735\n",
      "Epoch 5/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9839\n",
      "Epoch 00005: val_loss did not improve from 0.07059\n",
      "5158/5158 [==============================] - 3s 591us/sample - loss: 0.0446 - acc: 0.9839 - val_loss: 0.1349 - val_acc: 0.9651\n",
      "Epoch 6/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9771\n",
      "Epoch 00006: val_loss did not improve from 0.07059\n",
      "5158/5158 [==============================] - 3s 602us/sample - loss: 0.0641 - acc: 0.9769 - val_loss: 0.0868 - val_acc: 0.9707\n",
      "Epoch 7/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9896\n",
      "Epoch 00007: val_loss did not improve from 0.07059\n",
      "5158/5158 [==============================] - 3s 607us/sample - loss: 0.0332 - acc: 0.9895 - val_loss: 0.1013 - val_acc: 0.9693\n",
      "Epoch 8/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9888\n",
      "Epoch 00008: val_loss improved from 0.07059 to 0.04556, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_1.hdf5\n",
      "5158/5158 [==============================] - 3s 612us/sample - loss: 0.0320 - acc: 0.9888 - val_loss: 0.0456 - val_acc: 0.9860\n",
      "Epoch 9/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9924\n",
      "Epoch 00009: val_loss did not improve from 0.04556\n",
      "5158/5158 [==============================] - 3s 602us/sample - loss: 0.0244 - acc: 0.9924 - val_loss: 0.0715 - val_acc: 0.9818\n",
      "Epoch 10/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9925\n",
      "Epoch 00010: val_loss did not improve from 0.04556\n",
      "5158/5158 [==============================] - 3s 597us/sample - loss: 0.0247 - acc: 0.9926 - val_loss: 0.0472 - val_acc: 0.9860\n",
      "Epoch 11/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9953\n",
      "Epoch 00011: val_loss did not improve from 0.04556\n",
      "5158/5158 [==============================] - 3s 606us/sample - loss: 0.0137 - acc: 0.9952 - val_loss: 0.0547 - val_acc: 0.9846\n",
      "Epoch 12/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9888\n",
      "Epoch 00012: val_loss did not improve from 0.04556\n",
      "5158/5158 [==============================] - 3s 605us/sample - loss: 0.0300 - acc: 0.9889 - val_loss: 0.1801 - val_acc: 0.9693\n",
      "Epoch 13/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9914\n",
      "Epoch 00013: val_loss did not improve from 0.04556\n",
      "5158/5158 [==============================] - 3s 600us/sample - loss: 0.0233 - acc: 0.9913 - val_loss: 0.0596 - val_acc: 0.9832\n",
      "Epoch 14/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 00014: val_loss did not improve from 0.04556\n",
      "5158/5158 [==============================] - 3s 599us/sample - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0510 - val_acc: 0.9874\n",
      "Epoch 15/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 00015: val_loss did not improve from 0.04556\n",
      "5158/5158 [==============================] - 3s 606us/sample - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0483 - val_acc: 0.9902\n",
      "Epoch 16/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9880\n",
      "Epoch 00016: val_loss did not improve from 0.04556\n",
      "5158/5158 [==============================] - 3s 599us/sample - loss: 0.0343 - acc: 0.9878 - val_loss: 0.0936 - val_acc: 0.9735\n",
      "Epoch 17/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9935\n",
      "Epoch 00017: val_loss improved from 0.04556 to 0.04472, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_1.hdf5\n",
      "5158/5158 [==============================] - 3s 611us/sample - loss: 0.0206 - acc: 0.9936 - val_loss: 0.0447 - val_acc: 0.9860\n",
      "Epoch 18/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 00018: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 604us/sample - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0496 - val_acc: 0.9860\n",
      "Epoch 19/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9984\n",
      "Epoch 00019: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 619us/sample - loss: 0.0044 - acc: 0.9984 - val_loss: 0.0580 - val_acc: 0.9874\n",
      "Epoch 20/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9990\n",
      "Epoch 00020: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 619us/sample - loss: 0.0047 - acc: 0.9990 - val_loss: 0.0797 - val_acc: 0.9846\n",
      "Epoch 21/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9896\n",
      "Epoch 00021: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 607us/sample - loss: 0.0374 - acc: 0.9897 - val_loss: 0.0626 - val_acc: 0.9846\n",
      "Epoch 22/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9943\n",
      "Epoch 00022: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 604us/sample - loss: 0.0154 - acc: 0.9944 - val_loss: 0.0565 - val_acc: 0.9818\n",
      "Epoch 23/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9984\n",
      "Epoch 00023: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 610us/sample - loss: 0.0074 - acc: 0.9984 - val_loss: 0.1795 - val_acc: 0.9707\n",
      "Epoch 24/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9959\n",
      "Epoch 00024: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 610us/sample - loss: 0.0139 - acc: 0.9959 - val_loss: 0.1313 - val_acc: 0.9735\n",
      "Epoch 25/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9967\n",
      "Epoch 00025: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 605us/sample - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0620 - val_acc: 0.9860\n",
      "Epoch 26/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9990\n",
      "Epoch 00026: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 614us/sample - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0706 - val_acc: 0.9818\n",
      "Epoch 27/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9996\n",
      "Epoch 00027: val_loss did not improve from 0.04472\n",
      "5158/5158 [==============================] - 3s 604us/sample - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0627 - val_acc: 0.9846\n",
      "Training time: 84.89683175086975 s\n",
      "1290/1290 [==============================] - 1s 556us/sample - loss: 0.0333 - acc: 0.9915\n",
      "\n",
      "Fold: 2\n",
      "\n",
      "Train on 5158 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9922\n",
      "Epoch 00001: val_loss improved from inf to 0.05433, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_2.hdf5\n",
      "5158/5158 [==============================] - 3s 598us/sample - loss: 0.0266 - acc: 0.9922 - val_loss: 0.0543 - val_acc: 0.9860\n",
      "Epoch 2/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9969\n",
      "Epoch 00002: val_loss improved from 0.05433 to 0.03952, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_2.hdf5\n",
      "5158/5158 [==============================] - 3s 603us/sample - loss: 0.0140 - acc: 0.9969 - val_loss: 0.0395 - val_acc: 0.9860\n",
      "Epoch 3/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 00003: val_loss improved from 0.03952 to 0.03114, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_2.hdf5\n",
      "5158/5158 [==============================] - 3s 594us/sample - loss: 0.0106 - acc: 0.9969 - val_loss: 0.0311 - val_acc: 0.9930\n",
      "Epoch 4/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9967\n",
      "Epoch 00004: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 613us/sample - loss: 0.0117 - acc: 0.9967 - val_loss: 0.0667 - val_acc: 0.9846\n",
      "Epoch 5/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.4410 - acc: 0.8747\n",
      "Epoch 00005: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 616us/sample - loss: 0.4424 - acc: 0.8726 - val_loss: 0.7584 - val_acc: 0.5922\n",
      "Epoch 6/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.5096 - acc: 0.7669\n",
      "Epoch 00006: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 610us/sample - loss: 0.5097 - acc: 0.7679 - val_loss: 0.4337 - val_acc: 0.8841\n",
      "Epoch 7/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3539 - acc: 0.8788\n",
      "Epoch 00007: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 616us/sample - loss: 0.3538 - acc: 0.8794 - val_loss: 0.2735 - val_acc: 0.9344\n",
      "Epoch 8/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9322\n",
      "Epoch 00008: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 600us/sample - loss: 0.2365 - acc: 0.9321 - val_loss: 0.2214 - val_acc: 0.9330\n",
      "Epoch 9/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9316\n",
      "Epoch 00009: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 610us/sample - loss: 0.2048 - acc: 0.9314 - val_loss: 0.2034 - val_acc: 0.9427\n",
      "Epoch 10/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9408\n",
      "Epoch 00010: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 612us/sample - loss: 0.1633 - acc: 0.9407 - val_loss: 0.1694 - val_acc: 0.9399\n",
      "Epoch 11/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9504\n",
      "Epoch 00011: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 610us/sample - loss: 0.1256 - acc: 0.9508 - val_loss: 0.1341 - val_acc: 0.9385\n",
      "Epoch 12/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9643\n",
      "Epoch 00012: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 612us/sample - loss: 0.0971 - acc: 0.9637 - val_loss: 0.1039 - val_acc: 0.9623\n",
      "Epoch 13/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9743\n",
      "Epoch 00013: val_loss did not improve from 0.03114\n",
      "5158/5158 [==============================] - 3s 604us/sample - loss: 0.0765 - acc: 0.9744 - val_loss: 0.0848 - val_acc: 0.9735\n",
      "Training time: 40.76273441314697 s\n",
      "1290/1290 [==============================] - 1s 573us/sample - loss: 0.0048 - acc: 0.9992\n",
      "\n",
      "Fold: 3\n",
      "\n",
      "Train on 5158 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9988\n",
      "Epoch 00001: val_loss improved from inf to 0.03741, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_3.hdf5\n",
      "5158/5158 [==============================] - 3s 611us/sample - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0374 - val_acc: 0.9888\n",
      "Epoch 2/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 00002: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 613us/sample - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0386 - val_acc: 0.9888\n",
      "Epoch 3/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 00003: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 608us/sample - loss: 0.0022 - acc: 0.9998 - val_loss: 0.0408 - val_acc: 0.9874\n",
      "Epoch 4/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 00004: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 619us/sample - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0391 - val_acc: 0.9874\n",
      "Epoch 5/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 00005: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 608us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 0.9888\n",
      "Epoch 6/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00006: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 616us/sample - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0408 - val_acc: 0.9860\n",
      "Epoch 7/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 00007: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 607us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9874\n",
      "Epoch 8/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 00008: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 596us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9888\n",
      "Epoch 9/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 00009: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 598us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9874\n",
      "Epoch 10/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 00010: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 598us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 0.9874\n",
      "Epoch 11/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 9.5402e-04 - acc: 1.0000\n",
      "Epoch 00011: val_loss did not improve from 0.03741\n",
      "5158/5158 [==============================] - 3s 600us/sample - loss: 9.4847e-04 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9888\n",
      "Training time: 34.453264236450195 s\n",
      "1290/1290 [==============================] - 1s 570us/sample - loss: 0.0041 - acc: 1.0000\n",
      "\n",
      "Fold: 4\n",
      "\n",
      "Train on 5159 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00001: val_loss improved from inf to 0.04146, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_4.hdf5\n",
      "5159/5159 [==============================] - 3s 609us/sample - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0415 - val_acc: 0.9888\n",
      "Epoch 2/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 00002: val_loss improved from 0.04146 to 0.03915, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_4.hdf5\n",
      "5159/5159 [==============================] - 3s 612us/sample - loss: 0.0024 - acc: 0.9998 - val_loss: 0.0392 - val_acc: 0.9916\n",
      "Epoch 3/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 00003: val_loss improved from 0.03915 to 0.03412, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_4.hdf5\n",
      "5159/5159 [==============================] - 3s 613us/sample - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0341 - val_acc: 0.9930\n",
      "Epoch 4/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 00004: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 601us/sample - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0429 - val_acc: 0.9888\n",
      "Epoch 5/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 00005: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 612us/sample - loss: 0.0021 - acc: 0.9998 - val_loss: 0.0402 - val_acc: 0.9916\n",
      "Epoch 6/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00006: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 602us/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0447 - val_acc: 0.9916\n",
      "Epoch 7/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00007: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 608us/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0417 - val_acc: 0.9916\n",
      "Epoch 8/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00008: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 598us/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0437 - val_acc: 0.9902\n",
      "Epoch 9/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9994\n",
      "Epoch 00009: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 600us/sample - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0450 - val_acc: 0.9902\n",
      "Epoch 10/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00010: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 602us/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0383 - val_acc: 0.9930\n",
      "Epoch 11/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998 \n",
      "Epoch 00011: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 610us/sample - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0441 - val_acc: 0.9888\n",
      "Epoch 12/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 00012: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 606us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 0.9888\n",
      "Epoch 13/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 00013: val_loss did not improve from 0.03412\n",
      "5159/5159 [==============================] - 3s 607us/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0535 - val_acc: 0.9888\n",
      "Training time: 40.681434869766235 s\n",
      "1289/1289 [==============================] - 1s 602us/sample - loss: 0.0026 - acc: 1.0000\n",
      "\n",
      "Fold: 5\n",
      "\n",
      "Train on 5159 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9984\n",
      "Epoch 00001: val_loss improved from inf to 0.04109, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_5.hdf5\n",
      "5159/5159 [==============================] - 3s 605us/sample - loss: 0.0042 - acc: 0.9984 - val_loss: 0.0411 - val_acc: 0.9888\n",
      "Epoch 2/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 00002: val_loss did not improve from 0.04109\n",
      "5159/5159 [==============================] - 3s 616us/sample - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0444 - val_acc: 0.9902\n",
      "Epoch 3/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 00003: val_loss did not improve from 0.04109\n",
      "5159/5159 [==============================] - 3s 611us/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0476 - val_acc: 0.9888\n",
      "Epoch 4/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998    \n",
      "Epoch 00004: val_loss did not improve from 0.04109\n",
      "5159/5159 [==============================] - 3s 605us/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0453 - val_acc: 0.9916\n",
      "Epoch 5/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 9.8089e-04 - acc: 0.9998\n",
      "Epoch 00005: val_loss improved from 0.04109 to 0.03980, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_5.hdf5\n",
      "5159/5159 [==============================] - 3s 598us/sample - loss: 9.8270e-04 - acc: 0.9998 - val_loss: 0.0398 - val_acc: 0.9916\n",
      "Epoch 6/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 00006: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 609us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 0.9930\n",
      "Epoch 7/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 8.3009e-04 - acc: 1.0000\n",
      "Epoch 00007: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 607us/sample - loss: 8.2136e-04 - acc: 1.0000 - val_loss: 0.0469 - val_acc: 0.9902\n",
      "Epoch 8/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 6.9201e-04 - acc: 1.0000\n",
      "Epoch 00008: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 611us/sample - loss: 6.8498e-04 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9916\n",
      "Epoch 9/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 9.1299e-04 - acc: 0.9998\n",
      "Epoch 00009: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 601us/sample - loss: 9.0344e-04 - acc: 0.9998 - val_loss: 0.0432 - val_acc: 0.9930\n",
      "Epoch 10/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9984\n",
      "Epoch 00010: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 609us/sample - loss: 0.0065 - acc: 0.9983 - val_loss: 0.0693 - val_acc: 0.9846\n",
      "Epoch 11/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9937\n",
      "Epoch 00011: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 610us/sample - loss: 0.0210 - acc: 0.9938 - val_loss: 0.0705 - val_acc: 0.9846\n",
      "Epoch 12/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9980\n",
      "Epoch 00012: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 598us/sample - loss: 0.0079 - acc: 0.9981 - val_loss: 0.0480 - val_acc: 0.9916\n",
      "Epoch 13/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 00013: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 607us/sample - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0415 - val_acc: 0.9930\n",
      "Epoch 14/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9994\n",
      "Epoch 00014: val_loss did not improve from 0.03980\n",
      "5159/5159 [==============================] - 3s 599us/sample - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0400 - val_acc: 0.9930\n",
      "Epoch 15/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00015: val_loss improved from 0.03980 to 0.03925, saving model to /home/dorads/NeuralODE/models/Wafer/Wafer-LMU_5.hdf5\n",
      "5159/5159 [==============================] - 3s 608us/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0392 - val_acc: 0.9930\n",
      "Epoch 16/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 00016: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 601us/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0466 - val_acc: 0.9902\n",
      "Epoch 17/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 00017: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 592us/sample - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0445 - val_acc: 0.9916\n",
      "Epoch 18/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 7.5820e-04 - acc: 1.0000\n",
      "Epoch 00018: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 604us/sample - loss: 7.5137e-04 - acc: 1.0000 - val_loss: 0.0486 - val_acc: 0.9916\n",
      "Epoch 19/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 6.1496e-04 - acc: 1.0000\n",
      "Epoch 00019: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 609us/sample - loss: 6.1115e-04 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 0.9916\n",
      "Epoch 20/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 00020: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 606us/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0540 - val_acc: 0.9916\n",
      "Epoch 21/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 00021: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 603us/sample - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0738 - val_acc: 0.9860\n",
      "Epoch 22/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 00022: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 601us/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0563 - val_acc: 0.9902\n",
      "Epoch 23/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 00023: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 595us/sample - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0763 - val_acc: 0.9860\n",
      "Epoch 24/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 9.0003e-04 - acc: 0.9998\n",
      "Epoch 00024: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 608us/sample - loss: 8.9314e-04 - acc: 0.9998 - val_loss: 0.0634 - val_acc: 0.9902\n",
      "Epoch 25/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 4.8439e-04 - acc: 1.0000\n",
      "Epoch 00025: val_loss did not improve from 0.03925\n",
      "5159/5159 [==============================] - 3s 619us/sample - loss: 4.7896e-04 - acc: 1.0000 - val_loss: 0.0642 - val_acc: 0.9902\n",
      "Training time: 78.11002087593079 s\n",
      "1289/1289 [==============================] - 1s 604us/sample - loss: 0.0065 - acc: 0.9984\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.abspath(os.path.join('models', dataset))):\n",
    "    os.mkdir(os.path.abspath(os.path.join('models', dataset)))\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "sdk = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "df_tpr = pd.DataFrame(columns = [1, 2, 3, 4, 5])\n",
    "df_fpr = pd.DataFrame(columns = [1, 2, 3, 4, 5])\n",
    "\n",
    "n_fold = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "epoch_per_fold = []\n",
    "loss_per_fold = []\n",
    "rec_per_fold = []\n",
    "prec_per_fold = []\n",
    "f1_per_fold = []\n",
    "auroc_per_fold = []\n",
    "fpr_per_fold = []\n",
    "tpr_per_fold = []\n",
    "\n",
    "for train, test in sdk.split(x_all, y_all):\n",
    "    \n",
    "    file_path = os.path.abspath(os.path.join('models', dataset, f'{dataset}-{model_name}_{n_fold}.hdf5'))\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=file_path, monitor='val_loss', save_best_only = True, mode = 'min', verbose = 1), \n",
    "        EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min')]\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    print(f\"\\nFold: {n_fold}\\n\")\n",
    "    result = model.fit(x_all[train], \n",
    "                       to_categorical(y_all[train]),\n",
    "                       epochs = 200, \n",
    "                       batch_size = 100, \n",
    "                       validation_data = (x_valid, to_categorical(y_valid)), \n",
    "                       callbacks = callbacks)\n",
    "\n",
    "    print(f\"Training time: {time.time() - t} s\")\n",
    "\n",
    "    df_results = pd.DataFrame(result.history)\n",
    "    df_results.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_{n_fold}.csv')))\n",
    "    \n",
    "    model.load_weights(file_path)\n",
    "    scores = model.evaluate(x_all[test], to_categorical(y_all[test]))\n",
    "    loss_per_fold.append(scores[0])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    epoch_per_fold.append(np.argmin(result.history['val_loss']))\n",
    "    \n",
    "    # Computing predictions\n",
    "    y_pred_test = np.argmax(model.predict(x_all[test]), axis = 1)\n",
    "    \n",
    "    # Getting performance scores per fold\n",
    "    f1_per_fold.append(f1_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    rec_per_fold.append(recall_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    prec_per_fold.append(precision_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    auroc_per_fold.append(roc_auc_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    \n",
    "    # Getting ROC curve for this binary classification task\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_all[test], y_pred_test)\n",
    "    \n",
    "    df_fpr[n_fold] = fpr\n",
    "    df_tpr[n_fold] = tpr\n",
    "        \n",
    "    n_fold += 1\n",
    "\n",
    "df_scores = pd.DataFrame(columns = ['F1', 'Loss', 'Accuracy', 'Precision', 'Recall', 'AUROC'])\n",
    "df_scores['F1'] = f1_per_fold\n",
    "df_scores['Loss'] = loss_per_fold\n",
    "df_scores['Accuracy'] = acc_per_fold\n",
    "df_scores['Precision'] = prec_per_fold\n",
    "df_scores['Recall'] = rec_per_fold\n",
    "df_scores['AUROC'] = auroc_per_fold\n",
    "\n",
    "df_scores.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds.csv')))\n",
    "df_tpr.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds_tpr.csv')))\n",
    "df_fpr.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds_fpr.csv')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
