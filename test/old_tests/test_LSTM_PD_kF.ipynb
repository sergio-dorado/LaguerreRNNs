{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures_v1 import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training/Testing/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Instances: 6668\n",
      "Validation Instances: 666\n",
      "x_all: (6002, 217, 11) - y_all: (6002,)\n",
      "x_valid: (666, 217, 11) - y_valid: (666,)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"PhonemeSpectra\"\n",
    "\n",
    "x_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_train.npz')))\n",
    "x_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_test.npz')))\n",
    "\n",
    "x_train = x_train_load['arr_0']\n",
    "x_test = x_test_load['arr_0']\n",
    "\n",
    "x_all = np.concatenate((x_train, x_test), axis = 0)\n",
    "\n",
    "n_instances = x_all.shape[0]\n",
    "print(f\"Total Instances: {n_instances}\")\n",
    "\n",
    "y_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_train.npz')))\n",
    "y_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_test.npz')))\n",
    "\n",
    "y_train = np.asarray(y_train_load['arr_0'], dtype = np.uint64)\n",
    "y_test = np.asarray(y_test_load['arr_0'], dtype = np.uint64)\n",
    "\n",
    "y_all = np.concatenate((y_train, y_test), axis = 0)\n",
    "\n",
    "n_validation = int(0.1*n_instances)\n",
    "print(f\"Validation Instances: {n_validation}\")\n",
    "\n",
    "ind_validation = random.sample(range(0, n_instances), n_validation)\n",
    "x_valid = x_all[ind_validation, :, :]\n",
    "y_valid = y_all[ind_validation]\n",
    "\n",
    "x_all = np.delete(x_all, ind_validation, axis = 0)\n",
    "y_all = np.delete(y_all, ind_validation, axis = 0)\n",
    "\n",
    "print(f\"x_all: {x_all.shape} - y_all: {y_all.shape}\")\n",
    "print(f\"x_valid: {x_valid.shape} - y_valid: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dorads/.conda/envs/sd_dev_tf_1/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 212)               189952    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 39)                8307      \n",
      "=================================================================\n",
      "Total params: 198,259\n",
      "Trainable params: 198,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "length = x_all.shape[1]\n",
    "n_features = x_all.shape[-1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 212, \n",
    "              input_shape = (length, n_features), return_sequences = False))\n",
    "model.add(Dense(to_categorical(y_all).shape[-1], activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "\n",
      "WARNING:tensorflow:From /home/dorads/.conda/envs/sd_dev_tf_1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 4801 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.6413 - acc: 0.0344\n",
      "Epoch 00001: val_loss improved from inf to 3.59253, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 3.6413 - acc: 0.0344 - val_loss: 3.5925 - val_acc: 0.0240\n",
      "Epoch 2/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.5649 - acc: 0.0448\n",
      "Epoch 00002: val_loss improved from 3.59253 to 3.55273, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 3.5648 - acc: 0.0448 - val_loss: 3.5527 - val_acc: 0.0511\n",
      "Epoch 3/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.5000 - acc: 0.0546\n",
      "Epoch 00003: val_loss improved from 3.55273 to 3.40612, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 3.4999 - acc: 0.0546 - val_loss: 3.4061 - val_acc: 0.0691\n",
      "Epoch 4/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.3425 - acc: 0.0660\n",
      "Epoch 00004: val_loss improved from 3.40612 to 3.30264, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 3.3425 - acc: 0.0660 - val_loss: 3.3026 - val_acc: 0.0871\n",
      "Epoch 5/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.2706 - acc: 0.0817\n",
      "Epoch 00005: val_loss improved from 3.30264 to 3.19515, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 3.2708 - acc: 0.0816 - val_loss: 3.1952 - val_acc: 0.0871\n",
      "Epoch 6/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.1880 - acc: 0.0938\n",
      "Epoch 00006: val_loss improved from 3.19515 to 3.11801, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 3.1880 - acc: 0.0937 - val_loss: 3.1180 - val_acc: 0.0736\n",
      "Epoch 7/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.0796 - acc: 0.1029\n",
      "Epoch 00007: val_loss improved from 3.11801 to 3.04714, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 3.0796 - acc: 0.1029 - val_loss: 3.0471 - val_acc: 0.1096\n",
      "Epoch 8/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.1951 - acc: 0.0919\n",
      "Epoch 00008: val_loss did not improve from 3.04714\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 3.1950 - acc: 0.0919 - val_loss: 3.1918 - val_acc: 0.0856\n",
      "Epoch 9/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.0482 - acc: 0.1102\n",
      "Epoch 00009: val_loss improved from 3.04714 to 3.01338, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 3.0483 - acc: 0.1102 - val_loss: 3.0134 - val_acc: 0.1096\n",
      "Epoch 10/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.0113 - acc: 0.1056\n",
      "Epoch 00010: val_loss did not improve from 3.01338\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 3.0111 - acc: 0.1056 - val_loss: 3.0664 - val_acc: 0.1036\n",
      "Epoch 11/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.0212 - acc: 0.1181\n",
      "Epoch 00011: val_loss improved from 3.01338 to 3.01204, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 3.0210 - acc: 0.1181 - val_loss: 3.0120 - val_acc: 0.1006\n",
      "Epoch 12/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.9495 - acc: 0.1285\n",
      "Epoch 00012: val_loss did not improve from 3.01204\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.9494 - acc: 0.1285 - val_loss: 3.0134 - val_acc: 0.1156\n",
      "Epoch 13/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.9271 - acc: 0.1388\n",
      "Epoch 00013: val_loss improved from 3.01204 to 2.99069, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.9274 - acc: 0.1387 - val_loss: 2.9907 - val_acc: 0.1291\n",
      "Epoch 14/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.8911 - acc: 0.1408\n",
      "Epoch 00014: val_loss did not improve from 2.99069\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.8910 - acc: 0.1408 - val_loss: 2.9934 - val_acc: 0.1201\n",
      "Epoch 15/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.9797 - acc: 0.1373\n",
      "Epoch 00015: val_loss improved from 2.99069 to 2.98492, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.9796 - acc: 0.1375 - val_loss: 2.9849 - val_acc: 0.1156\n",
      "Epoch 16/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.9316 - acc: 0.1392\n",
      "Epoch 00016: val_loss improved from 2.98492 to 2.93644, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.9316 - acc: 0.1391 - val_loss: 2.9364 - val_acc: 0.1126\n",
      "Epoch 17/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.8294 - acc: 0.1625\n",
      "Epoch 00017: val_loss did not improve from 2.93644\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.8294 - acc: 0.1625 - val_loss: 2.9410 - val_acc: 0.1336\n",
      "Epoch 18/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.8183 - acc: 0.1608\n",
      "Epoch 00018: val_loss improved from 2.93644 to 2.88080, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.8182 - acc: 0.1608 - val_loss: 2.8808 - val_acc: 0.1381\n",
      "Epoch 19/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7698 - acc: 0.1740\n",
      "Epoch 00019: val_loss did not improve from 2.88080\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.7700 - acc: 0.1739 - val_loss: 2.8930 - val_acc: 0.1652\n",
      "Epoch 20/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7930 - acc: 0.1785\n",
      "Epoch 00020: val_loss did not improve from 2.88080\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.7932 - acc: 0.1785 - val_loss: 2.9168 - val_acc: 0.1441\n",
      "Epoch 21/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.8780 - acc: 0.1633\n",
      "Epoch 00021: val_loss improved from 2.88080 to 2.86339, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.8780 - acc: 0.1633 - val_loss: 2.8634 - val_acc: 0.1396\n",
      "Epoch 22/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7336 - acc: 0.1819\n",
      "Epoch 00022: val_loss improved from 2.86339 to 2.84890, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.7336 - acc: 0.1818 - val_loss: 2.8489 - val_acc: 0.1381\n",
      "Epoch 23/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.8714 - acc: 0.1577\n",
      "Epoch 00023: val_loss did not improve from 2.84890\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.8716 - acc: 0.1577 - val_loss: 2.9482 - val_acc: 0.1261\n",
      "Epoch 24/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.8778 - acc: 0.1612\n",
      "Epoch 00024: val_loss did not improve from 2.84890\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.8778 - acc: 0.1612 - val_loss: 2.9685 - val_acc: 0.1502\n",
      "Epoch 25/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7290 - acc: 0.1877\n",
      "Epoch 00025: val_loss did not improve from 2.84890\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.7289 - acc: 0.1879 - val_loss: 2.8851 - val_acc: 0.1562\n",
      "Epoch 26/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6730 - acc: 0.1954\n",
      "Epoch 00026: val_loss did not improve from 2.84890\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.6730 - acc: 0.1954 - val_loss: 2.8874 - val_acc: 0.1471\n",
      "Epoch 27/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7939 - acc: 0.1708\n",
      "Epoch 00027: val_loss did not improve from 2.84890\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.7940 - acc: 0.1708 - val_loss: 2.8760 - val_acc: 0.1456\n",
      "Epoch 28/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6543 - acc: 0.2081\n",
      "Epoch 00028: val_loss did not improve from 2.84890\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.6544 - acc: 0.2081 - val_loss: 2.8667 - val_acc: 0.1517\n",
      "Epoch 29/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6190 - acc: 0.2077\n",
      "Epoch 00029: val_loss did not improve from 2.84890\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.6195 - acc: 0.2077 - val_loss: 2.8609 - val_acc: 0.1547\n",
      "Epoch 30/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6577 - acc: 0.2048\n",
      "Epoch 00030: val_loss did not improve from 2.84890\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.6578 - acc: 0.2047 - val_loss: 2.9093 - val_acc: 0.1652\n",
      "Epoch 31/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6070 - acc: 0.2150\n",
      "Epoch 00031: val_loss improved from 2.84890 to 2.81951, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.6073 - acc: 0.2150 - val_loss: 2.8195 - val_acc: 0.1547\n",
      "Epoch 32/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.5717 - acc: 0.2281\n",
      "Epoch 00032: val_loss improved from 2.81951 to 2.81686, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.5714 - acc: 0.2281 - val_loss: 2.8169 - val_acc: 0.1802\n",
      "Epoch 33/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.5159 - acc: 0.2444\n",
      "Epoch 00033: val_loss did not improve from 2.81686\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.5159 - acc: 0.2443 - val_loss: 2.8325 - val_acc: 0.1742\n",
      "Epoch 34/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6609 - acc: 0.2077\n",
      "Epoch 00034: val_loss improved from 2.81686 to 2.81133, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.6609 - acc: 0.2077 - val_loss: 2.8113 - val_acc: 0.1832\n",
      "Epoch 35/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.5306 - acc: 0.2419\n",
      "Epoch 00035: val_loss improved from 2.81133 to 2.77717, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.5312 - acc: 0.2418 - val_loss: 2.7772 - val_acc: 0.1997\n",
      "Epoch 36/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.4724 - acc: 0.2529\n",
      "Epoch 00036: val_loss improved from 2.77717 to 2.76833, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.4724 - acc: 0.2531 - val_loss: 2.7683 - val_acc: 0.1637\n",
      "Epoch 37/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.4537 - acc: 0.2558\n",
      "Epoch 00037: val_loss did not improve from 2.76833\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.4537 - acc: 0.2558 - val_loss: 2.8323 - val_acc: 0.1712\n",
      "Epoch 38/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.5357 - acc: 0.2348\n",
      "Epoch 00038: val_loss did not improve from 2.76833\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.5353 - acc: 0.2350 - val_loss: 2.7704 - val_acc: 0.1622\n",
      "Epoch 39/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.4219 - acc: 0.2642\n",
      "Epoch 00039: val_loss did not improve from 2.76833\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.4219 - acc: 0.2641 - val_loss: 2.7801 - val_acc: 0.1772\n",
      "Epoch 40/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3811 - acc: 0.2740\n",
      "Epoch 00040: val_loss did not improve from 2.76833\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.3809 - acc: 0.2739 - val_loss: 2.7743 - val_acc: 0.1652\n",
      "Epoch 41/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3859 - acc: 0.2744\n",
      "Epoch 00041: val_loss did not improve from 2.76833\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.3858 - acc: 0.2745 - val_loss: 2.7825 - val_acc: 0.1982\n",
      "Epoch 42/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.4743 - acc: 0.2473\n",
      "Epoch 00042: val_loss improved from 2.76833 to 2.76396, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.4741 - acc: 0.2474 - val_loss: 2.7640 - val_acc: 0.1922\n",
      "Epoch 43/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3482 - acc: 0.2823\n",
      "Epoch 00043: val_loss did not improve from 2.76396\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.3481 - acc: 0.2824 - val_loss: 2.7706 - val_acc: 0.1817\n",
      "Epoch 44/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2835 - acc: 0.3027\n",
      "Epoch 00044: val_loss improved from 2.76396 to 2.76083, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2832 - acc: 0.3029 - val_loss: 2.7608 - val_acc: 0.1937\n",
      "Epoch 45/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3716 - acc: 0.2794\n",
      "Epoch 00045: val_loss did not improve from 2.76083\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.3715 - acc: 0.2793 - val_loss: 2.8020 - val_acc: 0.1742\n",
      "Epoch 46/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2862 - acc: 0.3004\n",
      "Epoch 00046: val_loss improved from 2.76083 to 2.73820, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.2861 - acc: 0.3004 - val_loss: 2.7382 - val_acc: 0.1772\n",
      "Epoch 47/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2639 - acc: 0.3004\n",
      "Epoch 00047: val_loss did not improve from 2.73820\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2639 - acc: 0.3004 - val_loss: 2.7524 - val_acc: 0.1892\n",
      "Epoch 48/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2865 - acc: 0.2981\n",
      "Epoch 00048: val_loss did not improve from 2.73820\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2863 - acc: 0.2983 - val_loss: 2.7680 - val_acc: 0.1997\n",
      "Epoch 49/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2364 - acc: 0.3173\n",
      "Epoch 00049: val_loss did not improve from 2.73820\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.2364 - acc: 0.3172 - val_loss: 2.7897 - val_acc: 0.1937\n",
      "Epoch 50/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1979 - acc: 0.3271\n",
      "Epoch 00050: val_loss did not improve from 2.73820\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.1978 - acc: 0.3270 - val_loss: 2.7749 - val_acc: 0.1802\n",
      "Epoch 51/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2693 - acc: 0.2977\n",
      "Epoch 00051: val_loss did not improve from 2.73820\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2692 - acc: 0.2976 - val_loss: 2.8409 - val_acc: 0.1772\n",
      "Epoch 52/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3135 - acc: 0.2965\n",
      "Epoch 00052: val_loss did not improve from 2.73820\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.3137 - acc: 0.2964 - val_loss: 2.8275 - val_acc: 0.1772\n",
      "Epoch 53/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.4306 - acc: 0.2667\n",
      "Epoch 00053: val_loss improved from 2.73820 to 2.73361, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.4305 - acc: 0.2666 - val_loss: 2.7336 - val_acc: 0.1772\n",
      "Epoch 54/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2165 - acc: 0.3237\n",
      "Epoch 00054: val_loss improved from 2.73361 to 2.71309, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_1.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2163 - acc: 0.3239 - val_loss: 2.7131 - val_acc: 0.2012\n",
      "Epoch 55/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1293 - acc: 0.3469\n",
      "Epoch 00055: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.1293 - acc: 0.3468 - val_loss: 2.7873 - val_acc: 0.1862\n",
      "Epoch 56/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1434 - acc: 0.3390\n",
      "Epoch 00056: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.1433 - acc: 0.3389 - val_loss: 2.7810 - val_acc: 0.2102\n",
      "Epoch 57/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1734 - acc: 0.3394\n",
      "Epoch 00057: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.1731 - acc: 0.3395 - val_loss: 2.7552 - val_acc: 0.1922\n",
      "Epoch 58/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0636 - acc: 0.3617\n",
      "Epoch 00058: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.0636 - acc: 0.3618 - val_loss: 2.7713 - val_acc: 0.1982\n",
      "Epoch 59/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0213 - acc: 0.3752\n",
      "Epoch 00059: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.0213 - acc: 0.3751 - val_loss: 2.7448 - val_acc: 0.2012\n",
      "Epoch 60/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0958 - acc: 0.3540\n",
      "Epoch 00060: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.0957 - acc: 0.3541 - val_loss: 2.8020 - val_acc: 0.2012\n",
      "Epoch 61/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0086 - acc: 0.3858\n",
      "Epoch 00061: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.0085 - acc: 0.3858 - val_loss: 2.7706 - val_acc: 0.1877\n",
      "Epoch 62/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0125 - acc: 0.3869\n",
      "Epoch 00062: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.0127 - acc: 0.3868 - val_loss: 2.7536 - val_acc: 0.2192\n",
      "Epoch 63/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9900 - acc: 0.3862\n",
      "Epoch 00063: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.9898 - acc: 0.3864 - val_loss: 2.7672 - val_acc: 0.2072\n",
      "Epoch 64/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8993 - acc: 0.4096\n",
      "Epoch 00064: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8991 - acc: 0.4097 - val_loss: 2.7969 - val_acc: 0.1832\n",
      "Epoch 65/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8748 - acc: 0.4210\n",
      "Epoch 00065: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8749 - acc: 0.4210 - val_loss: 2.8139 - val_acc: 0.1907\n",
      "Epoch 66/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8847 - acc: 0.4196\n",
      "Epoch 00066: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8846 - acc: 0.4197 - val_loss: 2.7838 - val_acc: 0.1952\n",
      "Epoch 67/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8408 - acc: 0.4317\n",
      "Epoch 00067: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.8411 - acc: 0.4316 - val_loss: 2.8293 - val_acc: 0.1922\n",
      "Epoch 68/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8694 - acc: 0.4131\n",
      "Epoch 00068: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8693 - acc: 0.4130 - val_loss: 2.7891 - val_acc: 0.2027\n",
      "Epoch 69/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8647 - acc: 0.4296\n",
      "Epoch 00069: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8647 - acc: 0.4295 - val_loss: 2.7977 - val_acc: 0.1997\n",
      "Epoch 70/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7788 - acc: 0.4487\n",
      "Epoch 00070: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7787 - acc: 0.4489 - val_loss: 2.8309 - val_acc: 0.2147\n",
      "Epoch 71/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8083 - acc: 0.4440\n",
      "Epoch 00071: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8088 - acc: 0.4439 - val_loss: 2.8326 - val_acc: 0.2042\n",
      "Epoch 72/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7654 - acc: 0.4581\n",
      "Epoch 00072: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7656 - acc: 0.4580 - val_loss: 2.8618 - val_acc: 0.2012\n",
      "Epoch 73/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8382 - acc: 0.4354\n",
      "Epoch 00073: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8382 - acc: 0.4353 - val_loss: 2.8791 - val_acc: 0.1892\n",
      "Epoch 74/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7731 - acc: 0.4565\n",
      "Epoch 00074: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7736 - acc: 0.4564 - val_loss: 2.9606 - val_acc: 0.1892\n",
      "Epoch 75/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3045 - acc: 0.3135\n",
      "Epoch 00075: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.3045 - acc: 0.3135 - val_loss: 2.9048 - val_acc: 0.1952\n",
      "Epoch 76/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1001 - acc: 0.3465\n",
      "Epoch 00076: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.0999 - acc: 0.3466 - val_loss: 2.8593 - val_acc: 0.2042\n",
      "Epoch 77/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9406 - acc: 0.3938\n",
      "Epoch 00077: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.9406 - acc: 0.3937 - val_loss: 2.8706 - val_acc: 0.1757\n",
      "Epoch 78/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9045 - acc: 0.4075\n",
      "Epoch 00078: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.9044 - acc: 0.4076 - val_loss: 2.8509 - val_acc: 0.1862\n",
      "Epoch 79/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8400 - acc: 0.4233\n",
      "Epoch 00079: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8399 - acc: 0.4235 - val_loss: 2.8511 - val_acc: 0.1997\n",
      "Epoch 80/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8183 - acc: 0.4269\n",
      "Epoch 00080: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8183 - acc: 0.4268 - val_loss: 2.8657 - val_acc: 0.1877\n",
      "Epoch 81/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7936 - acc: 0.4406\n",
      "Epoch 00081: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7934 - acc: 0.4407 - val_loss: 2.8938 - val_acc: 0.1892\n",
      "Epoch 82/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6941 - acc: 0.4771\n",
      "Epoch 00082: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.6938 - acc: 0.4772 - val_loss: 2.8620 - val_acc: 0.2057\n",
      "Epoch 83/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6852 - acc: 0.4806\n",
      "Epoch 00083: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.6851 - acc: 0.4807 - val_loss: 2.9492 - val_acc: 0.1697\n",
      "Epoch 84/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6636 - acc: 0.4865\n",
      "Epoch 00084: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.6637 - acc: 0.4864 - val_loss: 2.9140 - val_acc: 0.1772\n",
      "Epoch 85/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7951 - acc: 0.4396\n",
      "Epoch 00085: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7955 - acc: 0.4395 - val_loss: 3.0147 - val_acc: 0.1862\n",
      "Epoch 86/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6708 - acc: 0.2531\n",
      "Epoch 00086: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.6705 - acc: 0.2533 - val_loss: 3.1222 - val_acc: 0.1441\n",
      "Epoch 87/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3288 - acc: 0.2900\n",
      "Epoch 00087: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.3290 - acc: 0.2899 - val_loss: 3.0134 - val_acc: 0.1502\n",
      "Epoch 88/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2042 - acc: 0.3156\n",
      "Epoch 00088: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2042 - acc: 0.3156 - val_loss: 2.9316 - val_acc: 0.1607\n",
      "Epoch 89/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1176 - acc: 0.3481\n",
      "Epoch 00089: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.1175 - acc: 0.3483 - val_loss: 2.9384 - val_acc: 0.1757\n",
      "Epoch 90/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0230 - acc: 0.3802\n",
      "Epoch 00090: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.0231 - acc: 0.3801 - val_loss: 2.8801 - val_acc: 0.1832\n",
      "Epoch 91/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0224 - acc: 0.3798\n",
      "Epoch 00091: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.0223 - acc: 0.3799 - val_loss: 2.8797 - val_acc: 0.1772\n",
      "Epoch 92/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9245 - acc: 0.4004\n",
      "Epoch 00092: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.9243 - acc: 0.4005 - val_loss: 2.8374 - val_acc: 0.1787\n",
      "Epoch 93/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8716 - acc: 0.4123\n",
      "Epoch 00093: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8722 - acc: 0.4122 - val_loss: 2.9167 - val_acc: 0.1742\n",
      "Epoch 94/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8300 - acc: 0.4269\n",
      "Epoch 00094: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8298 - acc: 0.4270 - val_loss: 2.8934 - val_acc: 0.1727\n",
      "Epoch 95/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8097 - acc: 0.4444\n",
      "Epoch 00095: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.8095 - acc: 0.4445 - val_loss: 2.8672 - val_acc: 0.1847\n",
      "Epoch 96/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7744 - acc: 0.4477\n",
      "Epoch 00096: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7744 - acc: 0.4476 - val_loss: 2.9178 - val_acc: 0.1787\n",
      "Epoch 97/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8181 - acc: 0.4404\n",
      "Epoch 00097: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.8180 - acc: 0.4403 - val_loss: 2.8499 - val_acc: 0.1832\n",
      "Epoch 98/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7447 - acc: 0.4581\n",
      "Epoch 00098: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7456 - acc: 0.4580 - val_loss: 2.9213 - val_acc: 0.1937\n",
      "Epoch 99/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7006 - acc: 0.4710\n",
      "Epoch 00099: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7007 - acc: 0.4712 - val_loss: 2.9478 - val_acc: 0.1802\n",
      "Epoch 100/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.1732 - acc: 0.1825\n",
      "Epoch 00100: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 3.1729 - acc: 0.1827 - val_loss: 3.1075 - val_acc: 0.1471\n",
      "Epoch 101/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6636 - acc: 0.2279\n",
      "Epoch 00101: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.6632 - acc: 0.2281 - val_loss: 2.9402 - val_acc: 0.1396\n",
      "Epoch 102/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3742 - acc: 0.2883\n",
      "Epoch 00102: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.3740 - acc: 0.2885 - val_loss: 2.8600 - val_acc: 0.1787\n",
      "Epoch 103/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2078 - acc: 0.3277\n",
      "Epoch 00103: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.2078 - acc: 0.3276 - val_loss: 2.8582 - val_acc: 0.1471\n",
      "Epoch 104/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1012 - acc: 0.3485\n",
      "Epoch 00104: val_loss did not improve from 2.71309\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.1015 - acc: 0.3485 - val_loss: 2.8017 - val_acc: 0.1787\n",
      "Training time: 989.6067879199982 s\n",
      "1201/1201 [==============================] - 2s 1ms/sample - loss: 2.7099 - acc: 0.2048\n",
      "Fold: 2\n",
      "\n",
      "Train on 4801 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2464 - acc: 0.3183\n",
      "Epoch 00001: val_loss improved from inf to 2.72368, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_2.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2465 - acc: 0.3183 - val_loss: 2.7237 - val_acc: 0.1862\n",
      "Epoch 2/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3585 - acc: 0.2867\n",
      "Epoch 00002: val_loss did not improve from 2.72368\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.3582 - acc: 0.2868 - val_loss: 2.7652 - val_acc: 0.1607\n",
      "Epoch 3/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2504 - acc: 0.3177\n",
      "Epoch 00003: val_loss did not improve from 2.72368\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2504 - acc: 0.3176 - val_loss: 2.7337 - val_acc: 0.2042\n",
      "Epoch 4/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1874 - acc: 0.3327\n",
      "Epoch 00004: val_loss did not improve from 2.72368\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.1871 - acc: 0.3328 - val_loss: 2.7372 - val_acc: 0.1967\n",
      "Epoch 5/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1251 - acc: 0.3592\n",
      "Epoch 00005: val_loss improved from 2.72368 to 2.69505, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_2.hdf5\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.1254 - acc: 0.3591 - val_loss: 2.6950 - val_acc: 0.1892\n",
      "Epoch 6/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1303 - acc: 0.3442\n",
      "Epoch 00006: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 2.1310 - acc: 0.3441 - val_loss: 2.7486 - val_acc: 0.1922\n",
      "Epoch 7/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.5471 - acc: 0.2627\n",
      "Epoch 00007: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.5469 - acc: 0.2627 - val_loss: 2.7439 - val_acc: 0.1892\n",
      "Epoch 8/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2795 - acc: 0.3065\n",
      "Epoch 00008: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2795 - acc: 0.3064 - val_loss: 2.7106 - val_acc: 0.2102\n",
      "Epoch 9/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2215 - acc: 0.3183\n",
      "Epoch 00009: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.2214 - acc: 0.3183 - val_loss: 2.7202 - val_acc: 0.2057\n",
      "Epoch 10/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1487 - acc: 0.3417\n",
      "Epoch 00010: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.1486 - acc: 0.3418 - val_loss: 2.7225 - val_acc: 0.1877\n",
      "Epoch 11/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1893 - acc: 0.3288\n",
      "Epoch 00011: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.1890 - acc: 0.3289 - val_loss: 2.7400 - val_acc: 0.1892\n",
      "Epoch 12/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1074 - acc: 0.3598\n",
      "Epoch 00012: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.1073 - acc: 0.3599 - val_loss: 2.7374 - val_acc: 0.2132\n",
      "Epoch 13/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0730 - acc: 0.3681\n",
      "Epoch 00013: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.0729 - acc: 0.3683 - val_loss: 2.7451 - val_acc: 0.1967\n",
      "Epoch 14/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0146 - acc: 0.3779\n",
      "Epoch 00014: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.0145 - acc: 0.3778 - val_loss: 2.7300 - val_acc: 0.2072\n",
      "Epoch 15/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9917 - acc: 0.3869\n",
      "Epoch 00015: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.9915 - acc: 0.3870 - val_loss: 2.7610 - val_acc: 0.1907\n",
      "Epoch 16/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9844 - acc: 0.3858\n",
      "Epoch 00016: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.9848 - acc: 0.3858 - val_loss: 2.7352 - val_acc: 0.1832\n",
      "Epoch 17/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9952 - acc: 0.3883\n",
      "Epoch 00017: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.9951 - acc: 0.3883 - val_loss: 2.7474 - val_acc: 0.2042\n",
      "Epoch 18/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9771 - acc: 0.3942\n",
      "Epoch 00018: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.9771 - acc: 0.3941 - val_loss: 2.7449 - val_acc: 0.2102\n",
      "Epoch 19/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9178 - acc: 0.4140\n",
      "Epoch 00019: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.9183 - acc: 0.4139 - val_loss: 2.7340 - val_acc: 0.1952\n",
      "Epoch 20/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8567 - acc: 0.4315\n",
      "Epoch 00020: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8569 - acc: 0.4314 - val_loss: 2.8039 - val_acc: 0.2042\n",
      "Epoch 21/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8548 - acc: 0.4354\n",
      "Epoch 00021: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8547 - acc: 0.4355 - val_loss: 2.8157 - val_acc: 0.1982\n",
      "Epoch 22/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8525 - acc: 0.4260\n",
      "Epoch 00022: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8524 - acc: 0.4262 - val_loss: 2.7738 - val_acc: 0.1967\n",
      "Epoch 23/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8110 - acc: 0.4381\n",
      "Epoch 00023: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8107 - acc: 0.4382 - val_loss: 2.8443 - val_acc: 0.2072\n",
      "Epoch 24/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7901 - acc: 0.4431\n",
      "Epoch 00024: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7904 - acc: 0.4430 - val_loss: 2.8609 - val_acc: 0.1802\n",
      "Epoch 25/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8611 - acc: 0.4269\n",
      "Epoch 00025: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8613 - acc: 0.4268 - val_loss: 2.8609 - val_acc: 0.1952\n",
      "Epoch 26/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8417 - acc: 0.4265\n",
      "Epoch 00026: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8418 - acc: 0.4264 - val_loss: 2.8741 - val_acc: 0.1937\n",
      "Epoch 27/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7933 - acc: 0.4419\n",
      "Epoch 00027: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7936 - acc: 0.4418 - val_loss: 2.8248 - val_acc: 0.1952\n",
      "Epoch 28/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7440 - acc: 0.4623\n",
      "Epoch 00028: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7446 - acc: 0.4622 - val_loss: 2.8721 - val_acc: 0.2027\n",
      "Epoch 29/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7266 - acc: 0.4752\n",
      "Epoch 00029: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7266 - acc: 0.4751 - val_loss: 2.8663 - val_acc: 0.1892\n",
      "Epoch 30/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6755 - acc: 0.4860\n",
      "Epoch 00030: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.6754 - acc: 0.4861 - val_loss: 2.8832 - val_acc: 0.2087\n",
      "Epoch 31/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8184 - acc: 0.4385\n",
      "Epoch 00031: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.8182 - acc: 0.4387 - val_loss: 2.9114 - val_acc: 0.1847\n",
      "Epoch 32/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7174 - acc: 0.4650\n",
      "Epoch 00032: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7170 - acc: 0.4651 - val_loss: 2.9084 - val_acc: 0.1967\n",
      "Epoch 33/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6623 - acc: 0.4963\n",
      "Epoch 00033: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.6626 - acc: 0.4961 - val_loss: 2.8598 - val_acc: 0.2177\n",
      "Epoch 34/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7157 - acc: 0.4583\n",
      "Epoch 00034: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7158 - acc: 0.4582 - val_loss: 2.8722 - val_acc: 0.2207\n",
      "Epoch 35/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7352 - acc: 0.4592\n",
      "Epoch 00035: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7351 - acc: 0.4593 - val_loss: 2.8986 - val_acc: 0.1997\n",
      "Epoch 36/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9656 - acc: 0.3925\n",
      "Epoch 00036: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.9659 - acc: 0.3924 - val_loss: 2.9383 - val_acc: 0.1817\n",
      "Epoch 37/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8299 - acc: 0.4402\n",
      "Epoch 00037: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.8304 - acc: 0.4401 - val_loss: 2.8838 - val_acc: 0.1847\n",
      "Epoch 38/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7173 - acc: 0.4660\n",
      "Epoch 00038: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7174 - acc: 0.4659 - val_loss: 2.8835 - val_acc: 0.2042\n",
      "Epoch 39/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6441 - acc: 0.4919- ETA: 4s -\n",
      "Epoch 00039: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.6441 - acc: 0.4918 - val_loss: 2.9111 - val_acc: 0.2087\n",
      "Epoch 40/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.5959 - acc: 0.5021\n",
      "Epoch 00040: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.5956 - acc: 0.5022 - val_loss: 2.9245 - val_acc: 0.2102\n",
      "Epoch 41/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7089 - acc: 0.4798\n",
      "Epoch 00041: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7087 - acc: 0.4799 - val_loss: 3.0921 - val_acc: 0.1757\n",
      "Epoch 42/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0037 - acc: 0.3915\n",
      "Epoch 00042: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.0036 - acc: 0.3916 - val_loss: 2.9198 - val_acc: 0.1937\n",
      "Epoch 43/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8405 - acc: 0.4290\n",
      "Epoch 00043: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.8402 - acc: 0.4291 - val_loss: 2.9337 - val_acc: 0.1862\n",
      "Epoch 44/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7188 - acc: 0.4673\n",
      "Epoch 00044: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.7189 - acc: 0.4672 - val_loss: 2.9073 - val_acc: 0.1922\n",
      "Epoch 45/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0699 - acc: 0.3698\n",
      "Epoch 00045: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 2.0695 - acc: 0.3699 - val_loss: 2.9387 - val_acc: 0.1817\n",
      "Epoch 46/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8561 - acc: 0.4208\n",
      "Epoch 00046: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.8560 - acc: 0.4207 - val_loss: 2.9306 - val_acc: 0.2117\n",
      "Epoch 47/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8972 - acc: 0.4117\n",
      "Epoch 00047: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.8976 - acc: 0.4116 - val_loss: 2.8928 - val_acc: 0.1907\n",
      "Epoch 48/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7530 - acc: 0.4538\n",
      "Epoch 00048: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7530 - acc: 0.4537 - val_loss: 2.9292 - val_acc: 0.1982\n",
      "Epoch 49/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8373 - acc: 0.4317\n",
      "Epoch 00049: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.8372 - acc: 0.4318 - val_loss: 2.8644 - val_acc: 0.2147\n",
      "Epoch 50/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9418 - acc: 0.4092\n",
      "Epoch 00050: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.9415 - acc: 0.4093 - val_loss: 2.9108 - val_acc: 0.2027\n",
      "Epoch 51/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7558 - acc: 0.4542\n",
      "Epoch 00051: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7562 - acc: 0.4541 - val_loss: 2.9224 - val_acc: 0.2042\n",
      "Epoch 52/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7296 - acc: 0.4635\n",
      "Epoch 00052: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.7297 - acc: 0.4634 - val_loss: 2.9123 - val_acc: 0.2102\n",
      "Epoch 53/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.5946 - acc: 0.5048\n",
      "Epoch 00053: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 10s 2ms/sample - loss: 1.5945 - acc: 0.5049 - val_loss: 2.8924 - val_acc: 0.2222\n",
      "Epoch 54/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.5316 - acc: 0.5312\n",
      "Epoch 00054: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.5314 - acc: 0.5313 - val_loss: 2.9469 - val_acc: 0.2042\n",
      "Epoch 55/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.5098 - acc: 0.5385\n",
      "Epoch 00055: val_loss did not improve from 2.69505\n",
      "4801/4801 [==============================] - 9s 2ms/sample - loss: 1.5099 - acc: 0.5384 - val_loss: 2.9605 - val_acc: 0.2147\n",
      "Training time: 523.4457685947418 s\n",
      "1201/1201 [==============================] - 2s 1ms/sample - loss: 2.2183 - acc: 0.3122\n",
      "Fold: 3\n",
      "\n",
      "Train on 4802 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1852 - acc: 0.3306\n",
      "Epoch 00001: val_loss improved from inf to 2.71646, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_3.hdf5\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.1856 - acc: 0.3305 - val_loss: 2.7165 - val_acc: 0.1967\n",
      "Epoch 2/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1383 - acc: 0.3356\n",
      "Epoch 00002: val_loss improved from 2.71646 to 2.71397, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_3.hdf5\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.1391 - acc: 0.3355 - val_loss: 2.7140 - val_acc: 0.1937\n",
      "Epoch 3/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0902 - acc: 0.3508\n",
      "Epoch 00003: val_loss did not improve from 2.71397\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.0899 - acc: 0.3511 - val_loss: 2.7191 - val_acc: 0.1772\n",
      "Epoch 4/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0335 - acc: 0.3785\n",
      "Epoch 00004: val_loss improved from 2.71397 to 2.71373, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_3.hdf5\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.0339 - acc: 0.3784 - val_loss: 2.7137 - val_acc: 0.2132\n",
      "Epoch 5/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0066 - acc: 0.3754\n",
      "Epoch 00005: val_loss did not improve from 2.71373\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.0067 - acc: 0.3755 - val_loss: 2.7164 - val_acc: 0.2012\n",
      "Epoch 6/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9712 - acc: 0.3931\n",
      "Epoch 00006: val_loss improved from 2.71373 to 2.70716, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_3.hdf5\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9712 - acc: 0.3930 - val_loss: 2.7072 - val_acc: 0.2162\n",
      "Epoch 7/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9747 - acc: 0.3956\n",
      "Epoch 00007: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9746 - acc: 0.3957 - val_loss: 2.7592 - val_acc: 0.1907\n",
      "Epoch 8/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9941 - acc: 0.3794\n",
      "Epoch 00008: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9945 - acc: 0.3792 - val_loss: 2.7133 - val_acc: 0.2027\n",
      "Epoch 9/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9515 - acc: 0.3908\n",
      "Epoch 00009: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9515 - acc: 0.3909 - val_loss: 2.7230 - val_acc: 0.1922\n",
      "Epoch 10/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8860 - acc: 0.4148\n",
      "Epoch 00010: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8864 - acc: 0.4146 - val_loss: 2.7274 - val_acc: 0.1907\n",
      "Epoch 11/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8899 - acc: 0.4131\n",
      "Epoch 00011: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8896 - acc: 0.4134 - val_loss: 2.7530 - val_acc: 0.2042\n",
      "Epoch 12/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9194 - acc: 0.4062\n",
      "Epoch 00012: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9193 - acc: 0.4061 - val_loss: 2.7588 - val_acc: 0.2192\n",
      "Epoch 13/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8597 - acc: 0.4346\n",
      "Epoch 00013: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8598 - acc: 0.4346 - val_loss: 2.7671 - val_acc: 0.2012\n",
      "Epoch 14/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8114 - acc: 0.4358\n",
      "Epoch 00014: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8112 - acc: 0.4361 - val_loss: 2.7511 - val_acc: 0.1967\n",
      "Epoch 15/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7698 - acc: 0.4546\n",
      "Epoch 00015: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.7696 - acc: 0.4546 - val_loss: 2.7832 - val_acc: 0.2177\n",
      "Epoch 16/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8891 - acc: 0.4142\n",
      "Epoch 00016: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8890 - acc: 0.4142 - val_loss: 2.8555 - val_acc: 0.1967\n",
      "Epoch 17/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9380 - acc: 0.4025\n",
      "Epoch 00017: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9379 - acc: 0.4025 - val_loss: 2.8413 - val_acc: 0.1982\n",
      "Epoch 18/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0129 - acc: 0.3742\n",
      "Epoch 00018: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.0132 - acc: 0.3740 - val_loss: 2.8533 - val_acc: 0.1967\n",
      "Epoch 19/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9307 - acc: 0.4023\n",
      "Epoch 00019: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9303 - acc: 0.4025 - val_loss: 2.8656 - val_acc: 0.1907\n",
      "Epoch 20/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8616 - acc: 0.4181\n",
      "Epoch 00020: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8625 - acc: 0.4180 - val_loss: 2.7806 - val_acc: 0.2057\n",
      "Epoch 21/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8484 - acc: 0.4275\n",
      "Epoch 00021: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8478 - acc: 0.4277 - val_loss: 2.7754 - val_acc: 0.2222\n",
      "Epoch 22/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7491 - acc: 0.4596\n",
      "Epoch 00022: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7490 - acc: 0.4594 - val_loss: 2.7961 - val_acc: 0.2087\n",
      "Epoch 23/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7223 - acc: 0.4654\n",
      "Epoch 00023: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.7221 - acc: 0.4654 - val_loss: 2.7552 - val_acc: 0.2162\n",
      "Epoch 24/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7021 - acc: 0.4721\n",
      "Epoch 00024: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7024 - acc: 0.4719 - val_loss: 2.7947 - val_acc: 0.2012\n",
      "Epoch 25/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6709 - acc: 0.4817\n",
      "Epoch 00025: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6713 - acc: 0.4817 - val_loss: 2.8973 - val_acc: 0.2012\n",
      "Epoch 26/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7196 - acc: 0.4602\n",
      "Epoch 00026: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7198 - acc: 0.4602 - val_loss: 2.8423 - val_acc: 0.2012\n",
      "Epoch 27/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1586 - acc: 0.3698\n",
      "Epoch 00027: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.1582 - acc: 0.3701 - val_loss: 2.8268 - val_acc: 0.2042\n",
      "Epoch 28/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0237 - acc: 0.3740\n",
      "Epoch 00028: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.0237 - acc: 0.3738 - val_loss: 2.8228 - val_acc: 0.2042\n",
      "Epoch 29/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1026 - acc: 0.3623\n",
      "Epoch 00029: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.1022 - acc: 0.3626 - val_loss: 2.8329 - val_acc: 0.1907\n",
      "Epoch 30/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9001 - acc: 0.4125\n",
      "Epoch 00030: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9004 - acc: 0.4123 - val_loss: 2.8240 - val_acc: 0.1937\n",
      "Epoch 31/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8133 - acc: 0.4346\n",
      "Epoch 00031: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8127 - acc: 0.4348 - val_loss: 2.8008 - val_acc: 0.1937\n",
      "Epoch 32/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7506 - acc: 0.4621\n",
      "Epoch 00032: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7505 - acc: 0.4619 - val_loss: 2.9262 - val_acc: 0.1847\n",
      "Epoch 33/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0558 - acc: 0.3625\n",
      "Epoch 00033: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.0563 - acc: 0.3623 - val_loss: 2.8398 - val_acc: 0.2027\n",
      "Epoch 34/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8814 - acc: 0.4242\n",
      "Epoch 00034: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8810 - acc: 0.4242 - val_loss: 2.8412 - val_acc: 0.2027\n",
      "Epoch 35/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8218 - acc: 0.4317\n",
      "Epoch 00035: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8220 - acc: 0.4315 - val_loss: 2.8416 - val_acc: 0.2042\n",
      "Epoch 36/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7554 - acc: 0.4650\n",
      "Epoch 00036: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7555 - acc: 0.4648 - val_loss: 2.8313 - val_acc: 0.2087\n",
      "Epoch 37/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6949 - acc: 0.4706\n",
      "Epoch 00037: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6948 - acc: 0.4704 - val_loss: 2.8083 - val_acc: 0.2147\n",
      "Epoch 38/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6313 - acc: 0.4917\n",
      "Epoch 00038: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.6316 - acc: 0.4915 - val_loss: 2.8524 - val_acc: 0.1997\n",
      "Epoch 39/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6011 - acc: 0.5077\n",
      "Epoch 00039: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.6010 - acc: 0.5079 - val_loss: 2.8392 - val_acc: 0.1862\n",
      "Epoch 40/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6003 - acc: 0.5069\n",
      "Epoch 00040: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.6001 - acc: 0.5071 - val_loss: 2.8706 - val_acc: 0.1907\n",
      "Epoch 41/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5267 - acc: 0.5310\n",
      "Epoch 00041: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5272 - acc: 0.5308 - val_loss: 2.8894 - val_acc: 0.1892\n",
      "Epoch 42/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6078 - acc: 0.5040\n",
      "Epoch 00042: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6078 - acc: 0.5040 - val_loss: 2.9517 - val_acc: 0.1967\n",
      "Epoch 43/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8979 - acc: 0.4146\n",
      "Epoch 00043: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8978 - acc: 0.4146 - val_loss: 2.8996 - val_acc: 0.1832\n",
      "Epoch 44/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6398 - acc: 0.4917\n",
      "Epoch 00044: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.6401 - acc: 0.4915 - val_loss: 2.9302 - val_acc: 0.2057\n",
      "Epoch 45/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5622 - acc: 0.5165\n",
      "Epoch 00045: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5621 - acc: 0.5165 - val_loss: 2.9197 - val_acc: 0.1982\n",
      "Epoch 46/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4880 - acc: 0.5465\n",
      "Epoch 00046: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.4877 - acc: 0.5466 - val_loss: 2.9486 - val_acc: 0.1907\n",
      "Epoch 47/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4447 - acc: 0.5619\n",
      "Epoch 00047: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.4446 - acc: 0.5618 - val_loss: 2.9611 - val_acc: 0.1982\n",
      "Epoch 48/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4881 - acc: 0.5398\n",
      "Epoch 00048: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.4877 - acc: 0.5400 - val_loss: 2.9296 - val_acc: 0.2027\n",
      "Epoch 49/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5664 - acc: 0.5379\n",
      "Epoch 00049: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.5668 - acc: 0.5379 - val_loss: 3.0263 - val_acc: 0.2027\n",
      "Epoch 50/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5475 - acc: 0.5240\n",
      "Epoch 00050: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5478 - acc: 0.5239 - val_loss: 2.9369 - val_acc: 0.2237\n",
      "Epoch 51/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4400 - acc: 0.5565\n",
      "Epoch 00051: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.4398 - acc: 0.5566 - val_loss: 2.8790 - val_acc: 0.2057\n",
      "Epoch 52/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3506 - acc: 0.5958\n",
      "Epoch 00052: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.3503 - acc: 0.5958 - val_loss: 2.9453 - val_acc: 0.2207\n",
      "Epoch 53/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3122 - acc: 0.5960\n",
      "Epoch 00053: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.3123 - acc: 0.5962 - val_loss: 2.9550 - val_acc: 0.2087\n",
      "Epoch 54/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2933 - acc: 0.6087\n",
      "Epoch 00054: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.2938 - acc: 0.6087 - val_loss: 3.0230 - val_acc: 0.2147\n",
      "Epoch 55/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3792 - acc: 0.5783\n",
      "Epoch 00055: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.3796 - acc: 0.5783 - val_loss: 3.0507 - val_acc: 0.2012\n",
      "Epoch 56/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8032 - acc: 0.4458\n",
      "Epoch 00056: val_loss did not improve from 2.70716\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8031 - acc: 0.4456 - val_loss: 3.0221 - val_acc: 0.1922\n",
      "Training time: 531.2479496002197 s\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 2.0953 - acc: 0.3508\n",
      "Fold: 4\n",
      "\n",
      "Train on 4802 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0468 - acc: 0.3713\n",
      "Epoch 00001: val_loss improved from inf to 2.71080, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_4.hdf5\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.0469 - acc: 0.3713 - val_loss: 2.7108 - val_acc: 0.2042\n",
      "Epoch 2/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0113 - acc: 0.3802\n",
      "Epoch 00002: val_loss did not improve from 2.71080\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.0109 - acc: 0.3805 - val_loss: 2.7348 - val_acc: 0.2012\n",
      "Epoch 3/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1684 - acc: 0.3462\n",
      "Epoch 00003: val_loss did not improve from 2.71080\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.1680 - acc: 0.3465 - val_loss: 2.7302 - val_acc: 0.2117\n",
      "Epoch 4/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0288 - acc: 0.3783\n",
      "Epoch 00004: val_loss improved from 2.71080 to 2.70022, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_4.hdf5\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.0293 - acc: 0.3784 - val_loss: 2.7002 - val_acc: 0.2192\n",
      "Epoch 5/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9803 - acc: 0.3969\n",
      "Epoch 00005: val_loss did not improve from 2.70022\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9807 - acc: 0.3967 - val_loss: 2.7071 - val_acc: 0.2132\n",
      "Epoch 6/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9848 - acc: 0.3913\n",
      "Epoch 00006: val_loss did not improve from 2.70022\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9843 - acc: 0.3915 - val_loss: 2.7201 - val_acc: 0.2072\n",
      "Epoch 7/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9229 - acc: 0.4077\n",
      "Epoch 00007: val_loss improved from 2.70022 to 2.66695, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_4.hdf5\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9231 - acc: 0.4075 - val_loss: 2.6669 - val_acc: 0.2237\n",
      "Epoch 8/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9035 - acc: 0.4165\n",
      "Epoch 00008: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9038 - acc: 0.4163 - val_loss: 2.7456 - val_acc: 0.2072\n",
      "Epoch 9/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8467 - acc: 0.4294\n",
      "Epoch 00009: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8468 - acc: 0.4294 - val_loss: 2.7461 - val_acc: 0.2207\n",
      "Epoch 10/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8175 - acc: 0.4465\n",
      "Epoch 00010: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8171 - acc: 0.4467 - val_loss: 2.7580 - val_acc: 0.2072\n",
      "Epoch 11/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7843 - acc: 0.4577\n",
      "Epoch 00011: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.7842 - acc: 0.4577 - val_loss: 2.7666 - val_acc: 0.2192\n",
      "Epoch 12/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9544 - acc: 0.3996\n",
      "Epoch 00012: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9547 - acc: 0.3994 - val_loss: 2.8064 - val_acc: 0.1967\n",
      "Epoch 13/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1131 - acc: 0.3565\n",
      "Epoch 00013: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.1138 - acc: 0.3563 - val_loss: 2.8424 - val_acc: 0.1817\n",
      "Epoch 14/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9704 - acc: 0.3948\n",
      "Epoch 00014: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9700 - acc: 0.3950 - val_loss: 2.8038 - val_acc: 0.1982\n",
      "Epoch 15/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8505 - acc: 0.4290\n",
      "Epoch 00015: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8504 - acc: 0.4288 - val_loss: 2.7674 - val_acc: 0.1922\n",
      "Epoch 16/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8357 - acc: 0.4331\n",
      "Epoch 00016: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8353 - acc: 0.4334 - val_loss: 2.7467 - val_acc: 0.1997\n",
      "Epoch 17/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7385 - acc: 0.4648\n",
      "Epoch 00017: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7383 - acc: 0.4648 - val_loss: 2.7722 - val_acc: 0.2072\n",
      "Epoch 18/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8552 - acc: 0.4246\n",
      "Epoch 00018: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8558 - acc: 0.4244 - val_loss: 2.7755 - val_acc: 0.1967\n",
      "Epoch 19/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7734 - acc: 0.4535\n",
      "Epoch 00019: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7735 - acc: 0.4534 - val_loss: 2.8038 - val_acc: 0.2087\n",
      "Epoch 20/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7617 - acc: 0.4621\n",
      "Epoch 00020: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7614 - acc: 0.4621 - val_loss: 2.7942 - val_acc: 0.2072\n",
      "Epoch 21/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7353 - acc: 0.4590\n",
      "Epoch 00021: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7348 - acc: 0.4592 - val_loss: 2.8213 - val_acc: 0.2042\n",
      "Epoch 22/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6848 - acc: 0.4888\n",
      "Epoch 00022: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6844 - acc: 0.4888 - val_loss: 2.8260 - val_acc: 0.2162\n",
      "Epoch 23/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6086 - acc: 0.5004\n",
      "Epoch 00023: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.6087 - acc: 0.5002 - val_loss: 2.8195 - val_acc: 0.2177\n",
      "Epoch 24/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6498 - acc: 0.4904\n",
      "Epoch 00024: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6495 - acc: 0.4904 - val_loss: 2.8341 - val_acc: 0.2027\n",
      "Epoch 25/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6462 - acc: 0.4898\n",
      "Epoch 00025: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.6461 - acc: 0.4898 - val_loss: 2.8902 - val_acc: 0.1922\n",
      "Epoch 26/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5709 - acc: 0.5133\n",
      "Epoch 00026: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.5710 - acc: 0.5133 - val_loss: 2.8292 - val_acc: 0.2267\n",
      "Epoch 27/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6952 - acc: 0.4794\n",
      "Epoch 00027: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6947 - acc: 0.4796 - val_loss: 2.9218 - val_acc: 0.1892\n",
      "Epoch 28/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6254 - acc: 0.5063\n",
      "Epoch 00028: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.6255 - acc: 0.5060 - val_loss: 2.8795 - val_acc: 0.1982\n",
      "Epoch 29/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5014 - acc: 0.5406\n",
      "Epoch 00029: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5012 - acc: 0.5408 - val_loss: 2.8749 - val_acc: 0.1982\n",
      "Epoch 30/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4475 - acc: 0.5648\n",
      "Epoch 00030: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.4483 - acc: 0.5646 - val_loss: 2.9072 - val_acc: 0.2027\n",
      "Epoch 31/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4952 - acc: 0.5494\n",
      "Epoch 00031: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.4954 - acc: 0.5494 - val_loss: 2.9626 - val_acc: 0.1802\n",
      "Epoch 32/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7385 - acc: 0.4613\n",
      "Epoch 00032: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.7385 - acc: 0.4613 - val_loss: 3.0016 - val_acc: 0.1967\n",
      "Epoch 33/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8556 - acc: 0.4342\n",
      "Epoch 00033: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8556 - acc: 0.4342 - val_loss: 2.9963 - val_acc: 0.1847\n",
      "Epoch 34/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6174 - acc: 0.5075\n",
      "Epoch 00034: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6177 - acc: 0.5075 - val_loss: 2.9535 - val_acc: 0.1832\n",
      "Epoch 35/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5484 - acc: 0.5219\n",
      "Epoch 00035: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5484 - acc: 0.5219 - val_loss: 2.9441 - val_acc: 0.1952\n",
      "Epoch 36/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4443 - acc: 0.5708\n",
      "Epoch 00036: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.4442 - acc: 0.5708 - val_loss: 2.9479 - val_acc: 0.1937\n",
      "Epoch 37/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3862 - acc: 0.5885\n",
      "Epoch 00037: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.3861 - acc: 0.5885 - val_loss: 2.9786 - val_acc: 0.1982\n",
      "Epoch 38/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3678 - acc: 0.5900\n",
      "Epoch 00038: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.3680 - acc: 0.5900 - val_loss: 2.9511 - val_acc: 0.2102\n",
      "Epoch 39/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3104 - acc: 0.6117\n",
      "Epoch 00039: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.3114 - acc: 0.6116 - val_loss: 2.9736 - val_acc: 0.2027\n",
      "Epoch 40/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2765 - acc: 0.6250\n",
      "Epoch 00040: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2763 - acc: 0.6249 - val_loss: 3.0039 - val_acc: 0.1952\n",
      "Epoch 41/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2693 - acc: 0.6244\n",
      "Epoch 00041: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2691 - acc: 0.6245 - val_loss: 3.0281 - val_acc: 0.2087\n",
      "Epoch 42/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2456 - acc: 0.6215\n",
      "Epoch 00042: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2453 - acc: 0.6216 - val_loss: 3.0480 - val_acc: 0.2117\n",
      "Epoch 43/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2172 - acc: 0.6379\n",
      "Epoch 00043: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.2172 - acc: 0.6379 - val_loss: 3.0680 - val_acc: 0.2042\n",
      "Epoch 44/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2180 - acc: 0.6313\n",
      "Epoch 00044: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2182 - acc: 0.6312 - val_loss: 3.1101 - val_acc: 0.1892\n",
      "Epoch 45/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2662 - acc: 0.6177\n",
      "Epoch 00045: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2659 - acc: 0.6179 - val_loss: 3.0552 - val_acc: 0.2207\n",
      "Epoch 46/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2532 - acc: 0.6185\n",
      "Epoch 00046: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.2531 - acc: 0.6185 - val_loss: 3.1471 - val_acc: 0.1967\n",
      "Epoch 47/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3791 - acc: 0.5910\n",
      "Epoch 00047: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.3788 - acc: 0.5912 - val_loss: 3.1709 - val_acc: 0.1997\n",
      "Epoch 48/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6567 - acc: 0.5042\n",
      "Epoch 00048: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6566 - acc: 0.5042 - val_loss: 3.0922 - val_acc: 0.1892\n",
      "Epoch 49/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4271 - acc: 0.5590\n",
      "Epoch 00049: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.4267 - acc: 0.5591 - val_loss: 3.0695 - val_acc: 0.2027\n",
      "Epoch 50/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2493 - acc: 0.6269\n",
      "Epoch 00050: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.2490 - acc: 0.6270 - val_loss: 3.0898 - val_acc: 0.2042\n",
      "Epoch 51/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3430 - acc: 0.5935\n",
      "Epoch 00051: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.3435 - acc: 0.5933 - val_loss: 3.0870 - val_acc: 0.1652\n",
      "Epoch 52/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3166 - acc: 0.5950\n",
      "Epoch 00052: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.3167 - acc: 0.5950 - val_loss: 3.0879 - val_acc: 0.1952\n",
      "Epoch 53/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2605 - acc: 0.6194\n",
      "Epoch 00053: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.2601 - acc: 0.6195 - val_loss: 3.1285 - val_acc: 0.1802\n",
      "Epoch 54/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.1635 - acc: 0.6510\n",
      "Epoch 00054: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.1633 - acc: 0.6512 - val_loss: 3.0947 - val_acc: 0.2012\n",
      "Epoch 55/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.0685 - acc: 0.6944\n",
      "Epoch 00055: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.0683 - acc: 0.6945 - val_loss: 3.1842 - val_acc: 0.1907\n",
      "Epoch 56/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2076 - acc: 0.6325\n",
      "Epoch 00056: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2078 - acc: 0.6324 - val_loss: 3.1433 - val_acc: 0.1922\n",
      "Epoch 57/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.1461 - acc: 0.6606\n",
      "Epoch 00057: val_loss did not improve from 2.66695\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.1463 - acc: 0.6606 - val_loss: 3.2653 - val_acc: 0.1787\n",
      "Training time: 541.3875563144684 s\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 2.0779 - acc: 0.3367\n",
      "Fold: 5\n",
      "\n",
      "Train on 4802 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0925 - acc: 0.3600\n",
      "Epoch 00001: val_loss improved from inf to 2.73161, saving model to /home/dorads/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-LSTM_5.hdf5\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.0926 - acc: 0.3601 - val_loss: 2.7316 - val_acc: 0.1952\n",
      "Epoch 2/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0307 - acc: 0.3767\n",
      "Epoch 00002: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.0304 - acc: 0.3769 - val_loss: 2.9001 - val_acc: 0.1697\n",
      "Epoch 3/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1041 - acc: 0.3610\n",
      "Epoch 00003: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 2.1040 - acc: 0.3609 - val_loss: 2.8025 - val_acc: 0.1877\n",
      "Epoch 4/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9927 - acc: 0.3852\n",
      "Epoch 00004: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9927 - acc: 0.3850 - val_loss: 2.7873 - val_acc: 0.1937\n",
      "Epoch 5/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9206 - acc: 0.4054\n",
      "Epoch 00005: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9205 - acc: 0.4052 - val_loss: 2.7632 - val_acc: 0.2072\n",
      "Epoch 6/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8965 - acc: 0.4060\n",
      "Epoch 00006: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8967 - acc: 0.4059 - val_loss: 2.7979 - val_acc: 0.1742\n",
      "Epoch 7/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0607 - acc: 0.3638\n",
      "Epoch 00007: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 2.0608 - acc: 0.3638 - val_loss: 2.7996 - val_acc: 0.1967\n",
      "Epoch 8/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9364 - acc: 0.3967\n",
      "Epoch 00008: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9362 - acc: 0.3967 - val_loss: 2.7564 - val_acc: 0.1892\n",
      "Epoch 9/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8611 - acc: 0.4279\n",
      "Epoch 00009: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8610 - acc: 0.4277 - val_loss: 2.7943 - val_acc: 0.2057\n",
      "Epoch 10/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8507 - acc: 0.4242\n",
      "Epoch 00010: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8509 - acc: 0.4242 - val_loss: 2.8217 - val_acc: 0.1997\n",
      "Epoch 11/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8304 - acc: 0.4265\n",
      "Epoch 00011: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8303 - acc: 0.4265 - val_loss: 2.8018 - val_acc: 0.1802\n",
      "Epoch 12/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8866 - acc: 0.4200\n",
      "Epoch 00012: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8873 - acc: 0.4198 - val_loss: 2.8325 - val_acc: 0.1922\n",
      "Epoch 13/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8409 - acc: 0.4331\n",
      "Epoch 00013: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8405 - acc: 0.4334 - val_loss: 2.8249 - val_acc: 0.1967\n",
      "Epoch 14/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7464 - acc: 0.4575\n",
      "Epoch 00014: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7464 - acc: 0.4573 - val_loss: 2.8325 - val_acc: 0.1817\n",
      "Epoch 15/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7712 - acc: 0.4567\n",
      "Epoch 00015: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7715 - acc: 0.4567 - val_loss: 2.8264 - val_acc: 0.1832\n",
      "Epoch 16/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7776 - acc: 0.4500\n",
      "Epoch 00016: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.7774 - acc: 0.4500 - val_loss: 2.8336 - val_acc: 0.2042\n",
      "Epoch 17/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9086 - acc: 0.4248\n",
      "Epoch 00017: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9084 - acc: 0.4248 - val_loss: 2.8498 - val_acc: 0.1832\n",
      "Epoch 18/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8184 - acc: 0.4375\n",
      "Epoch 00018: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.8184 - acc: 0.4375 - val_loss: 2.9217 - val_acc: 0.1727\n",
      "Epoch 19/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9964 - acc: 0.3840\n",
      "Epoch 00019: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.9964 - acc: 0.3838 - val_loss: 2.8261 - val_acc: 0.1967\n",
      "Epoch 20/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8171 - acc: 0.4402\n",
      "Epoch 00020: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8171 - acc: 0.4402 - val_loss: 2.8395 - val_acc: 0.1862\n",
      "Epoch 21/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6950 - acc: 0.4821\n",
      "Epoch 00021: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6953 - acc: 0.4819 - val_loss: 2.8506 - val_acc: 0.1832\n",
      "Epoch 22/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6577 - acc: 0.4910\n",
      "Epoch 00022: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6577 - acc: 0.4910 - val_loss: 2.8579 - val_acc: 0.1802\n",
      "Epoch 23/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7164 - acc: 0.4694\n",
      "Epoch 00023: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.7161 - acc: 0.4694 - val_loss: 2.9015 - val_acc: 0.1697\n",
      "Epoch 24/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6175 - acc: 0.5113\n",
      "Epoch 00024: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.6178 - acc: 0.5112 - val_loss: 2.9003 - val_acc: 0.1952\n",
      "Epoch 25/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5722 - acc: 0.5185\n",
      "Epoch 00025: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5722 - acc: 0.5185 - val_loss: 2.9250 - val_acc: 0.1997\n",
      "Epoch 26/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5616 - acc: 0.5292\n",
      "Epoch 00026: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5618 - acc: 0.5292 - val_loss: 2.8521 - val_acc: 0.1952\n",
      "Epoch 27/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5563 - acc: 0.5240\n",
      "Epoch 00027: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5564 - acc: 0.5239 - val_loss: 2.9260 - val_acc: 0.1907\n",
      "Epoch 28/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5863 - acc: 0.5154\n",
      "Epoch 00028: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.5865 - acc: 0.5152 - val_loss: 2.9269 - val_acc: 0.2087\n",
      "Epoch 29/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9703 - acc: 0.4073\n",
      "Epoch 00029: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.9700 - acc: 0.4073 - val_loss: 2.9704 - val_acc: 0.1982\n",
      "Epoch 30/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8166 - acc: 0.4363\n",
      "Epoch 00030: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.8163 - acc: 0.4363 - val_loss: 2.9169 - val_acc: 0.1997\n",
      "Epoch 31/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6483 - acc: 0.4990\n",
      "Epoch 00031: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.6481 - acc: 0.4992 - val_loss: 2.8786 - val_acc: 0.1997\n",
      "Epoch 32/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5887 - acc: 0.5150\n",
      "Epoch 00032: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5886 - acc: 0.5150 - val_loss: 2.9720 - val_acc: 0.2117\n",
      "Epoch 33/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5852 - acc: 0.5146\n",
      "Epoch 00033: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5858 - acc: 0.5146 - val_loss: 2.9527 - val_acc: 0.1832\n",
      "Epoch 34/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5744 - acc: 0.5204\n",
      "Epoch 00034: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5741 - acc: 0.5206 - val_loss: 2.9960 - val_acc: 0.1982\n",
      "Epoch 35/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4977 - acc: 0.5354\n",
      "Epoch 00035: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.4981 - acc: 0.5354 - val_loss: 2.9651 - val_acc: 0.1892\n",
      "Epoch 36/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4983 - acc: 0.5385\n",
      "Epoch 00036: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.4988 - acc: 0.5383 - val_loss: 2.9338 - val_acc: 0.1817\n",
      "Epoch 37/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3916 - acc: 0.5815\n",
      "Epoch 00037: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.3916 - acc: 0.5814 - val_loss: 2.9279 - val_acc: 0.2072\n",
      "Epoch 38/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3360 - acc: 0.6042\n",
      "Epoch 00038: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.3356 - acc: 0.6043 - val_loss: 2.9452 - val_acc: 0.2087\n",
      "Epoch 39/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3080 - acc: 0.6042\n",
      "Epoch 00039: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.3078 - acc: 0.6043 - val_loss: 2.9834 - val_acc: 0.1982\n",
      "Epoch 40/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2415 - acc: 0.6237\n",
      "Epoch 00040: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2412 - acc: 0.6239 - val_loss: 3.0219 - val_acc: 0.2102\n",
      "Epoch 41/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2650 - acc: 0.6356\n",
      "Epoch 00041: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2649 - acc: 0.6358 - val_loss: 3.0191 - val_acc: 0.1967\n",
      "Epoch 42/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2853 - acc: 0.6167\n",
      "Epoch 00042: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2858 - acc: 0.6164 - val_loss: 3.0515 - val_acc: 0.1982\n",
      "Epoch 43/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2852 - acc: 0.6054\n",
      "Epoch 00043: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.2860 - acc: 0.6052 - val_loss: 3.0846 - val_acc: 0.1892\n",
      "Epoch 44/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5202 - acc: 0.5275\n",
      "Epoch 00044: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.5198 - acc: 0.5277 - val_loss: 3.0604 - val_acc: 0.1832\n",
      "Epoch 45/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4148 - acc: 0.5654\n",
      "Epoch 00045: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.4153 - acc: 0.5652 - val_loss: 3.0156 - val_acc: 0.1907\n",
      "Epoch 46/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5718 - acc: 0.5110\n",
      "Epoch 00046: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.5719 - acc: 0.5108 - val_loss: 3.0353 - val_acc: 0.1997\n",
      "Epoch 47/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4203 - acc: 0.5629\n",
      "Epoch 00047: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.4198 - acc: 0.5631 - val_loss: 3.0697 - val_acc: 0.2012\n",
      "Epoch 48/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2482 - acc: 0.6231\n",
      "Epoch 00048: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.2479 - acc: 0.6233 - val_loss: 3.0397 - val_acc: 0.1892\n",
      "Epoch 49/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.1737 - acc: 0.6556\n",
      "Epoch 00049: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 10s 2ms/sample - loss: 1.1737 - acc: 0.6556 - val_loss: 3.0773 - val_acc: 0.2057\n",
      "Epoch 50/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3424 - acc: 0.5919\n",
      "Epoch 00050: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.3423 - acc: 0.5918 - val_loss: 3.0990 - val_acc: 0.2027\n",
      "Epoch 51/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3150 - acc: 0.6031\n",
      "Epoch 00051: val_loss did not improve from 2.73161\n",
      "4802/4802 [==============================] - 9s 2ms/sample - loss: 1.3145 - acc: 0.6033 - val_loss: 3.0932 - val_acc: 0.1982\n",
      "Training time: 482.9667212963104 s\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 1.8539 - acc: 0.4242\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.abspath(os.path.join('models', dataset))):\n",
    "    os.mkdir(os.path.abspath(os.path.join('models', dataset)))\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "sdk = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "n_fold = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "epoch_per_fold = []\n",
    "loss_per_fold = []\n",
    "rec_per_fold = []\n",
    "prec_per_fold = []\n",
    "f1_per_fold = []\n",
    "\n",
    "for train, test in sdk.split(x_all, y_all):\n",
    "    \n",
    "    file_path = os.path.abspath(os.path.join('models', dataset, f'{dataset}-LSTM_{n_fold}.hdf5'))\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=file_path, monitor='val_loss', save_best_only = True, mode = 'min', verbose = 1), \n",
    "        EarlyStopping(monitor = 'val_loss', patience = 50, mode = 'min')]\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    print(f\"Fold: {n_fold}\\n\")\n",
    "    result = model.fit(x_all[train], \n",
    "                       to_categorical(y_all[train]),\n",
    "                       epochs = 2000, \n",
    "                       batch_size = 100, \n",
    "                       validation_data = (x_valid, to_categorical(y_valid)), \n",
    "                       callbacks = callbacks)\n",
    "\n",
    "    print(f\"Training time: {time.time() - t} s\")\n",
    "\n",
    "    df_results = pd.DataFrame(result.history)\n",
    "    df_results.to_csv(os.path.abspath(os.path.join('models', dataset, f'LSTM_results_{n_fold}.csv')))\n",
    "    \n",
    "    model.load_weights(file_path)\n",
    "    scores = model.evaluate(x_all[test], to_categorical(y_all[test]))\n",
    "    loss_per_fold.append(scores[0])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    epoch_per_fold.append(np.argmin(result.history['val_loss']))\n",
    "    \n",
    "    # Computing predictions\n",
    "    y_pred_test = np.argmax(model.predict(x_all[test]), axis = 1)\n",
    "    \n",
    "    f1_per_fold.append(f1_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    rec_per_fold.append(recall_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    prec_per_fold.append(precision_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    \n",
    "    n_fold += 1\n",
    "    \n",
    "df_scores = pd.DataFrame(columns = ['F1', 'Loss', 'Accuracy', 'Precision', 'Recall'])\n",
    "df_scores['F1'] = f1_per_fold\n",
    "df_scores['Loss'] = loss_per_fold\n",
    "df_scores['Accuracy'] = acc_per_fold\n",
    "df_scores['Precision'] = prec_per_fold\n",
    "df_scores['Recall'] = rec_per_fold\n",
    "\n",
    "df_scores.to_csv(os.path.abspath(os.path.join('models', dataset, f'LSTM_results_k-Folds.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
