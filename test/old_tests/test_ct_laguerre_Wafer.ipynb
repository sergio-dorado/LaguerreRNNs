{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures_v1 import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, roc_auc_score\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training/Testing/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Instances: 716\n",
      "x_all: (6448, 152, 1) - y_all: (6448,)\n",
      "x_valid: (716, 152, 1) - y_valid: (716,)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Wafer\"\n",
    "model_name = \"laguerre\"\n",
    "\n",
    "x_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_train.npz')))\n",
    "x_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_test.npz')))\n",
    "\n",
    "x_train = np.reshape(x_train_load['arr_0'], [x_train_load['arr_0'].shape[0], x_train_load['arr_0'].shape[1], 1])\n",
    "x_test = np.reshape(x_test_load['arr_0'], [x_test_load['arr_0'].shape[0], x_test_load['arr_0'].shape[1], 1])\n",
    "\n",
    "x_all = np.concatenate((x_train, x_test), axis = 0)\n",
    "\n",
    "n_instances = x_all.shape[0]\n",
    "\n",
    "y_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_train.npz')))\n",
    "y_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_test.npz')))\n",
    "\n",
    "y_train = y_train_load['arr_0']\n",
    "y_test = y_test_load['arr_0']\n",
    "\n",
    "y_all = np.concatenate((y_train, y_test), axis = 0)\n",
    "y_all = np.asarray(y_all, dtype = np.uint64)\n",
    "\n",
    "n_validation = int(0.1*n_instances)\n",
    "print(f\"Validation Instances: {n_validation}\")\n",
    "\n",
    "ind_validation = random.sample(range(0, n_instances), n_validation)\n",
    "x_valid = x_all[ind_validation, :, :]\n",
    "y_valid = y_all[ind_validation]\n",
    "\n",
    "x_all = np.delete(x_all, ind_validation, axis = 0)\n",
    "y_all = np.delete(y_all, ind_validation, axis = 0)\n",
    "\n",
    "print(f\"x_all: {x_all.shape} - y_all: {y_all.shape}\")\n",
    "print(f\"x_valid: {x_valid.shape} - y_valid: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sergio.dorado/miniconda3/envs/sd_test_rnns/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn (RNN)                    (None, 212)               165691    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 426       \n",
      "=================================================================\n",
      "Total params: 166,117\n",
      "Trainable params: 100,323\n",
      "Non-trainable params: 65,794\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "length = x_all.shape[1]\n",
    "n_features = x_all.shape[-1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(RNN(OrthogonalCell(units = 212,\n",
    "                             order = 256,\n",
    "                             variant = 'ct_laguerre',\n",
    "                             dt = 1,\n",
    "                            input_dims = n_features), \n",
    "              input_shape = (length, n_features),\n",
    "             return_sequences = False))\n",
    "model.add(Dense(to_categorical(y_all).shape[-1], activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "\n",
      "Train on 5158 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9992\n",
      "Epoch 00001: val_loss improved from inf to 0.00436, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 8s 2ms/sample - loss: 0.0049 - acc: 0.9992 - val_loss: 0.0044 - val_acc: 0.9986\n",
      "Epoch 2/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 00002: val_loss improved from 0.00436 to 0.00314, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 9s 2ms/sample - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0031 - val_acc: 0.9986\n",
      "Epoch 3/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 00003: val_loss improved from 0.00314 to 0.00186, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 10s 2ms/sample - loss: 0.0021 - acc: 0.9998 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 4/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00004: val_loss did not improve from 0.00186\n",
      "5158/5158 [==============================] - 10s 2ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0025 - val_acc: 0.9986\n",
      "Epoch 5/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00005: val_loss improved from 0.00186 to 0.00129, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 10s 2ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 6/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 9.7225e-04 - acc: 0.9998\n",
      "Epoch 00006: val_loss improved from 0.00129 to 0.00121, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 11s 2ms/sample - loss: 9.6448e-04 - acc: 0.9998 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 7/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 7.2131e-04 - acc: 0.9998\n",
      "Epoch 00007: val_loss did not improve from 0.00121\n",
      "5158/5158 [==============================] - 10s 2ms/sample - loss: 7.1646e-04 - acc: 0.9998 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 8/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 5.4588e-04 - acc: 1.0000\n",
      "Epoch 00008: val_loss improved from 0.00121 to 0.00087, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 10s 2ms/sample - loss: 5.4726e-04 - acc: 1.0000 - val_loss: 8.7019e-04 - val_acc: 1.0000\n",
      "Epoch 9/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 4.9734e-04 - acc: 0.9998\n",
      "Epoch 00009: val_loss improved from 0.00087 to 0.00081, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 9s 2ms/sample - loss: 4.9223e-04 - acc: 0.9998 - val_loss: 8.0568e-04 - val_acc: 1.0000\n",
      "Epoch 10/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 3.5337e-04 - acc: 1.0000\n",
      "Epoch 00010: val_loss improved from 0.00081 to 0.00078, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 10s 2ms/sample - loss: 3.5059e-04 - acc: 1.0000 - val_loss: 7.8152e-04 - val_acc: 1.0000\n",
      "Epoch 11/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 2.3984e-04 - acc: 1.0000\n",
      "Epoch 00011: val_loss improved from 0.00078 to 0.00040, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 9s 2ms/sample - loss: 2.4005e-04 - acc: 1.0000 - val_loss: 3.9967e-04 - val_acc: 1.0000\n",
      "Epoch 12/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 2.4018e-04 - acc: 1.0000\n",
      "Epoch 00012: val_loss improved from 0.00040 to 0.00035, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 9s 2ms/sample - loss: 2.3793e-04 - acc: 1.0000 - val_loss: 3.5128e-04 - val_acc: 1.0000\n",
      "Epoch 13/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 1.7479e-04 - acc: 1.0000\n",
      "Epoch 00013: val_loss improved from 0.00035 to 0.00030, saving model to /Users/sergio.dorado/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/Wafer/Wafer-laguerre_1.hdf5\n",
      "5158/5158 [==============================] - 9s 2ms/sample - loss: 1.7712e-04 - acc: 1.0000 - val_loss: 2.9934e-04 - val_acc: 1.0000\n",
      "Epoch 14/200\n",
      "4500/5158 [=========================>....] - ETA: 1s - loss: 1.5648e-04 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d3a0f50c7643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                        \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                        \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                        callbacks = callbacks)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training time: {time.time() - t} s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sd_test_rnns/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/sd_test_rnns/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/sd_test_rnns/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sd_test_rnns/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/miniconda3/envs/sd_test_rnns/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.abspath(os.path.join('models', dataset))):\n",
    "    os.mkdir(os.path.abspath(os.path.join('models', dataset)))\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "sdk = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "df_tpr = pd.DataFrame(columns = [1, 2, 3, 4, 5])\n",
    "df_fpr = pd.DataFrame(columns = [1, 2, 3, 4, 5])\n",
    "\n",
    "n_fold = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "epoch_per_fold = []\n",
    "loss_per_fold = []\n",
    "rec_per_fold = []\n",
    "prec_per_fold = []\n",
    "f1_per_fold = []\n",
    "auroc_per_fold = []\n",
    "fpr_per_fold = []\n",
    "tpr_per_fold = []\n",
    "\n",
    "for train, test in sdk.split(x_all, y_all):\n",
    "    \n",
    "    file_path = os.path.abspath(os.path.join('models', dataset, f'{dataset}-{model_name}_{n_fold}.hdf5'))\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=file_path, monitor='val_loss', save_best_only = True, mode = 'min', verbose = 1), \n",
    "        EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min')]\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    print(f\"\\nFold: {n_fold}\\n\")\n",
    "    result = model.fit(x_all[train], \n",
    "                       to_categorical(y_all[train]),\n",
    "                       epochs = 200, \n",
    "                       batch_size = 100, \n",
    "                       validation_data = (x_valid, to_categorical(y_valid)), \n",
    "                       callbacks = callbacks)\n",
    "\n",
    "    print(f\"Training time: {time.time() - t} s\")\n",
    "\n",
    "    df_results = pd.DataFrame(result.history)\n",
    "    df_results.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_{n_fold}.csv')))\n",
    "    \n",
    "    model.load_weights(file_path)\n",
    "    scores = model.evaluate(x_all[test], to_categorical(y_all[test]))\n",
    "    loss_per_fold.append(scores[0])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    epoch_per_fold.append(np.argmin(result.history['val_loss']))\n",
    "    \n",
    "    # Computing predictions\n",
    "    y_pred_test = np.argmax(model.predict(x_all[test]), axis = 1)\n",
    "    \n",
    "    # Getting performance scores per fold\n",
    "    f1_per_fold.append(f1_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    rec_per_fold.append(recall_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    prec_per_fold.append(precision_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    auroc_per_fold.append(roc_auc_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    \n",
    "    # Getting ROC curve for this binary classification task\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_all[test], model.predict(x_all[test])[:,1])\n",
    "    \n",
    "    df_fpr[n_fold] = fpr\n",
    "    df_tpr[n_fold] = tpr\n",
    "        \n",
    "    n_fold += 1\n",
    "\n",
    "df_scores = pd.DataFrame(columns = ['F1', 'Loss', 'Accuracy', 'Precision', 'Recall', 'AUROC'])\n",
    "df_scores['F1'] = f1_per_fold\n",
    "df_scores['Loss'] = loss_per_fold\n",
    "df_scores['Accuracy'] = acc_per_fold\n",
    "df_scores['Precision'] = prec_per_fold\n",
    "df_scores['Recall'] = rec_per_fold\n",
    "df_scores['AUROC'] = auroc_per_fold\n",
    "\n",
    "df_scores.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds.csv')))\n",
    "df_tpr.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds_tpr.csv')))\n",
    "df_fpr.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds_fpr.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all[test].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffe1834eb10>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(fpr.shape)\n",
    "\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_all[test])[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.810608e-04, 9.996189e-01], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_all[test])[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
