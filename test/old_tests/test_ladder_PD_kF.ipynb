{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures_v1 import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training/Testing/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Instances: 6668\n",
      "Validation Instances: 666\n",
      "x_all: (6002, 217, 11) - y_all: (6002,)\n",
      "x_valid: (666, 217, 11) - y_valid: (666,)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"PhonemeSpectra\"\n",
    "\n",
    "x_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_train.npz')))\n",
    "x_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_test.npz')))\n",
    "\n",
    "x_train = x_train_load['arr_0']\n",
    "x_test = x_test_load['arr_0']\n",
    "\n",
    "x_all = np.concatenate((x_train, x_test), axis = 0)\n",
    "\n",
    "n_instances = x_all.shape[0]\n",
    "print(f\"Total Instances: {n_instances}\")\n",
    "\n",
    "y_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_train.npz')))\n",
    "y_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_test.npz')))\n",
    "\n",
    "y_train = np.asarray(y_train_load['arr_0'], dtype = np.uint64)\n",
    "y_test = np.asarray(y_test_load['arr_0'], dtype = np.uint64)\n",
    "\n",
    "y_all = np.concatenate((y_train, y_test), axis = 0)\n",
    "\n",
    "n_validation = int(0.1*n_instances)\n",
    "print(f\"Validation Instances: {n_validation}\")\n",
    "\n",
    "ind_validation = random.sample(range(0, n_instances), n_validation)\n",
    "x_valid = x_all[ind_validation, :, :]\n",
    "y_valid = y_all[ind_validation]\n",
    "\n",
    "x_all = np.delete(x_all, ind_validation, axis = 0)\n",
    "y_all = np.delete(y_all, ind_validation, axis = 0)\n",
    "\n",
    "print(f\"x_all: {x_all.shape} - y_all: {y_all.shape}\")\n",
    "print(f\"x_valid: {x_valid.shape} - y_valid: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/home/dorads/miniconda3/envs/sd_dev_tf_1/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn (RNN)                    (None, 212)               1654361   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 39)                8307      \n",
      "=================================================================\n",
      "Total params: 1,662,668\n",
      "Trainable params: 300,878\n",
      "Non-trainable params: 1,361,790\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "length = x_all.shape[1]\n",
    "n_features = x_all.shape[-1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(RNN(LadderCell(units = 212,\n",
    "                             max_delay = length,\n",
    "                             input_dims = n_features), \n",
    "              input_shape = (length, n_features),\n",
    "             return_sequences = False))\n",
    "model.add(Dense(to_categorical(y_all).shape[-1], activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "\n",
      "Train on 4801 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.7678 - acc: 0.0467\n",
      "Epoch 00001: val_loss improved from inf to 3.71312, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-ladder_1.hdf5\n",
      "4801/4801 [==============================] - 7s 2ms/sample - loss: 3.7680 - acc: 0.0467 - val_loss: 3.7131 - val_acc: 0.0420\n",
      "Epoch 2/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.4489 - acc: 0.0973\n",
      "Epoch 00002: val_loss improved from 3.71312 to 3.70231, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-ladder_1.hdf5\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 3.4489 - acc: 0.0973 - val_loss: 3.7023 - val_acc: 0.0526\n",
      "Epoch 3/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.3274 - acc: 0.1402\n",
      "Epoch 00003: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 3.3276 - acc: 0.1402 - val_loss: 3.7377 - val_acc: 0.0420\n",
      "Epoch 4/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.2325 - acc: 0.1612\n",
      "Epoch 00004: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 3.2322 - acc: 0.1614 - val_loss: 3.7561 - val_acc: 0.0541\n",
      "Epoch 5/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.1416 - acc: 0.1790\n",
      "Epoch 00005: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 3.1413 - acc: 0.1789 - val_loss: 3.7589 - val_acc: 0.0691\n",
      "Epoch 6/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.0404 - acc: 0.2144\n",
      "Epoch 00006: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 3.0402 - acc: 0.2143 - val_loss: 3.8057 - val_acc: 0.0480\n",
      "Epoch 7/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.9609 - acc: 0.2262\n",
      "Epoch 00007: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.9603 - acc: 0.2264 - val_loss: 3.7781 - val_acc: 0.0586\n",
      "Epoch 8/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7931 - acc: 0.2829\n",
      "Epoch 00008: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.7931 - acc: 0.2829 - val_loss: 3.7863 - val_acc: 0.0706\n",
      "Epoch 9/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7782 - acc: 0.2848\n",
      "Epoch 00009: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.7780 - acc: 0.2847 - val_loss: 3.7871 - val_acc: 0.0736\n",
      "Epoch 10/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6393 - acc: 0.3219\n",
      "Epoch 00010: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.6397 - acc: 0.3218 - val_loss: 3.8438 - val_acc: 0.0706\n",
      "Epoch 11/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6548 - acc: 0.3173\n",
      "Epoch 00011: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 2.6549 - acc: 0.3172 - val_loss: 3.8141 - val_acc: 0.0661\n",
      "Epoch 12/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.5072 - acc: 0.3587\n",
      "Epoch 00012: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.5073 - acc: 0.3587 - val_loss: 3.8615 - val_acc: 0.0616\n",
      "Epoch 13/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.4406 - acc: 0.3694\n",
      "Epoch 00013: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.4407 - acc: 0.3693 - val_loss: 3.8484 - val_acc: 0.0676\n",
      "Epoch 14/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3542 - acc: 0.3915\n",
      "Epoch 00014: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 2.3538 - acc: 0.3916 - val_loss: 3.9119 - val_acc: 0.0646\n",
      "Epoch 15/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2458 - acc: 0.4340\n",
      "Epoch 00015: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.2457 - acc: 0.4341 - val_loss: 3.9521 - val_acc: 0.0676\n",
      "Epoch 16/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2306 - acc: 0.4187\n",
      "Epoch 00016: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.2307 - acc: 0.4187 - val_loss: 3.9803 - val_acc: 0.0586\n",
      "Epoch 17/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1884 - acc: 0.4381\n",
      "Epoch 00017: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.1884 - acc: 0.4380 - val_loss: 3.9648 - val_acc: 0.0646\n",
      "Epoch 18/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0654 - acc: 0.4700\n",
      "Epoch 00018: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.0651 - acc: 0.4701 - val_loss: 3.9857 - val_acc: 0.0886\n",
      "Epoch 19/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9584 - acc: 0.4998\n",
      "Epoch 00019: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.9584 - acc: 0.4997 - val_loss: 4.0313 - val_acc: 0.0796\n",
      "Epoch 20/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8629 - acc: 0.5360\n",
      "Epoch 00020: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.8630 - acc: 0.5359 - val_loss: 4.1011 - val_acc: 0.0781\n",
      "Epoch 21/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9550 - acc: 0.5002\n",
      "Epoch 00021: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.9554 - acc: 0.5001 - val_loss: 4.1512 - val_acc: 0.0676\n",
      "Epoch 22/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7718 - acc: 0.5604\n",
      "Epoch 00022: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.7715 - acc: 0.5605 - val_loss: 4.1473 - val_acc: 0.0676\n",
      "Epoch 23/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.5172 - acc: 0.6515\n",
      "Epoch 00023: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.5171 - acc: 0.6515 - val_loss: 4.1648 - val_acc: 0.0766\n",
      "Epoch 24/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4845 - acc: 0.6546\n",
      "Epoch 00024: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4842 - acc: 0.6547 - val_loss: 4.2200 - val_acc: 0.0751\n",
      "Epoch 25/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.3192 - acc: 0.7042\n",
      "Epoch 00025: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.3194 - acc: 0.7040 - val_loss: 4.3190 - val_acc: 0.0676\n",
      "Epoch 26/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.5032 - acc: 0.6352\n",
      "Epoch 00026: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.5033 - acc: 0.6351 - val_loss: 4.2390 - val_acc: 0.0781\n",
      "Epoch 27/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4421 - acc: 0.6506\n",
      "Epoch 00027: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4420 - acc: 0.6507 - val_loss: 4.3420 - val_acc: 0.0631\n",
      "Epoch 28/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.3153 - acc: 0.6919\n",
      "Epoch 00028: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.3154 - acc: 0.6917 - val_loss: 4.4025 - val_acc: 0.0691\n",
      "Epoch 29/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.3821 - acc: 0.6725\n",
      "Epoch 00029: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.3825 - acc: 0.6724 - val_loss: 4.4010 - val_acc: 0.0721\n",
      "Epoch 30/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4150 - acc: 0.6517\n",
      "Epoch 00030: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4147 - acc: 0.6517 - val_loss: 4.4294 - val_acc: 0.0676\n",
      "Epoch 31/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.0369 - acc: 0.7944\n",
      "Epoch 00031: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.0371 - acc: 0.7942 - val_loss: 4.5431 - val_acc: 0.0646\n",
      "Epoch 32/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.2207 - acc: 0.7160\n",
      "Epoch 00032: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.2206 - acc: 0.7161 - val_loss: 4.5691 - val_acc: 0.0571\n",
      "Epoch 33/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.1124 - acc: 0.7542\n",
      "Epoch 00033: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.1122 - acc: 0.7542 - val_loss: 4.6528 - val_acc: 0.0631\n",
      "Epoch 34/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.8584 - acc: 0.8415\n",
      "Epoch 00034: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.8584 - acc: 0.8415 - val_loss: 4.6701 - val_acc: 0.0676\n",
      "Epoch 35/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.1686 - acc: 0.7125\n",
      "Epoch 00035: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.1687 - acc: 0.7124 - val_loss: 4.6207 - val_acc: 0.0586\n",
      "Epoch 36/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.0885 - acc: 0.7546\n",
      "Epoch 00036: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.0885 - acc: 0.7546 - val_loss: 4.6849 - val_acc: 0.0511\n",
      "Epoch 37/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.1783 - acc: 0.7110\n",
      "Epoch 00037: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.1782 - acc: 0.7111 - val_loss: 4.6942 - val_acc: 0.0601\n",
      "Epoch 38/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.9423 - acc: 0.8110\n",
      "Epoch 00038: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.9423 - acc: 0.8111 - val_loss: 4.6886 - val_acc: 0.0556\n",
      "Epoch 39/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.7841 - acc: 0.8608\n",
      "Epoch 00039: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.7840 - acc: 0.8609 - val_loss: 4.7939 - val_acc: 0.0646\n",
      "Epoch 40/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6386 - acc: 0.9023\n",
      "Epoch 00040: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6385 - acc: 0.9023 - val_loss: 4.8023 - val_acc: 0.0676\n",
      "Epoch 41/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.9050\n",
      "Epoch 00041: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6086 - acc: 0.9050 - val_loss: 4.8799 - val_acc: 0.0676\n",
      "Epoch 42/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6848 - acc: 0.8754\n",
      "Epoch 00042: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6850 - acc: 0.8752 - val_loss: 4.8955 - val_acc: 0.0571\n",
      "Epoch 43/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6332 - acc: 0.5440\n",
      "Epoch 00043: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.6333 - acc: 0.5438 - val_loss: 5.0006 - val_acc: 0.0586\n",
      "Epoch 44/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4881 - acc: 0.6004\n",
      "Epoch 00044: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4879 - acc: 0.6005 - val_loss: 4.8957 - val_acc: 0.0556\n",
      "Epoch 45/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.9812 - acc: 0.7775\n",
      "Epoch 00045: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.9811 - acc: 0.7775 - val_loss: 4.9292 - val_acc: 0.0586\n",
      "Epoch 46/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.9349 - acc: 0.7946\n",
      "Epoch 00046: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.9348 - acc: 0.7946 - val_loss: 4.9676 - val_acc: 0.0526\n",
      "Epoch 47/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.7865 - acc: 0.8481\n",
      "Epoch 00047: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.7865 - acc: 0.8482 - val_loss: 5.0034 - val_acc: 0.0526\n",
      "Epoch 48/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6686 - acc: 0.8821\n",
      "Epoch 00048: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6686 - acc: 0.8821 - val_loss: 5.0449 - val_acc: 0.0526\n",
      "Epoch 49/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6095 - acc: 0.9010\n",
      "Epoch 00049: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6096 - acc: 0.9011 - val_loss: 5.0889 - val_acc: 0.0495\n",
      "Epoch 50/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.7563 - acc: 0.8502\n",
      "Epoch 00050: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.7563 - acc: 0.8502 - val_loss: 5.1143 - val_acc: 0.0676\n",
      "Epoch 51/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.7011 - acc: 0.8567\n",
      "Epoch 00051: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.7010 - acc: 0.8567 - val_loss: 5.2100 - val_acc: 0.0601\n",
      "Epoch 52/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6538 - acc: 0.8815\n",
      "Epoch 00052: val_loss did not improve from 3.70231\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6537 - acc: 0.8815 - val_loss: 5.1686 - val_acc: 0.0631\n",
      "Training time: 334.35032081604004 s\n",
      "1201/1201 [==============================] - 2s 1ms/sample - loss: 3.7067 - acc: 0.0583\n",
      "Fold: 2\n",
      "\n",
      "Train on 4801 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.3630 - acc: 0.1427\n",
      "Epoch 00001: val_loss improved from inf to 3.69880, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-ladder_2.hdf5\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 3.3631 - acc: 0.1427 - val_loss: 3.6988 - val_acc: 0.0571\n",
      "Epoch 2/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.3010 - acc: 0.1440\n",
      "Epoch 00002: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 3.3012 - acc: 0.1439 - val_loss: 3.7000 - val_acc: 0.0465\n",
      "Epoch 3/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.2104 - acc: 0.1731\n",
      "Epoch 00003: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 3.2105 - acc: 0.1731 - val_loss: 3.7084 - val_acc: 0.0646\n",
      "Epoch 4/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.1592 - acc: 0.1813\n",
      "Epoch 00004: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 3.1591 - acc: 0.1812 - val_loss: 3.7220 - val_acc: 0.0631\n",
      "Epoch 5/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.0819 - acc: 0.1992\n",
      "Epoch 00005: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 3.0820 - acc: 0.1991 - val_loss: 3.7246 - val_acc: 0.0616\n",
      "Epoch 6/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.0398 - acc: 0.2144\n",
      "Epoch 00006: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 3.0397 - acc: 0.2143 - val_loss: 3.7265 - val_acc: 0.0661\n",
      "Epoch 7/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 3.0009 - acc: 0.2246\n",
      "Epoch 00007: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 3.0010 - acc: 0.2245 - val_loss: 3.7286 - val_acc: 0.0646\n",
      "Epoch 8/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.9218 - acc: 0.2408\n",
      "Epoch 00008: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 7s 1ms/sample - loss: 2.9217 - acc: 0.2408 - val_loss: 3.7347 - val_acc: 0.0781\n",
      "Epoch 9/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.8852 - acc: 0.2519\n",
      "Epoch 00009: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.8854 - acc: 0.2518 - val_loss: 3.7377 - val_acc: 0.0766\n",
      "Epoch 10/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7828 - acc: 0.2798\n",
      "Epoch 00010: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.7826 - acc: 0.2799 - val_loss: 3.7388 - val_acc: 0.0811\n",
      "Epoch 11/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.7155 - acc: 0.2975\n",
      "Epoch 00011: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.7154 - acc: 0.2976 - val_loss: 3.7530 - val_acc: 0.0826\n",
      "Epoch 12/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6516 - acc: 0.3202\n",
      "Epoch 00012: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.6518 - acc: 0.3201 - val_loss: 3.7781 - val_acc: 0.0781\n",
      "Epoch 13/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6716 - acc: 0.3048\n",
      "Epoch 00013: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.6720 - acc: 0.3047 - val_loss: 3.7871 - val_acc: 0.0811\n",
      "Epoch 14/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.6024 - acc: 0.3248\n",
      "Epoch 00014: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.6026 - acc: 0.3247 - val_loss: 3.8227 - val_acc: 0.0811\n",
      "Epoch 15/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.5378 - acc: 0.3562\n",
      "Epoch 00015: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.5377 - acc: 0.3564 - val_loss: 3.8271 - val_acc: 0.0736\n",
      "Epoch 16/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.4585 - acc: 0.3690\n",
      "Epoch 00016: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.4587 - acc: 0.3689 - val_loss: 3.8429 - val_acc: 0.0856\n",
      "Epoch 17/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.4419 - acc: 0.3829\n",
      "Epoch 00017: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.4418 - acc: 0.3830 - val_loss: 3.8456 - val_acc: 0.0811\n",
      "Epoch 18/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.3107 - acc: 0.4233\n",
      "Epoch 00018: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.3105 - acc: 0.4235 - val_loss: 3.8649 - val_acc: 0.0916\n",
      "Epoch 19/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.2501 - acc: 0.4369\n",
      "Epoch 00019: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.2498 - acc: 0.4370 - val_loss: 3.8932 - val_acc: 0.0826\n",
      "Epoch 20/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1751 - acc: 0.4594\n",
      "Epoch 00020: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.1747 - acc: 0.4595 - val_loss: 3.8759 - val_acc: 0.0901\n",
      "Epoch 21/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.0980 - acc: 0.4787\n",
      "Epoch 00021: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.0981 - acc: 0.4787 - val_loss: 3.8967 - val_acc: 0.0901\n",
      "Epoch 22/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 2.1119 - acc: 0.4704\n",
      "Epoch 00022: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 2.1115 - acc: 0.4705 - val_loss: 3.9247 - val_acc: 0.0811\n",
      "Epoch 23/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.9269 - acc: 0.5344\n",
      "Epoch 00023: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.9268 - acc: 0.5345 - val_loss: 3.9290 - val_acc: 0.0751\n",
      "Epoch 24/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8984 - acc: 0.5402\n",
      "Epoch 00024: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.8983 - acc: 0.5403 - val_loss: 3.9466 - val_acc: 0.0856\n",
      "Epoch 25/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.8590 - acc: 0.5502\n",
      "Epoch 00025: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.8588 - acc: 0.5503 - val_loss: 3.9847 - val_acc: 0.0736\n",
      "Epoch 26/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7816 - acc: 0.5702\n",
      "Epoch 00026: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.7820 - acc: 0.5701 - val_loss: 3.9911 - val_acc: 0.0901\n",
      "Epoch 27/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.7149 - acc: 0.5923\n",
      "Epoch 00027: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.7147 - acc: 0.5924 - val_loss: 4.0218 - val_acc: 0.0886\n",
      "Epoch 28/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6614 - acc: 0.6094\n",
      "Epoch 00028: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.6614 - acc: 0.6095 - val_loss: 4.0452 - val_acc: 0.0826\n",
      "Epoch 29/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.6266 - acc: 0.6202\n",
      "Epoch 00029: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.6263 - acc: 0.6203 - val_loss: 4.0578 - val_acc: 0.0916\n",
      "Epoch 30/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4712 - acc: 0.6792\n",
      "Epoch 00030: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4710 - acc: 0.6792 - val_loss: 4.0797 - val_acc: 0.0901\n",
      "Epoch 31/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4434 - acc: 0.6783\n",
      "Epoch 00031: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4432 - acc: 0.6784 - val_loss: 4.1095 - val_acc: 0.0946\n",
      "Epoch 32/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.3662 - acc: 0.7031\n",
      "Epoch 00032: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.3663 - acc: 0.7030 - val_loss: 4.1351 - val_acc: 0.0871\n",
      "Epoch 33/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4564 - acc: 0.6652\n",
      "Epoch 00033: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4565 - acc: 0.6653 - val_loss: 4.1991 - val_acc: 0.0721\n",
      "Epoch 34/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4051 - acc: 0.6735\n",
      "Epoch 00034: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4054 - acc: 0.6734 - val_loss: 4.2030 - val_acc: 0.0886\n",
      "Epoch 35/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4806 - acc: 0.6508\n",
      "Epoch 00035: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4807 - acc: 0.6507 - val_loss: 4.2505 - val_acc: 0.0721\n",
      "Epoch 36/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.4772 - acc: 0.6498\n",
      "Epoch 00036: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.4770 - acc: 0.6499 - val_loss: 4.2414 - val_acc: 0.0811\n",
      "Epoch 37/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.2021 - acc: 0.7421\n",
      "Epoch 00037: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.2020 - acc: 0.7421 - val_loss: 4.2843 - val_acc: 0.0931\n",
      "Epoch 38/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.1278 - acc: 0.7615\n",
      "Epoch 00038: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.1281 - acc: 0.7613 - val_loss: 4.3052 - val_acc: 0.0796\n",
      "Epoch 39/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.2105 - acc: 0.7275\n",
      "Epoch 00039: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.2106 - acc: 0.7276 - val_loss: 4.3867 - val_acc: 0.0676\n",
      "Epoch 40/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.3748 - acc: 0.6696\n",
      "Epoch 00040: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.3746 - acc: 0.6697 - val_loss: 4.4298 - val_acc: 0.0751\n",
      "Epoch 41/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.0539 - acc: 0.7865\n",
      "Epoch 00041: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.0540 - acc: 0.7865 - val_loss: 4.4197 - val_acc: 0.0766\n",
      "Epoch 42/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.0335 - acc: 0.7821\n",
      "Epoch 00042: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.0335 - acc: 0.7821 - val_loss: 4.4280 - val_acc: 0.0766\n",
      "Epoch 43/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.9316 - acc: 0.8112\n",
      "Epoch 00043: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.9318 - acc: 0.8113 - val_loss: 4.5301 - val_acc: 0.0826\n",
      "Epoch 44/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 1.0063 - acc: 0.7873\n",
      "Epoch 00044: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 1.0063 - acc: 0.7873 - val_loss: 4.5125 - val_acc: 0.0826\n",
      "Epoch 45/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.8788 - acc: 0.8240\n",
      "Epoch 00045: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.8789 - acc: 0.8240 - val_loss: 4.5403 - val_acc: 0.0766\n",
      "Epoch 46/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.8414 - acc: 0.8304\n",
      "Epoch 00046: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.8413 - acc: 0.8305 - val_loss: 4.5446 - val_acc: 0.0871\n",
      "Epoch 47/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.7436 - acc: 0.8671\n",
      "Epoch 00047: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.7436 - acc: 0.8671 - val_loss: 4.6409 - val_acc: 0.0751\n",
      "Epoch 48/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.8428 - acc: 0.8356\n",
      "Epoch 00048: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.8427 - acc: 0.8357 - val_loss: 4.6288 - val_acc: 0.0721\n",
      "Epoch 49/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6224 - acc: 0.9050\n",
      "Epoch 00049: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6224 - acc: 0.9050 - val_loss: 4.6540 - val_acc: 0.0811\n",
      "Epoch 50/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6749 - acc: 0.8908\n",
      "Epoch 00050: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6748 - acc: 0.8909 - val_loss: 4.7254 - val_acc: 0.0691\n",
      "Epoch 51/2000\n",
      "4800/4801 [============================>.] - ETA: 0s - loss: 0.6186 - acc: 0.9038\n",
      "Epoch 00051: val_loss did not improve from 3.69880\n",
      "4801/4801 [==============================] - 6s 1ms/sample - loss: 0.6187 - acc: 0.9038 - val_loss: 4.8142 - val_acc: 0.0721\n",
      "Training time: 322.88543915748596 s\n",
      "1201/1201 [==============================] - 2s 1ms/sample - loss: 3.2970 - acc: 0.1607\n",
      "Fold: 3\n",
      "\n",
      "Train on 4802 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.3645 - acc: 0.1287\n",
      "Epoch 00001: val_loss improved from inf to 3.71047, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-ladder_3.hdf5\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 3.3644 - acc: 0.1289 - val_loss: 3.7105 - val_acc: 0.0435\n",
      "Epoch 2/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.2736 - acc: 0.1508\n",
      "Epoch 00002: val_loss improved from 3.71047 to 3.70650, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-ladder_3.hdf5\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 3.2735 - acc: 0.1508 - val_loss: 3.7065 - val_acc: 0.0450\n",
      "Epoch 3/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.1672 - acc: 0.1733\n",
      "Epoch 00003: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 3.1672 - acc: 0.1735 - val_loss: 3.7120 - val_acc: 0.0616\n",
      "Epoch 4/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.0729 - acc: 0.2004\n",
      "Epoch 00004: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 3.0728 - acc: 0.2003 - val_loss: 3.7282 - val_acc: 0.0571\n",
      "Epoch 5/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.9962 - acc: 0.2167\n",
      "Epoch 00005: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.9964 - acc: 0.2166 - val_loss: 3.7344 - val_acc: 0.0586\n",
      "Epoch 6/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.8926 - acc: 0.2512\n",
      "Epoch 00006: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.8927 - acc: 0.2511 - val_loss: 3.7401 - val_acc: 0.0616\n",
      "Epoch 7/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.8334 - acc: 0.2610\n",
      "Epoch 00007: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.8340 - acc: 0.2609 - val_loss: 3.7573 - val_acc: 0.0586\n",
      "Epoch 8/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.7303 - acc: 0.2967\n",
      "Epoch 00008: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.7304 - acc: 0.2968 - val_loss: 3.7570 - val_acc: 0.0586\n",
      "Epoch 9/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.6668 - acc: 0.3060\n",
      "Epoch 00009: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.6671 - acc: 0.3059 - val_loss: 3.7785 - val_acc: 0.0661\n",
      "Epoch 10/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.6076 - acc: 0.3321\n",
      "Epoch 00010: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.6079 - acc: 0.3322 - val_loss: 3.8031 - val_acc: 0.0646\n",
      "Epoch 11/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.5130 - acc: 0.3565\n",
      "Epoch 00011: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 7s 1ms/sample - loss: 2.5129 - acc: 0.3565 - val_loss: 3.8130 - val_acc: 0.0691\n",
      "Epoch 12/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.4433 - acc: 0.3696\n",
      "Epoch 00012: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.4437 - acc: 0.3696 - val_loss: 3.8168 - val_acc: 0.0736\n",
      "Epoch 13/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.3497 - acc: 0.4013\n",
      "Epoch 00013: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.3495 - acc: 0.4013 - val_loss: 3.8214 - val_acc: 0.0691\n",
      "Epoch 14/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.2234 - acc: 0.4387\n",
      "Epoch 00014: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.2230 - acc: 0.4388 - val_loss: 3.8536 - val_acc: 0.0631\n",
      "Epoch 15/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1915 - acc: 0.4477\n",
      "Epoch 00015: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.1913 - acc: 0.4477 - val_loss: 3.9081 - val_acc: 0.0541\n",
      "Epoch 16/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0665 - acc: 0.4802\n",
      "Epoch 00016: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.0668 - acc: 0.4802 - val_loss: 3.9094 - val_acc: 0.0736\n",
      "Epoch 17/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0555 - acc: 0.4804\n",
      "Epoch 00017: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.0552 - acc: 0.4806 - val_loss: 3.8828 - val_acc: 0.0736\n",
      "Epoch 18/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9021 - acc: 0.5333\n",
      "Epoch 00018: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.9016 - acc: 0.5335 - val_loss: 3.9251 - val_acc: 0.0676\n",
      "Epoch 19/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7899 - acc: 0.5721\n",
      "Epoch 00019: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.7898 - acc: 0.5723 - val_loss: 3.9298 - val_acc: 0.0856\n",
      "Epoch 20/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7594 - acc: 0.5702\n",
      "Epoch 00020: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.7600 - acc: 0.5700 - val_loss: 4.0195 - val_acc: 0.0751\n",
      "Epoch 21/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6943 - acc: 0.5871\n",
      "Epoch 00021: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.6945 - acc: 0.5870 - val_loss: 4.0435 - val_acc: 0.0691\n",
      "Epoch 22/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6295 - acc: 0.6112\n",
      "Epoch 00022: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.6298 - acc: 0.6112 - val_loss: 4.0982 - val_acc: 0.0631\n",
      "Epoch 23/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5561 - acc: 0.6300\n",
      "Epoch 00023: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.5560 - acc: 0.6299 - val_loss: 4.0847 - val_acc: 0.0721\n",
      "Epoch 24/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4376 - acc: 0.6704\n",
      "Epoch 00024: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.4377 - acc: 0.6703 - val_loss: 4.0780 - val_acc: 0.0751\n",
      "Epoch 25/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3912 - acc: 0.6852\n",
      "Epoch 00025: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.3911 - acc: 0.6851 - val_loss: 4.1263 - val_acc: 0.0631\n",
      "Epoch 26/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2785 - acc: 0.7181\n",
      "Epoch 00026: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.2787 - acc: 0.7180 - val_loss: 4.1647 - val_acc: 0.0691\n",
      "Epoch 27/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2714 - acc: 0.7246\n",
      "Epoch 00027: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.2714 - acc: 0.7247 - val_loss: 4.2068 - val_acc: 0.0676\n",
      "Epoch 28/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.1744 - acc: 0.7481\n",
      "Epoch 00028: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.1742 - acc: 0.7482 - val_loss: 4.2488 - val_acc: 0.0631\n",
      "Epoch 29/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.0627 - acc: 0.7794\n",
      "Epoch 00029: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.0627 - acc: 0.7793 - val_loss: 4.3451 - val_acc: 0.0796\n",
      "Epoch 30/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.1704 - acc: 0.7387\n",
      "Epoch 00030: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.1704 - acc: 0.7387 - val_loss: 4.3104 - val_acc: 0.0841\n",
      "Epoch 31/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.0696 - acc: 0.7690\n",
      "Epoch 00031: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.0697 - acc: 0.7688 - val_loss: 4.4022 - val_acc: 0.0736\n",
      "Epoch 32/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.1131 - acc: 0.7538\n",
      "Epoch 00032: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.1128 - acc: 0.7539 - val_loss: 4.4629 - val_acc: 0.0631\n",
      "Epoch 33/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.8987 - acc: 0.8348\n",
      "Epoch 00033: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.8989 - acc: 0.8347 - val_loss: 4.5347 - val_acc: 0.0601\n",
      "Epoch 34/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.8534 - acc: 0.8398\n",
      "Epoch 00034: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.8535 - acc: 0.8397 - val_loss: 4.4944 - val_acc: 0.0601\n",
      "Epoch 35/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.7988 - acc: 0.8479\n",
      "Epoch 00035: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.7988 - acc: 0.8480 - val_loss: 4.5649 - val_acc: 0.0646\n",
      "Epoch 36/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.7051 - acc: 0.8835\n",
      "Epoch 00036: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.7051 - acc: 0.8836 - val_loss: 4.5985 - val_acc: 0.0736\n",
      "Epoch 37/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.8520 - acc: 0.8217\n",
      "Epoch 00037: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.8517 - acc: 0.8217 - val_loss: 4.6405 - val_acc: 0.0691\n",
      "Epoch 38/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5771 - acc: 0.9127\n",
      "Epoch 00038: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5771 - acc: 0.9127 - val_loss: 4.6855 - val_acc: 0.0661\n",
      "Epoch 39/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.9071\n",
      "Epoch 00039: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.6023 - acc: 0.9071 - val_loss: 4.7413 - val_acc: 0.0661\n",
      "Epoch 40/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.9807 - acc: 0.7723\n",
      "Epoch 00040: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.9809 - acc: 0.7722 - val_loss: 4.8603 - val_acc: 0.0631\n",
      "Epoch 41/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.1214 - acc: 0.7317\n",
      "Epoch 00041: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.1212 - acc: 0.7318 - val_loss: 4.8039 - val_acc: 0.0646\n",
      "Epoch 42/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.7473 - acc: 0.8625\n",
      "Epoch 00042: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.7473 - acc: 0.8626 - val_loss: 4.8327 - val_acc: 0.0556\n",
      "Epoch 43/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.6301 - acc: 0.8990\n",
      "Epoch 00043: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.6303 - acc: 0.8990 - val_loss: 4.8657 - val_acc: 0.0571\n",
      "Epoch 44/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5604 - acc: 0.9154\n",
      "Epoch 00044: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5602 - acc: 0.9155 - val_loss: 4.9303 - val_acc: 0.0495\n",
      "Epoch 45/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.9540\n",
      "Epoch 00045: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.4170 - acc: 0.9540 - val_loss: 4.9792 - val_acc: 0.0526\n",
      "Epoch 46/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.9298\n",
      "Epoch 00046: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.4675 - acc: 0.9296 - val_loss: 5.0710 - val_acc: 0.0676\n",
      "Epoch 47/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.9341 - acc: 0.7710\n",
      "Epoch 00047: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.9343 - acc: 0.7707 - val_loss: 4.9913 - val_acc: 0.0616\n",
      "Epoch 48/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.7923 - acc: 0.8290\n",
      "Epoch 00048: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.7921 - acc: 0.8290 - val_loss: 5.0135 - val_acc: 0.0736\n",
      "Epoch 49/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.9327\n",
      "Epoch 00049: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.4951 - acc: 0.9325 - val_loss: 5.0325 - val_acc: 0.0706\n",
      "Epoch 50/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5266 - acc: 0.9073\n",
      "Epoch 00050: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5267 - acc: 0.9073 - val_loss: 5.0958 - val_acc: 0.0586\n",
      "Epoch 51/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3713 - acc: 0.9581\n",
      "Epoch 00051: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3714 - acc: 0.9581 - val_loss: 5.1533 - val_acc: 0.0631\n",
      "Epoch 52/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.9646\n",
      "Epoch 00052: val_loss did not improve from 3.70650\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3375 - acc: 0.9646 - val_loss: 5.1578 - val_acc: 0.0721\n",
      "Training time: 328.02361011505127 s\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 3.3515 - acc: 0.1300\n",
      "Fold: 4\n",
      "\n",
      "Train on 4802 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.1986 - acc: 0.1737\n",
      "Epoch 00001: val_loss improved from inf to 3.70057, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-ladder_4.hdf5\n",
      "4802/4802 [==============================] - 7s 1ms/sample - loss: 3.1995 - acc: 0.1737 - val_loss: 3.7006 - val_acc: 0.0676\n",
      "Epoch 2/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.1335 - acc: 0.1885\n",
      "Epoch 00002: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 7s 1ms/sample - loss: 3.1336 - acc: 0.1885 - val_loss: 3.7357 - val_acc: 0.0556\n",
      "Epoch 3/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.0610 - acc: 0.2123\n",
      "Epoch 00003: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 7s 1ms/sample - loss: 3.0609 - acc: 0.2124 - val_loss: 3.7489 - val_acc: 0.0601\n",
      "Epoch 4/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.9479 - acc: 0.2369\n",
      "Epoch 00004: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.9479 - acc: 0.2368 - val_loss: 3.7532 - val_acc: 0.0646\n",
      "Epoch 5/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.8820 - acc: 0.2488\n",
      "Epoch 00005: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.8818 - acc: 0.2489 - val_loss: 3.7696 - val_acc: 0.0495\n",
      "Epoch 6/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.7849 - acc: 0.2827\n",
      "Epoch 00006: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.7846 - acc: 0.2828 - val_loss: 3.7668 - val_acc: 0.0736\n",
      "Epoch 7/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.6770 - acc: 0.3042\n",
      "Epoch 00007: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.6771 - acc: 0.3040 - val_loss: 3.7873 - val_acc: 0.0706\n",
      "Epoch 8/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.6140 - acc: 0.3177\n",
      "Epoch 00008: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.6143 - acc: 0.3176 - val_loss: 3.7819 - val_acc: 0.0691\n",
      "Epoch 9/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.5325 - acc: 0.3408\n",
      "Epoch 00009: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.5327 - acc: 0.3407 - val_loss: 3.8098 - val_acc: 0.0646\n",
      "Epoch 10/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.4350 - acc: 0.3644\n",
      "Epoch 00010: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.4357 - acc: 0.3644 - val_loss: 3.8394 - val_acc: 0.0661\n",
      "Epoch 11/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.3702 - acc: 0.3913\n",
      "Epoch 00011: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.3706 - acc: 0.3911 - val_loss: 3.8480 - val_acc: 0.0676\n",
      "Epoch 12/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.3433 - acc: 0.4021\n",
      "Epoch 00012: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.3435 - acc: 0.4019 - val_loss: 3.8386 - val_acc: 0.0706\n",
      "Epoch 13/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.2829 - acc: 0.4248\n",
      "Epoch 00013: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.2832 - acc: 0.4246 - val_loss: 3.8672 - val_acc: 0.0691\n",
      "Epoch 14/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1188 - acc: 0.4748\n",
      "Epoch 00014: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.1188 - acc: 0.4748 - val_loss: 3.9029 - val_acc: 0.0691\n",
      "Epoch 15/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.0458 - acc: 0.4908\n",
      "Epoch 00015: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.0455 - acc: 0.4908 - val_loss: 3.8782 - val_acc: 0.0856\n",
      "Epoch 16/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9626 - acc: 0.5144\n",
      "Epoch 00016: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.9622 - acc: 0.5146 - val_loss: 3.9293 - val_acc: 0.0721\n",
      "Epoch 17/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8399 - acc: 0.5523\n",
      "Epoch 00017: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.8397 - acc: 0.5525 - val_loss: 3.9160 - val_acc: 0.0856\n",
      "Epoch 18/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7633 - acc: 0.5700\n",
      "Epoch 00018: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.7633 - acc: 0.5700 - val_loss: 3.9769 - val_acc: 0.0676\n",
      "Epoch 19/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7336 - acc: 0.5685\n",
      "Epoch 00019: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.7332 - acc: 0.5687 - val_loss: 3.9884 - val_acc: 0.0796\n",
      "Epoch 20/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5753 - acc: 0.6281\n",
      "Epoch 00020: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.5757 - acc: 0.6281 - val_loss: 4.0298 - val_acc: 0.0751\n",
      "Epoch 21/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6024 - acc: 0.6108\n",
      "Epoch 00021: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.6024 - acc: 0.6108 - val_loss: 4.0820 - val_acc: 0.0736\n",
      "Epoch 22/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5704 - acc: 0.6342\n",
      "Epoch 00022: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.5703 - acc: 0.6341 - val_loss: 4.0856 - val_acc: 0.0751\n",
      "Epoch 23/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4032 - acc: 0.6815\n",
      "Epoch 00023: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.4035 - acc: 0.6814 - val_loss: 4.1047 - val_acc: 0.0706\n",
      "Epoch 24/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.5615 - acc: 0.6256\n",
      "Epoch 00024: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.5613 - acc: 0.6256 - val_loss: 4.1465 - val_acc: 0.0796\n",
      "Epoch 25/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3424 - acc: 0.6867\n",
      "Epoch 00025: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.3425 - acc: 0.6866 - val_loss: 4.1630 - val_acc: 0.0781\n",
      "Epoch 26/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3284 - acc: 0.6908\n",
      "Epoch 00026: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.3281 - acc: 0.6910 - val_loss: 4.1760 - val_acc: 0.0766\n",
      "Epoch 27/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.1353 - acc: 0.7631\n",
      "Epoch 00027: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.1350 - acc: 0.7632 - val_loss: 4.1913 - val_acc: 0.0751\n",
      "Epoch 28/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.0006 - acc: 0.8021\n",
      "Epoch 00028: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.0008 - acc: 0.8022 - val_loss: 4.2202 - val_acc: 0.0811\n",
      "Epoch 29/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.0134 - acc: 0.7867\n",
      "Epoch 00029: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.0141 - acc: 0.7863 - val_loss: 4.2966 - val_acc: 0.0706\n",
      "Epoch 30/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2120 - acc: 0.7163\n",
      "Epoch 00030: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.2120 - acc: 0.7162 - val_loss: 4.3274 - val_acc: 0.0751\n",
      "Epoch 31/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.0464 - acc: 0.7731\n",
      "Epoch 00031: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.0464 - acc: 0.7732 - val_loss: 4.3665 - val_acc: 0.0721\n",
      "Epoch 32/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.9731 - acc: 0.7898\n",
      "Epoch 00032: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.9732 - acc: 0.7897 - val_loss: 4.3450 - val_acc: 0.0781\n",
      "Epoch 33/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.9117 - acc: 0.8133\n",
      "Epoch 00033: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.9126 - acc: 0.8132 - val_loss: 4.4571 - val_acc: 0.0826\n",
      "Epoch 34/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.9041 - acc: 0.8138\n",
      "Epoch 00034: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.9043 - acc: 0.8136 - val_loss: 4.4767 - val_acc: 0.0646\n",
      "Epoch 35/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.8827 - acc: 0.8160\n",
      "Epoch 00035: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.8826 - acc: 0.8161 - val_loss: 4.4941 - val_acc: 0.0661\n",
      "Epoch 36/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.7256 - acc: 0.8727\n",
      "Epoch 00036: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 7s 1ms/sample - loss: 0.7253 - acc: 0.8728 - val_loss: 4.5300 - val_acc: 0.0676\n",
      "Epoch 37/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5997 - acc: 0.9148\n",
      "Epoch 00037: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5997 - acc: 0.9148 - val_loss: 4.5609 - val_acc: 0.0586\n",
      "Epoch 38/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5985 - acc: 0.9060\n",
      "Epoch 00038: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5983 - acc: 0.9061 - val_loss: 4.5921 - val_acc: 0.0691\n",
      "Epoch 39/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5274 - acc: 0.9321\n",
      "Epoch 00039: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5274 - acc: 0.9321 - val_loss: 4.6733 - val_acc: 0.0646\n",
      "Epoch 40/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5227 - acc: 0.9237\n",
      "Epoch 00040: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5225 - acc: 0.9238 - val_loss: 4.6696 - val_acc: 0.0706\n",
      "Epoch 41/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.4199 - acc: 0.9538\n",
      "Epoch 00041: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.4197 - acc: 0.9538 - val_loss: 4.7343 - val_acc: 0.0781\n",
      "Epoch 42/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.9677\n",
      "Epoch 00042: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3667 - acc: 0.9677 - val_loss: 4.7851 - val_acc: 0.0706\n",
      "Epoch 43/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3427 - acc: 0.9671\n",
      "Epoch 00043: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3429 - acc: 0.9669 - val_loss: 4.8099 - val_acc: 0.0721\n",
      "Epoch 44/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5112 - acc: 0.9196\n",
      "Epoch 00044: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5111 - acc: 0.9196 - val_loss: 4.8750 - val_acc: 0.0691\n",
      "Epoch 45/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.9623\n",
      "Epoch 00045: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3521 - acc: 0.9623 - val_loss: 4.9398 - val_acc: 0.0676\n",
      "Epoch 46/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5407 - acc: 0.9067\n",
      "Epoch 00046: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5408 - acc: 0.9067 - val_loss: 4.9834 - val_acc: 0.0646\n",
      "Epoch 47/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5696 - acc: 0.8917\n",
      "Epoch 00047: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5694 - acc: 0.8917 - val_loss: 4.9225 - val_acc: 0.0676\n",
      "Epoch 48/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.9694\n",
      "Epoch 00048: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3342 - acc: 0.9694 - val_loss: 4.9994 - val_acc: 0.0676\n",
      "Epoch 49/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.9812\n",
      "Epoch 00049: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.2492 - acc: 0.9813 - val_loss: 5.0195 - val_acc: 0.0601\n",
      "Epoch 50/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.2587 - acc: 0.9808\n",
      "Epoch 00050: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.2587 - acc: 0.9808 - val_loss: 5.0728 - val_acc: 0.0676\n",
      "Epoch 51/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9887\n",
      "Epoch 00051: val_loss did not improve from 3.70057\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.2222 - acc: 0.9888 - val_loss: 5.0958 - val_acc: 0.0691\n",
      "Training time: 302.6401765346527 s\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 3.1200 - acc: 0.1983\n",
      "Fold: 5\n",
      "\n",
      "Train on 4802 samples, validate on 666 samples\n",
      "Epoch 1/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.1408 - acc: 0.1885\n",
      "Epoch 00001: val_loss improved from inf to 3.70785, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/PhonemeSpectra/PhonemeSpectra-ladder_5.hdf5\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 3.1409 - acc: 0.1887 - val_loss: 3.7079 - val_acc: 0.0616\n",
      "Epoch 2/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 3.0494 - acc: 0.2083\n",
      "Epoch 00002: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 3.0492 - acc: 0.2082 - val_loss: 3.7437 - val_acc: 0.0631\n",
      "Epoch 3/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.9721 - acc: 0.2265\n",
      "Epoch 00003: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.9719 - acc: 0.2266 - val_loss: 3.7557 - val_acc: 0.0646\n",
      "Epoch 4/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.8745 - acc: 0.2537\n",
      "Epoch 00004: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.8748 - acc: 0.2536 - val_loss: 3.7827 - val_acc: 0.0676\n",
      "Epoch 5/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.7968 - acc: 0.2675\n",
      "Epoch 00005: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.7966 - acc: 0.2674 - val_loss: 3.7839 - val_acc: 0.0571\n",
      "Epoch 6/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.6882 - acc: 0.3025\n",
      "Epoch 00006: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.6885 - acc: 0.3024 - val_loss: 3.7838 - val_acc: 0.0751\n",
      "Epoch 7/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.5963 - acc: 0.3294\n",
      "Epoch 00007: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.5964 - acc: 0.3294 - val_loss: 3.8261 - val_acc: 0.0781\n",
      "Epoch 8/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.5250 - acc: 0.3492\n",
      "Epoch 00008: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.5248 - acc: 0.3492 - val_loss: 3.8577 - val_acc: 0.0646\n",
      "Epoch 9/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.4382 - acc: 0.3748\n",
      "Epoch 00009: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.4381 - acc: 0.3748 - val_loss: 3.8721 - val_acc: 0.0736\n",
      "Epoch 10/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.3299 - acc: 0.3963\n",
      "Epoch 00010: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.3296 - acc: 0.3963 - val_loss: 3.8988 - val_acc: 0.0781\n",
      "Epoch 11/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.3105 - acc: 0.4071\n",
      "Epoch 00011: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.3101 - acc: 0.4073 - val_loss: 3.9096 - val_acc: 0.0841\n",
      "Epoch 12/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.1066 - acc: 0.4767\n",
      "Epoch 00012: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.1059 - acc: 0.4769 - val_loss: 3.9234 - val_acc: 0.0736\n",
      "Epoch 13/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9591 - acc: 0.5246\n",
      "Epoch 00013: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.9594 - acc: 0.5246 - val_loss: 3.9762 - val_acc: 0.0766\n",
      "Epoch 14/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.9053 - acc: 0.5375\n",
      "Epoch 00014: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.9048 - acc: 0.5377 - val_loss: 3.9690 - val_acc: 0.0826\n",
      "Epoch 15/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.8065 - acc: 0.5612\n",
      "Epoch 00015: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.8066 - acc: 0.5612 - val_loss: 4.0096 - val_acc: 0.0781\n",
      "Epoch 16/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.7814 - acc: 0.5625\n",
      "Epoch 00016: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.7815 - acc: 0.5625 - val_loss: 4.0402 - val_acc: 0.0751\n",
      "Epoch 17/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6843 - acc: 0.5888\n",
      "Epoch 00017: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.6846 - acc: 0.5887 - val_loss: 4.0783 - val_acc: 0.0856\n",
      "Epoch 18/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.6320 - acc: 0.6081\n",
      "Epoch 00018: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.6317 - acc: 0.6083 - val_loss: 4.1001 - val_acc: 0.0691\n",
      "Epoch 19/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4377 - acc: 0.6706\n",
      "Epoch 00019: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.4378 - acc: 0.6706 - val_loss: 4.1272 - val_acc: 0.0721\n",
      "Epoch 20/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4098 - acc: 0.6721\n",
      "Epoch 00020: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.4103 - acc: 0.6718 - val_loss: 4.1574 - val_acc: 0.0646\n",
      "Epoch 21/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.3794 - acc: 0.6785\n",
      "Epoch 00021: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.3797 - acc: 0.6783 - val_loss: 4.1981 - val_acc: 0.0721\n",
      "Epoch 22/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.2927 - acc: 0.7142\n",
      "Epoch 00022: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.2930 - acc: 0.7141 - val_loss: 4.2814 - val_acc: 0.0691\n",
      "Epoch 23/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.4017 - acc: 0.6706\n",
      "Epoch 00023: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.4014 - acc: 0.6708 - val_loss: 4.2822 - val_acc: 0.0901\n",
      "Epoch 24/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.0949 - acc: 0.7731\n",
      "Epoch 00024: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.0948 - acc: 0.7732 - val_loss: 4.3308 - val_acc: 0.0886\n",
      "Epoch 25/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 1.0709 - acc: 0.7748\n",
      "Epoch 00025: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 1.0708 - acc: 0.7749 - val_loss: 4.3492 - val_acc: 0.0871\n",
      "Epoch 26/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.9770 - acc: 0.8079\n",
      "Epoch 00026: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.9770 - acc: 0.8078 - val_loss: 4.3644 - val_acc: 0.0976\n",
      "Epoch 27/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.9701 - acc: 0.8019\n",
      "Epoch 00027: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.9701 - acc: 0.8020 - val_loss: 4.4614 - val_acc: 0.0811\n",
      "Epoch 28/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.9727 - acc: 0.8021\n",
      "Epoch 00028: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.9726 - acc: 0.8022 - val_loss: 4.4586 - val_acc: 0.0751\n",
      "Epoch 29/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.8547 - acc: 0.8454\n",
      "Epoch 00029: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.8545 - acc: 0.8455 - val_loss: 4.4747 - val_acc: 0.0676\n",
      "Epoch 30/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.6868 - acc: 0.8942\n",
      "Epoch 00030: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.6866 - acc: 0.8942 - val_loss: 4.5432 - val_acc: 0.0841\n",
      "Epoch 31/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.9123\n",
      "Epoch 00031: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.6111 - acc: 0.9123 - val_loss: 4.5979 - val_acc: 0.0871\n",
      "Epoch 32/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5610 - acc: 0.9269\n",
      "Epoch 00032: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5609 - acc: 0.9269 - val_loss: 4.6309 - val_acc: 0.0751\n",
      "Epoch 33/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.9365\n",
      "Epoch 00033: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5191 - acc: 0.9365 - val_loss: 4.6609 - val_acc: 0.0751\n",
      "Epoch 34/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.4586 - acc: 0.9502\n",
      "Epoch 00034: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.4588 - acc: 0.9502 - val_loss: 4.7437 - val_acc: 0.0841\n",
      "Epoch 35/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.6825 - acc: 0.8771\n",
      "Epoch 00035: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.6824 - acc: 0.8771 - val_loss: 4.7555 - val_acc: 0.0781\n",
      "Epoch 36/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.6919 - acc: 0.8677\n",
      "Epoch 00036: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.6917 - acc: 0.8678 - val_loss: 4.8549 - val_acc: 0.0721\n",
      "Epoch 37/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5414 - acc: 0.9231\n",
      "Epoch 00037: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5412 - acc: 0.9232 - val_loss: 4.8319 - val_acc: 0.0736\n",
      "Epoch 38/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.4315 - acc: 0.9485\n",
      "Epoch 00038: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.4317 - acc: 0.9484 - val_loss: 4.8836 - val_acc: 0.0661\n",
      "Epoch 39/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.6569 - acc: 0.8744\n",
      "Epoch 00039: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.6567 - acc: 0.8744 - val_loss: 4.9075 - val_acc: 0.0691\n",
      "Epoch 40/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3728 - acc: 0.9596\n",
      "Epoch 00040: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3727 - acc: 0.9596 - val_loss: 4.9436 - val_acc: 0.0586\n",
      "Epoch 41/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.9758\n",
      "Epoch 00041: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.2938 - acc: 0.9758 - val_loss: 5.0016 - val_acc: 0.0796\n",
      "Epoch 42/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3276 - acc: 0.9627\n",
      "Epoch 00042: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3275 - acc: 0.9627 - val_loss: 5.0292 - val_acc: 0.0766\n",
      "Epoch 43/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.2424 - acc: 0.9837\n",
      "Epoch 00043: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.2429 - acc: 0.9835 - val_loss: 5.1224 - val_acc: 0.0751\n",
      "Epoch 44/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.8742 - acc: 0.7854\n",
      "Epoch 00044: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.8742 - acc: 0.7855 - val_loss: 5.0254 - val_acc: 0.0661\n",
      "Epoch 45/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.4897 - acc: 0.9171\n",
      "Epoch 00045: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.4895 - acc: 0.9171 - val_loss: 5.1073 - val_acc: 0.0601\n",
      "Epoch 46/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.2696 - acc: 0.9771\n",
      "Epoch 00046: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.2698 - acc: 0.9769 - val_loss: 5.1533 - val_acc: 0.0706\n",
      "Epoch 47/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3545 - acc: 0.9521\n",
      "Epoch 00047: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3546 - acc: 0.9521 - val_loss: 5.1891 - val_acc: 0.0736\n",
      "Epoch 48/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3740 - acc: 0.9458\n",
      "Epoch 00048: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3742 - acc: 0.9459 - val_loss: 5.2686 - val_acc: 0.0706\n",
      "Epoch 49/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.3554 - acc: 0.9494\n",
      "Epoch 00049: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.3553 - acc: 0.9494 - val_loss: 5.2286 - val_acc: 0.0646\n",
      "Epoch 50/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 0.5894 - acc: 0.8763\n",
      "Epoch 00050: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 0.5897 - acc: 0.8761 - val_loss: 5.8031 - val_acc: 0.0706\n",
      "Epoch 51/2000\n",
      "4800/4802 [============================>.] - ETA: 0s - loss: 2.3515 - acc: 0.3733\n",
      "Epoch 00051: val_loss did not improve from 3.70785\n",
      "4802/4802 [==============================] - 6s 1ms/sample - loss: 2.3509 - acc: 0.3734 - val_loss: 5.3236 - val_acc: 0.0706\n",
      "Training time: 290.9959387779236 s\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 3.0783 - acc: 0.1842\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.abspath(os.path.join('models', dataset))):\n",
    "    os.mkdir(os.path.abspath(os.path.join('models', dataset)))\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "sdk = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "n_fold = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "epoch_per_fold = []\n",
    "loss_per_fold = []\n",
    "rec_per_fold = []\n",
    "prec_per_fold = []\n",
    "f1_per_fold = []\n",
    "\n",
    "for train, test in sdk.split(x_all, y_all):\n",
    "    \n",
    "    file_path = os.path.abspath(os.path.join('models', dataset, f'{dataset}-ladder_{n_fold}.hdf5'))\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=file_path, monitor='val_loss', save_best_only = True, mode = 'min', verbose = 1), \n",
    "        EarlyStopping(monitor = 'val_loss', patience = 50, mode = 'min')]\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    print(f\"Fold: {n_fold}\\n\")\n",
    "    result = model.fit(x_all[train], \n",
    "                       to_categorical(y_all[train]),\n",
    "                       epochs = 2000, \n",
    "                       batch_size = 100, \n",
    "                       validation_data = (x_valid, to_categorical(y_valid)), \n",
    "                       callbacks = callbacks)\n",
    "\n",
    "    print(f\"Training time: {time.time() - t} s\")\n",
    "\n",
    "    df_results = pd.DataFrame(result.history)\n",
    "    df_results.to_csv(os.path.abspath(os.path.join('models', dataset, f'ladder_results_{n_fold}.csv')))\n",
    "    \n",
    "    model.load_weights(file_path)\n",
    "    scores = model.evaluate(x_all[test], to_categorical(y_all[test]))\n",
    "    loss_per_fold.append(scores[0])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    epoch_per_fold.append(np.argmin(result.history['val_loss']))\n",
    "    \n",
    "    # Computing predictions\n",
    "    y_pred_test = np.argmax(model.predict(x_all[test]), axis = 1)\n",
    "    \n",
    "    f1_per_fold.append(f1_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    rec_per_fold.append(recall_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    prec_per_fold.append(precision_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    \n",
    "    n_fold += 1\n",
    "    \n",
    "df_scores = pd.DataFrame(columns = ['F1', 'Loss', 'Accuracy', 'Precision', 'Recall'])\n",
    "df_scores['F1'] = f1_per_fold\n",
    "df_scores['Loss'] = loss_per_fold\n",
    "df_scores['Accuracy'] = acc_per_fold\n",
    "df_scores['Precision'] = prec_per_fold\n",
    "df_scores['Recall'] = rec_per_fold\n",
    "\n",
    "df_scores.to_csv(os.path.abspath(os.path.join('models', dataset, f'ladder_results_k-Folds.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
