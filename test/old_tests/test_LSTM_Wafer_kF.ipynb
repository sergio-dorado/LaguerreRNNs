{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures_v1 import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training/Testing/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Instances: 716\n",
      "x_all: (6448, 152, 1) - y_all: (6448,)\n",
      "x_valid: (716, 152, 1) - y_valid: (716,)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Wafer\"\n",
    "model_name = \"LSTM\"\n",
    "\n",
    "x_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_train.npz')))\n",
    "x_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_test.npz')))\n",
    "\n",
    "x_train = np.reshape(x_train_load['arr_0'], [x_train_load['arr_0'].shape[0], x_train_load['arr_0'].shape[1], 1])\n",
    "x_test = np.reshape(x_test_load['arr_0'], [x_test_load['arr_0'].shape[0], x_test_load['arr_0'].shape[1], 1])\n",
    "\n",
    "x_all = np.concatenate((x_train, x_test), axis = 0)\n",
    "\n",
    "n_instances = x_all.shape[0]\n",
    "\n",
    "y_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_train.npz')))\n",
    "y_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_test.npz')))\n",
    "\n",
    "y_train = y_train_load['arr_0']\n",
    "y_test = y_test_load['arr_0']\n",
    "\n",
    "y_all = np.concatenate((y_train, y_test), axis = 0)\n",
    "y_all = np.asarray(y_all, dtype = np.uint64)\n",
    "\n",
    "n_validation = int(0.1*n_instances)\n",
    "print(f\"Validation Instances: {n_validation}\")\n",
    "\n",
    "ind_validation = random.sample(range(0, n_instances), n_validation)\n",
    "x_valid = x_all[ind_validation, :, :]\n",
    "y_valid = y_all[ind_validation]\n",
    "\n",
    "x_all = np.delete(x_all, ind_validation, axis = 0)\n",
    "y_all = np.delete(y_all, ind_validation, axis = 0)\n",
    "\n",
    "print(f\"x_all: {x_all.shape} - y_all: {y_all.shape}\")\n",
    "print(f\"x_valid: {x_valid.shape} - y_valid: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 212)               181472    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 426       \n",
      "=================================================================\n",
      "Total params: 181,898\n",
      "Trainable params: 181,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "length = x_all.shape[1]\n",
    "n_features = x_all.shape[-1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 212, \n",
    "              input_shape = (length, n_features), return_sequences = False))\n",
    "model.add(Dense(to_categorical(y_all).shape[-1], activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "\n",
      "WARNING:tensorflow:From /data/home/dorads/miniconda3/envs/sd_dev_tf_1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 5158 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3449 - acc: 0.8500\n",
      "Epoch 00001: val_loss improved from inf to 0.16252, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 15s 3ms/sample - loss: 0.3423 - acc: 0.8513 - val_loss: 0.1625 - val_acc: 0.9455\n",
      "Epoch 2/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9602\n",
      "Epoch 00002: val_loss improved from 0.16252 to 0.08390, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 13s 3ms/sample - loss: 0.1139 - acc: 0.9604 - val_loss: 0.0839 - val_acc: 0.9679\n",
      "Epoch 3/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9769\n",
      "Epoch 00003: val_loss improved from 0.08390 to 0.04158, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 14s 3ms/sample - loss: 0.0740 - acc: 0.9771 - val_loss: 0.0416 - val_acc: 0.9902\n",
      "Epoch 4/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9502\n",
      "Epoch 00004: val_loss did not improve from 0.04158\n",
      "5158/5158 [==============================] - 14s 3ms/sample - loss: 0.1142 - acc: 0.9506 - val_loss: 0.0680 - val_acc: 0.9623\n",
      "Epoch 5/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9851\n",
      "Epoch 00005: val_loss improved from 0.04158 to 0.03410, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 13s 3ms/sample - loss: 0.0489 - acc: 0.9851 - val_loss: 0.0341 - val_acc: 0.9930\n",
      "Epoch 6/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9857\n",
      "Epoch 00006: val_loss improved from 0.03410 to 0.02941, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0393 - acc: 0.9858 - val_loss: 0.0294 - val_acc: 0.9874\n",
      "Epoch 7/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9892\n",
      "Epoch 00007: val_loss did not improve from 0.02941\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0313 - acc: 0.9893 - val_loss: 0.0593 - val_acc: 0.9735\n",
      "Epoch 8/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9910\n",
      "Epoch 00008: val_loss improved from 0.02941 to 0.02512, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0306 - acc: 0.9907 - val_loss: 0.0251 - val_acc: 0.9930\n",
      "Epoch 9/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9908\n",
      "Epoch 00009: val_loss improved from 0.02512 to 0.02425, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0289 - acc: 0.9909 - val_loss: 0.0243 - val_acc: 0.9902\n",
      "Epoch 10/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9916\n",
      "Epoch 00010: val_loss did not improve from 0.02425\n",
      "5158/5158 [==============================] - 13s 2ms/sample - loss: 0.0243 - acc: 0.9915 - val_loss: 0.0388 - val_acc: 0.9846\n",
      "Epoch 11/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9831\n",
      "Epoch 00011: val_loss did not improve from 0.02425\n",
      "5158/5158 [==============================] - 13s 2ms/sample - loss: 0.0433 - acc: 0.9833 - val_loss: 0.0410 - val_acc: 0.9832\n",
      "Epoch 12/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9839\n",
      "Epoch 00012: val_loss did not improve from 0.02425\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0407 - acc: 0.9841 - val_loss: 0.0251 - val_acc: 0.9958\n",
      "Epoch 13/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9931\n",
      "Epoch 00013: val_loss improved from 0.02425 to 0.01785, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0246 - acc: 0.9928 - val_loss: 0.0179 - val_acc: 0.9944\n",
      "Epoch 14/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9945\n",
      "Epoch 00014: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0186 - acc: 0.9946 - val_loss: 0.0211 - val_acc: 0.9930\n",
      "Epoch 15/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9875\n",
      "Epoch 00015: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0359 - acc: 0.9876 - val_loss: 0.0569 - val_acc: 0.9763\n",
      "Epoch 16/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9910\n",
      "Epoch 00016: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0258 - acc: 0.9911 - val_loss: 0.0259 - val_acc: 0.9888\n",
      "Epoch 17/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9890\n",
      "Epoch 00017: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0322 - acc: 0.9889 - val_loss: 0.0279 - val_acc: 0.9888\n",
      "Epoch 18/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9916\n",
      "Epoch 00018: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 13s 2ms/sample - loss: 0.0300 - acc: 0.9917 - val_loss: 0.0255 - val_acc: 0.9916\n",
      "Epoch 19/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9929\n",
      "Epoch 00019: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0228 - acc: 0.9926 - val_loss: 0.0247 - val_acc: 0.9902\n",
      "Epoch 20/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9912\n",
      "Epoch 00020: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0260 - acc: 0.9911 - val_loss: 0.0187 - val_acc: 0.9972\n",
      "Epoch 21/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9861\n",
      "Epoch 00021: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 13s 2ms/sample - loss: 0.0373 - acc: 0.9862 - val_loss: 0.0267 - val_acc: 0.9944\n",
      "Epoch 22/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9916\n",
      "Epoch 00022: val_loss did not improve from 0.01785\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0237 - acc: 0.9915 - val_loss: 0.0221 - val_acc: 0.9916\n",
      "Epoch 23/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9922\n",
      "Epoch 00023: val_loss improved from 0.01785 to 0.01455, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_1.hdf5\n",
      "5158/5158 [==============================] - 13s 2ms/sample - loss: 0.0228 - acc: 0.9922 - val_loss: 0.0146 - val_acc: 0.9972\n",
      "Epoch 24/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9894\n",
      "Epoch 00024: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 13s 3ms/sample - loss: 0.0274 - acc: 0.9895 - val_loss: 0.0206 - val_acc: 0.9944\n",
      "Epoch 25/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.4362 - acc: 0.8967\n",
      "Epoch 00025: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 13s 2ms/sample - loss: 0.4347 - acc: 0.8969 - val_loss: 0.3619 - val_acc: 0.8855\n",
      "Epoch 26/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3412 - acc: 0.8941\n",
      "Epoch 00026: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3404 - acc: 0.8945 - val_loss: 0.3690 - val_acc: 0.8855\n",
      "Epoch 27/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.8941\n",
      "Epoch 00027: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 13s 2ms/sample - loss: 0.3379 - acc: 0.8945 - val_loss: 0.3607 - val_acc: 0.8855\n",
      "Epoch 28/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3419 - acc: 0.8943\n",
      "Epoch 00028: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 13s 2ms/sample - loss: 0.3414 - acc: 0.8945 - val_loss: 0.3572 - val_acc: 0.8855\n",
      "Epoch 29/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3365 - acc: 0.8941\n",
      "Epoch 00029: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3357 - acc: 0.8945 - val_loss: 0.3510 - val_acc: 0.8855\n",
      "Epoch 30/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3358 - acc: 0.8945\n",
      "Epoch 00030: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3356 - acc: 0.8945 - val_loss: 0.3507 - val_acc: 0.8855\n",
      "Epoch 31/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3337 - acc: 0.8943\n",
      "Epoch 00031: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3332 - acc: 0.8945 - val_loss: 0.3495 - val_acc: 0.8855\n",
      "Epoch 32/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.8945\n",
      "Epoch 00032: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3278 - acc: 0.8945 - val_loss: 0.3198 - val_acc: 0.8855\n",
      "Epoch 33/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.2977 - acc: 0.9024\n",
      "Epoch 00033: val_loss did not improve from 0.01455\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.2977 - acc: 0.9023 - val_loss: 0.2965 - val_acc: 0.8869\n",
      "Training time: 415.58604311943054 s\n",
      "1290/1290 [==============================] - 2s 2ms/sample - loss: 0.0170 - acc: 0.9953\n",
      "\n",
      "Fold: 2\n",
      "\n",
      "Train on 5158 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9945\n",
      "Epoch 00001: val_loss improved from inf to 0.04173, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_2.hdf5\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0417 - val_acc: 0.9860\n",
      "Epoch 2/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9945\n",
      "Epoch 00002: val_loss improved from 0.04173 to 0.01600, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_2.hdf5\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0190 - acc: 0.9942 - val_loss: 0.0160 - val_acc: 0.9958\n",
      "Epoch 3/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9949\n",
      "Epoch 00003: val_loss did not improve from 0.01600\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0165 - acc: 0.9946 - val_loss: 0.0265 - val_acc: 0.9902\n",
      "Epoch 4/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9929\n",
      "Epoch 00004: val_loss improved from 0.01600 to 0.01407, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_2.hdf5\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0193 - acc: 0.9930 - val_loss: 0.0141 - val_acc: 0.9972\n",
      "Epoch 5/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9945\n",
      "Epoch 00005: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0178 - acc: 0.9946 - val_loss: 0.0142 - val_acc: 0.9972\n",
      "Epoch 6/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9937\n",
      "Epoch 00006: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0186 - acc: 0.9938 - val_loss: 0.0251 - val_acc: 0.9888\n",
      "Epoch 7/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9931\n",
      "Epoch 00007: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0209 - acc: 0.9930 - val_loss: 0.0177 - val_acc: 0.9944\n",
      "Epoch 8/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 00008: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0168 - val_acc: 0.9958\n",
      "Epoch 9/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9929\n",
      "Epoch 00009: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0207 - acc: 0.9930 - val_loss: 0.0202 - val_acc: 0.9930\n",
      "Epoch 10/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9939\n",
      "Epoch 00010: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0182 - acc: 0.9936 - val_loss: 0.0207 - val_acc: 0.9930\n",
      "Epoch 11/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9916\n",
      "Epoch 00011: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0238 - acc: 0.9917 - val_loss: 0.0157 - val_acc: 0.9944\n",
      "Epoch 12/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9890\n",
      "Epoch 00012: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0286 - acc: 0.9888 - val_loss: 0.0249 - val_acc: 0.9916\n",
      "Epoch 13/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9933\n",
      "Epoch 00013: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0203 - val_acc: 0.9972\n",
      "Epoch 14/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9951\n",
      "Epoch 00014: val_loss did not improve from 0.01407\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0161 - acc: 0.9952 - val_loss: 0.0173 - val_acc: 0.9958\n",
      "Training time: 169.72696924209595 s\n",
      "1290/1290 [==============================] - 2s 2ms/sample - loss: 0.0191 - acc: 0.9953\n",
      "\n",
      "Fold: 3\n",
      "\n",
      "Train on 5158 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9949\n",
      "Epoch 00001: val_loss improved from inf to 0.03315, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_3.hdf5\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0183 - acc: 0.9950 - val_loss: 0.0331 - val_acc: 0.9818\n",
      "Epoch 2/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9853\n",
      "Epoch 00002: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.0431 - acc: 0.9855 - val_loss: 0.0342 - val_acc: 0.9874\n",
      "Epoch 3/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9447\n",
      "Epoch 00003: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.1187 - acc: 0.9432 - val_loss: 0.5419 - val_acc: 0.8855\n",
      "Epoch 4/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3634 - acc: 0.8941\n",
      "Epoch 00004: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3619 - acc: 0.8945 - val_loss: 0.3748 - val_acc: 0.8855\n",
      "Epoch 5/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.8945\n",
      "Epoch 00005: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3340 - acc: 0.8945 - val_loss: 0.3454 - val_acc: 0.8855\n",
      "Epoch 6/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.8978\n",
      "Epoch 00006: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.2924 - acc: 0.8982 - val_loss: 0.2793 - val_acc: 0.8925\n",
      "Epoch 7/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8953\n",
      "Epoch 00007: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3401 - acc: 0.8955 - val_loss: 0.3595 - val_acc: 0.8855\n",
      "Epoch 8/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.8951\n",
      "Epoch 00008: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3375 - acc: 0.8945 - val_loss: 0.3549 - val_acc: 0.8855\n",
      "Epoch 9/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3356 - acc: 0.8953\n",
      "Epoch 00009: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3369 - acc: 0.8945 - val_loss: 0.3707 - val_acc: 0.8855\n",
      "Epoch 10/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3420 - acc: 0.8945\n",
      "Epoch 00010: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3419 - acc: 0.8945 - val_loss: 0.3607 - val_acc: 0.8855\n",
      "Epoch 11/200\n",
      "5100/5158 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.8947\n",
      "Epoch 00011: val_loss did not improve from 0.03315\n",
      "5158/5158 [==============================] - 12s 2ms/sample - loss: 0.3366 - acc: 0.8945 - val_loss: 0.3575 - val_acc: 0.8855\n",
      "Training time: 133.69326543807983 s\n",
      "1290/1290 [==============================] - 2s 2ms/sample - loss: 0.0312 - acc: 0.9884\n",
      "\n",
      "Fold: 4\n",
      "\n",
      "Train on 5159 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9935\n",
      "Epoch 00001: val_loss improved from inf to 0.01485, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_4.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0208 - acc: 0.9936 - val_loss: 0.0149 - val_acc: 0.9958\n",
      "Epoch 2/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9894\n",
      "Epoch 00002: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0344 - acc: 0.9895 - val_loss: 0.0226 - val_acc: 0.9930\n",
      "Epoch 3/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9943\n",
      "Epoch 00003: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0197 - acc: 0.9944 - val_loss: 0.0155 - val_acc: 0.9972\n",
      "Epoch 4/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9939\n",
      "Epoch 00004: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0212 - acc: 0.9940 - val_loss: 0.0161 - val_acc: 0.9944\n",
      "Epoch 5/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9904\n",
      "Epoch 00005: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0267 - acc: 0.9905 - val_loss: 0.0155 - val_acc: 0.9944\n",
      "Epoch 6/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9935\n",
      "Epoch 00006: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0211 - val_acc: 0.9958\n",
      "Epoch 7/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9933\n",
      "Epoch 00007: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 13s 2ms/sample - loss: 0.0201 - acc: 0.9934 - val_loss: 0.0179 - val_acc: 0.9958\n",
      "Epoch 8/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9924\n",
      "Epoch 00008: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0225 - acc: 0.9924 - val_loss: 0.0150 - val_acc: 0.9958\n",
      "Epoch 9/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9959\n",
      "Epoch 00009: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0160 - acc: 0.9959 - val_loss: 0.0164 - val_acc: 0.9944\n",
      "Epoch 10/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9945\n",
      "Epoch 00010: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0157 - val_acc: 0.9972\n",
      "Epoch 11/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9753\n",
      "Epoch 00011: val_loss did not improve from 0.01485\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1100 - acc: 0.9719 - val_loss: 0.7046 - val_acc: 0.7514\n",
      "Training time: 133.2568941116333 s\n",
      "1289/1289 [==============================] - 2s 2ms/sample - loss: 0.0198 - acc: 0.9930\n",
      "\n",
      "Fold: 5\n",
      "\n",
      "Train on 5159 samples, validate on 716 samples\n",
      "Epoch 1/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.8627\n",
      "Epoch 00001: val_loss improved from inf to 0.36013, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 13s 3ms/sample - loss: 0.4611 - acc: 0.8635 - val_loss: 0.3601 - val_acc: 0.8855\n",
      "Epoch 2/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3399 - acc: 0.8941\n",
      "Epoch 00002: val_loss did not improve from 0.36013\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3389 - acc: 0.8946 - val_loss: 0.3609 - val_acc: 0.8855\n",
      "Epoch 3/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3383 - acc: 0.8943\n",
      "Epoch 00003: val_loss did not improve from 0.36013\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3381 - acc: 0.8946 - val_loss: 0.3643 - val_acc: 0.8855\n",
      "Epoch 4/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3407 - acc: 0.8947\n",
      "Epoch 00004: val_loss improved from 0.36013 to 0.35598, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 13s 2ms/sample - loss: 0.3410 - acc: 0.8946 - val_loss: 0.3560 - val_acc: 0.8855\n",
      "Epoch 5/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3395 - acc: 0.8947\n",
      "Epoch 00005: val_loss did not improve from 0.35598\n",
      "5159/5159 [==============================] - 14s 3ms/sample - loss: 0.3399 - acc: 0.8946 - val_loss: 0.3676 - val_acc: 0.8855\n",
      "Epoch 6/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3391 - acc: 0.8945\n",
      "Epoch 00006: val_loss improved from 0.35598 to 0.35516, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3390 - acc: 0.8946 - val_loss: 0.3552 - val_acc: 0.8855\n",
      "Epoch 7/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3390 - acc: 0.8943\n",
      "Epoch 00007: val_loss improved from 0.35516 to 0.35453, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3385 - acc: 0.8946 - val_loss: 0.3545 - val_acc: 0.8855\n",
      "Epoch 8/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.8943\n",
      "Epoch 00008: val_loss did not improve from 0.35453\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3384 - acc: 0.8946 - val_loss: 0.3562 - val_acc: 0.8855\n",
      "Epoch 9/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3349 - acc: 0.8949\n",
      "Epoch 00009: val_loss improved from 0.35453 to 0.35223, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3358 - acc: 0.8946 - val_loss: 0.3522 - val_acc: 0.8855\n",
      "Epoch 10/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3386 - acc: 0.8947\n",
      "Epoch 00010: val_loss did not improve from 0.35223\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3389 - acc: 0.8946 - val_loss: 0.3556 - val_acc: 0.8855\n",
      "Epoch 11/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3346 - acc: 0.8947\n",
      "Epoch 00011: val_loss improved from 0.35223 to 0.34987, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 13s 3ms/sample - loss: 0.3350 - acc: 0.8946 - val_loss: 0.3499 - val_acc: 0.8855\n",
      "Epoch 12/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3346 - acc: 0.8941\n",
      "Epoch 00012: val_loss did not improve from 0.34987\n",
      "5159/5159 [==============================] - 13s 2ms/sample - loss: 0.3336 - acc: 0.8946 - val_loss: 0.3619 - val_acc: 0.8855\n",
      "Epoch 13/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3302 - acc: 0.8947\n",
      "Epoch 00013: val_loss improved from 0.34987 to 0.34144, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3304 - acc: 0.8946 - val_loss: 0.3414 - val_acc: 0.8855\n",
      "Epoch 14/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.2951 - acc: 0.8992\n",
      "Epoch 00014: val_loss did not improve from 0.34144\n",
      "5159/5159 [==============================] - 13s 2ms/sample - loss: 0.2959 - acc: 0.8996 - val_loss: 0.5801 - val_acc: 0.8855\n",
      "Epoch 15/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3504 - acc: 0.8945\n",
      "Epoch 00015: val_loss did not improve from 0.34144\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3501 - acc: 0.8946 - val_loss: 0.3541 - val_acc: 0.8855\n",
      "Epoch 16/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.9006\n",
      "Epoch 00016: val_loss did not improve from 0.34144\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.2812 - acc: 0.9006 - val_loss: 0.3541 - val_acc: 0.8855\n",
      "Epoch 17/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3359 - acc: 0.8943\n",
      "Epoch 00017: val_loss improved from 0.34144 to 0.34122, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3354 - acc: 0.8946 - val_loss: 0.3412 - val_acc: 0.8855\n",
      "Epoch 18/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3263 - acc: 0.8945\n",
      "Epoch 00018: val_loss improved from 0.34122 to 0.32689, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3263 - acc: 0.8946 - val_loss: 0.3269 - val_acc: 0.8855\n",
      "Epoch 19/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3138 - acc: 0.8951\n",
      "Epoch 00019: val_loss improved from 0.32689 to 0.31589, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3146 - acc: 0.8946 - val_loss: 0.3159 - val_acc: 0.8855\n",
      "Epoch 20/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.8947\n",
      "Epoch 00020: val_loss improved from 0.31589 to 0.27434, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.2861 - acc: 0.8946 - val_loss: 0.2743 - val_acc: 0.8855\n",
      "Epoch 21/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.2436 - acc: 0.8971\n",
      "Epoch 00021: val_loss did not improve from 0.27434\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.2449 - acc: 0.8969 - val_loss: 0.3137 - val_acc: 0.8855\n",
      "Epoch 22/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9024\n",
      "Epoch 00022: val_loss did not improve from 0.27434\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.2884 - acc: 0.9017 - val_loss: 0.3672 - val_acc: 0.8855\n",
      "Epoch 23/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3228 - acc: 0.8947\n",
      "Epoch 00023: val_loss did not improve from 0.27434\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3223 - acc: 0.8949 - val_loss: 0.3277 - val_acc: 0.8855\n",
      "Epoch 24/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3187 - acc: 0.8973\n",
      "Epoch 00024: val_loss did not improve from 0.27434\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3208 - acc: 0.8965 - val_loss: 0.3380 - val_acc: 0.8855\n",
      "Epoch 25/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3103 - acc: 0.8973\n",
      "Epoch 00025: val_loss did not improve from 0.27434\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3109 - acc: 0.8967 - val_loss: 0.2979 - val_acc: 0.8855\n",
      "Epoch 26/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9227\n",
      "Epoch 00026: val_loss improved from 0.27434 to 0.21944, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 13s 2ms/sample - loss: 0.2234 - acc: 0.9234 - val_loss: 0.2194 - val_acc: 0.9190\n",
      "Epoch 27/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1894 - acc: 0.9369\n",
      "Epoch 00027: val_loss did not improve from 0.21944\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1914 - acc: 0.9362 - val_loss: 0.3337 - val_acc: 0.8855\n",
      "Epoch 28/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9257\n",
      "Epoch 00028: val_loss improved from 0.21944 to 0.17324, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.2199 - acc: 0.9263 - val_loss: 0.1732 - val_acc: 0.9581\n",
      "Epoch 29/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9567\n",
      "Epoch 00029: val_loss improved from 0.17324 to 0.15154, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1481 - acc: 0.9570 - val_loss: 0.1515 - val_acc: 0.9497\n",
      "Epoch 30/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9547\n",
      "Epoch 00030: val_loss did not improve from 0.15154\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1460 - acc: 0.9548 - val_loss: 0.3527 - val_acc: 0.8980\n",
      "Epoch 31/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9516\n",
      "Epoch 00031: val_loss improved from 0.15154 to 0.14076, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1516 - acc: 0.9521 - val_loss: 0.1408 - val_acc: 0.9553\n",
      "Epoch 32/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9584\n",
      "Epoch 00032: val_loss improved from 0.14076 to 0.13402, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1323 - acc: 0.9581 - val_loss: 0.1340 - val_acc: 0.9609\n",
      "Epoch 33/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9625\n",
      "Epoch 00033: val_loss did not improve from 0.13402\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1222 - acc: 0.9622 - val_loss: 0.1362 - val_acc: 0.9539\n",
      "Epoch 34/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9592\n",
      "Epoch 00034: val_loss improved from 0.13402 to 0.12989, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 13s 2ms/sample - loss: 0.1249 - acc: 0.9593 - val_loss: 0.1299 - val_acc: 0.9609\n",
      "Epoch 35/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9600\n",
      "Epoch 00035: val_loss improved from 0.12989 to 0.11318, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1215 - acc: 0.9601 - val_loss: 0.1132 - val_acc: 0.9609\n",
      "Epoch 36/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9637\n",
      "Epoch 00036: val_loss improved from 0.11318 to 0.06625, saving model to /data/home/dorads/Documents/GitHub_Repos/01_Maintained/NeuralODE/models/Wafer/Wafer-LSTM_5.hdf5\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0926 - acc: 0.9639 - val_loss: 0.0663 - val_acc: 0.9679\n",
      "Epoch 37/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9737\n",
      "Epoch 00037: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0801 - acc: 0.9731 - val_loss: 0.1309 - val_acc: 0.9609\n",
      "Epoch 38/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9659\n",
      "Epoch 00038: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0980 - acc: 0.9663 - val_loss: 0.1128 - val_acc: 0.9553\n",
      "Epoch 39/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9625\n",
      "Epoch 00039: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.0935 - acc: 0.9626 - val_loss: 0.1343 - val_acc: 0.9609\n",
      "Epoch 40/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.8976\n",
      "Epoch 00040: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3334 - acc: 0.8980 - val_loss: 0.3476 - val_acc: 0.8855\n",
      "Epoch 41/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.3014 - acc: 0.8957\n",
      "Epoch 00041: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.3025 - acc: 0.8951 - val_loss: 0.2906 - val_acc: 0.8869\n",
      "Epoch 42/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.2261 - acc: 0.9196\n",
      "Epoch 00042: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.2254 - acc: 0.9199 - val_loss: 0.1754 - val_acc: 0.9567\n",
      "Epoch 43/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9484\n",
      "Epoch 00043: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1666 - acc: 0.9482 - val_loss: 0.1555 - val_acc: 0.9553\n",
      "Epoch 44/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9545\n",
      "Epoch 00044: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 13s 2ms/sample - loss: 0.1501 - acc: 0.9539 - val_loss: 0.2287 - val_acc: 0.9148\n",
      "Epoch 45/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9541\n",
      "Epoch 00045: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 13s 3ms/sample - loss: 0.1456 - acc: 0.9543 - val_loss: 0.1391 - val_acc: 0.9609\n",
      "Epoch 46/200\n",
      "5100/5159 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9586\n",
      "Epoch 00046: val_loss did not improve from 0.06625\n",
      "5159/5159 [==============================] - 12s 2ms/sample - loss: 0.1363 - acc: 0.9585 - val_loss: 0.1334 - val_acc: 0.9609\n",
      "Training time: 568.3262169361115 s\n",
      "1289/1289 [==============================] - 2s 2ms/sample - loss: 0.0862 - acc: 0.9620\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.abspath(os.path.join('models', dataset))):\n",
    "    os.mkdir(os.path.abspath(os.path.join('models', dataset)))\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "sdk = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "df_tpr = pd.DataFrame(columns = [1, 2, 3, 4, 5])\n",
    "df_fpr = pd.DataFrame(columns = [1, 2, 3, 4, 5])\n",
    "\n",
    "n_fold = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "epoch_per_fold = []\n",
    "loss_per_fold = []\n",
    "rec_per_fold = []\n",
    "prec_per_fold = []\n",
    "f1_per_fold = []\n",
    "auroc_per_fold = []\n",
    "fpr_per_fold = []\n",
    "tpr_per_fold = []\n",
    "\n",
    "for train, test in sdk.split(x_all, y_all):\n",
    "    \n",
    "    file_path = os.path.abspath(os.path.join('models', dataset, f'{dataset}-{model_name}_{n_fold}.hdf5'))\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=file_path, monitor='val_loss', save_best_only = True, mode = 'min', verbose = 1), \n",
    "        EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min')]\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    print(f\"\\nFold: {n_fold}\\n\")\n",
    "    result = model.fit(x_all[train], \n",
    "                       to_categorical(y_all[train]),\n",
    "                       epochs = 200, \n",
    "                       batch_size = 100, \n",
    "                       validation_data = (x_valid, to_categorical(y_valid)), \n",
    "                       callbacks = callbacks)\n",
    "\n",
    "    print(f\"Training time: {time.time() - t} s\")\n",
    "\n",
    "    df_results = pd.DataFrame(result.history)\n",
    "    df_results.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_{n_fold}.csv')))\n",
    "    \n",
    "    model.load_weights(file_path)\n",
    "    scores = model.evaluate(x_all[test], to_categorical(y_all[test]))\n",
    "    loss_per_fold.append(scores[0])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    epoch_per_fold.append(np.argmin(result.history['val_loss']))\n",
    "    \n",
    "    # Computing predictions\n",
    "    y_pred_test = np.argmax(model.predict(x_all[test]), axis = 1)\n",
    "    \n",
    "    # Getting performance scores per fold\n",
    "    f1_per_fold.append(f1_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    rec_per_fold.append(recall_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    prec_per_fold.append(precision_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    auroc_per_fold.append(roc_auc_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    \n",
    "    # Getting ROC curve for this binary classification task\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_all[test], y_pred_test)\n",
    "    \n",
    "    df_fpr[n_fold] = fpr\n",
    "    df_tpr[n_fold] = tpr\n",
    "        \n",
    "    n_fold += 1\n",
    "\n",
    "df_scores = pd.DataFrame(columns = ['F1', 'Loss', 'Accuracy', 'Precision', 'Recall', 'AUROC'])\n",
    "df_scores['F1'] = f1_per_fold\n",
    "df_scores['Loss'] = loss_per_fold\n",
    "df_scores['Accuracy'] = acc_per_fold\n",
    "df_scores['Precision'] = prec_per_fold\n",
    "df_scores['Recall'] = rec_per_fold\n",
    "df_scores['AUROC'] = auroc_per_fold\n",
    "\n",
    "df_scores.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds.csv')))\n",
    "df_tpr.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds_tpr.csv')))\n",
    "df_fpr.to_csv(os.path.abspath(os.path.join('models', dataset, f'{model_name}_results_k-Folds_fpr.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
