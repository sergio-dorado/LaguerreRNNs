{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures_v1 import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training/Testing/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Instances: 10992\n",
      "Validation Instances: 1099\n",
      "x_all: (9893, 8, 2) - y_all: (9893,)\n",
      "x_valid: (1099, 8, 2) - y_valid: (1099,)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"PenDigits\"\n",
    "\n",
    "x_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_train.npz')))\n",
    "x_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'x_test.npz')))\n",
    "\n",
    "x_train = x_train_load['arr_0']\n",
    "x_test = x_test_load['arr_0']\n",
    "\n",
    "x_all = np.concatenate((x_train, x_test), axis = 0)\n",
    "\n",
    "n_instances = x_all.shape[0]\n",
    "print(f\"Total Instances: {n_instances}\")\n",
    "\n",
    "y_train_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_train.npz')))\n",
    "y_test_load = np.load(os.path.abspath(os.path.join('99_data', dataset,'y_test.npz')))\n",
    "\n",
    "y_train = np.asarray(y_train_load['arr_0'], dtype = np.uint64)\n",
    "y_test = np.asarray(y_test_load['arr_0'], dtype = np.uint64)\n",
    "\n",
    "y_all = np.concatenate((y_train, y_test), axis = 0)\n",
    "\n",
    "n_validation = int(0.1*n_instances)\n",
    "print(f\"Validation Instances: {n_validation}\")\n",
    "\n",
    "ind_validation = random.sample(range(0, n_instances), n_validation)\n",
    "x_valid = x_all[ind_validation, :, :]\n",
    "y_valid = y_all[ind_validation]\n",
    "\n",
    "x_all = np.delete(x_all, ind_validation, axis = 0)\n",
    "y_all = np.delete(y_all, ind_validation, axis = 0)\n",
    "\n",
    "print(f\"x_all: {x_all.shape} - y_all: {y_all.shape}\")\n",
    "print(f\"x_valid: {x_valid.shape} - y_valid: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_1 (RNN)                  (None, 212)               166418    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2130      \n",
      "=================================================================\n",
      "Total params: 168,548\n",
      "Trainable params: 102,496\n",
      "Non-trainable params: 66,052\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "length = x_all.shape[1]\n",
    "n_features = x_all.shape[-1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(RNN(OrthogonalCell(units = 212,\n",
    "                             order = 256,\n",
    "                             variant = 'ct_laguerre',\n",
    "                             dt = 1,\n",
    "                            input_dims = n_features), \n",
    "              input_shape = (length, n_features),\n",
    "             return_sequences = False))\n",
    "model.add(Dense(to_categorical(y_all).shape[-1], activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "\n",
      "Train on 7914 samples, validate on 1099 samples\n",
      "Epoch 1/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 1.0784 - acc: 0.6521\n",
      "Epoch 00001: val_loss improved from inf to 0.79744, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 163us/sample - loss: 1.0711 - acc: 0.6549 - val_loss: 0.7974 - val_acc: 0.7580\n",
      "Epoch 2/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.6292 - acc: 0.7871\n",
      "Epoch 00002: val_loss improved from 0.79744 to 0.62075, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.6260 - acc: 0.7885 - val_loss: 0.6208 - val_acc: 0.7962\n",
      "Epoch 3/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.5126 - acc: 0.8232\n",
      "Epoch 00003: val_loss improved from 0.62075 to 0.48239, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.5104 - acc: 0.8239 - val_loss: 0.4824 - val_acc: 0.8362\n",
      "Epoch 4/2000\n",
      "7300/7914 [==========================>...] - ETA: 0s - loss: 0.4370 - acc: 0.8537\n",
      "Epoch 00004: val_loss did not improve from 0.48239\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.4339 - acc: 0.8547 - val_loss: 0.5125 - val_acc: 0.8144\n",
      "Epoch 5/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.3962 - acc: 0.8618\n",
      "Epoch 00005: val_loss improved from 0.48239 to 0.39065, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 104us/sample - loss: 0.3956 - acc: 0.8621 - val_loss: 0.3906 - val_acc: 0.8662\n",
      "Epoch 6/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8878\n",
      "Epoch 00006: val_loss improved from 0.39065 to 0.38075, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 102us/sample - loss: 0.3398 - acc: 0.8870 - val_loss: 0.3808 - val_acc: 0.8699\n",
      "Epoch 7/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.3320 - acc: 0.8878\n",
      "Epoch 00007: val_loss improved from 0.38075 to 0.36260, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 99us/sample - loss: 0.3317 - acc: 0.8879 - val_loss: 0.3626 - val_acc: 0.8817\n",
      "Epoch 8/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.2905 - acc: 0.9045\n",
      "Epoch 00008: val_loss improved from 0.36260 to 0.35276, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 101us/sample - loss: 0.2899 - acc: 0.9050 - val_loss: 0.3528 - val_acc: 0.8835\n",
      "Epoch 9/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.2846 - acc: 0.9022\n",
      "Epoch 00009: val_loss did not improve from 0.35276\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.2859 - acc: 0.9027 - val_loss: 0.3535 - val_acc: 0.8817\n",
      "Epoch 10/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.2782 - acc: 0.9072\n",
      "Epoch 00010: val_loss improved from 0.35276 to 0.30982, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 101us/sample - loss: 0.2780 - acc: 0.9074 - val_loss: 0.3098 - val_acc: 0.8972\n",
      "Epoch 11/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.2548 - acc: 0.9178\n",
      "Epoch 00011: val_loss did not improve from 0.30982\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.2574 - acc: 0.9161 - val_loss: 0.3423 - val_acc: 0.8835\n",
      "Epoch 12/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.2568 - acc: 0.9129\n",
      "Epoch 00012: val_loss improved from 0.30982 to 0.28720, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.2551 - acc: 0.9142 - val_loss: 0.2872 - val_acc: 0.9081\n",
      "Epoch 13/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.2394 - acc: 0.9171\n",
      "Epoch 00013: val_loss improved from 0.28720 to 0.24814, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 100us/sample - loss: 0.2382 - acc: 0.9175 - val_loss: 0.2481 - val_acc: 0.9281\n",
      "Epoch 14/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.2321 - acc: 0.9201\n",
      "Epoch 00014: val_loss did not improve from 0.24814\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.2302 - acc: 0.9212 - val_loss: 0.2498 - val_acc: 0.9245\n",
      "Epoch 15/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.2233 - acc: 0.9222\n",
      "Epoch 00015: val_loss did not improve from 0.24814\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.2219 - acc: 0.9229 - val_loss: 0.2499 - val_acc: 0.9263\n",
      "Epoch 16/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.2052 - acc: 0.9269\n",
      "Epoch 00016: val_loss did not improve from 0.24814\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.2062 - acc: 0.9270 - val_loss: 0.2939 - val_acc: 0.9117\n",
      "Epoch 17/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.2040 - acc: 0.9293\n",
      "Epoch 00017: val_loss improved from 0.24814 to 0.23594, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.2046 - acc: 0.9295 - val_loss: 0.2359 - val_acc: 0.9263\n",
      "Epoch 18/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.2007 - acc: 0.9316\n",
      "Epoch 00018: val_loss did not improve from 0.23594\n",
      "7914/7914 [==============================] - 1s 100us/sample - loss: 0.2009 - acc: 0.9315 - val_loss: 0.2370 - val_acc: 0.9236\n",
      "Epoch 19/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1909 - acc: 0.9326\n",
      "Epoch 00019: val_loss improved from 0.23594 to 0.22806, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 101us/sample - loss: 0.1923 - acc: 0.9321 - val_loss: 0.2281 - val_acc: 0.9281\n",
      "Epoch 20/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1835 - acc: 0.9363\n",
      "Epoch 00020: val_loss improved from 0.22806 to 0.21906, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 100us/sample - loss: 0.1836 - acc: 0.9363 - val_loss: 0.2191 - val_acc: 0.9345\n",
      "Epoch 21/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1776 - acc: 0.9372\n",
      "Epoch 00021: val_loss did not improve from 0.21906\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1773 - acc: 0.9373 - val_loss: 0.2216 - val_acc: 0.9263\n",
      "Epoch 22/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1661 - acc: 0.9436\n",
      "Epoch 00022: val_loss did not improve from 0.21906\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.1675 - acc: 0.9433 - val_loss: 0.2528 - val_acc: 0.9181\n",
      "Epoch 23/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1776 - acc: 0.9351\n",
      "Epoch 00023: val_loss improved from 0.21906 to 0.21029, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 101us/sample - loss: 0.1778 - acc: 0.9351 - val_loss: 0.2103 - val_acc: 0.9336\n",
      "Epoch 24/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1868 - acc: 0.9307\n",
      "Epoch 00024: val_loss did not improve from 0.21029\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1829 - acc: 0.9323 - val_loss: 0.2275 - val_acc: 0.9272\n",
      "Epoch 25/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1607 - acc: 0.9423\n",
      "Epoch 00025: val_loss did not improve from 0.21029\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1594 - acc: 0.9433 - val_loss: 0.2126 - val_acc: 0.9308\n",
      "Epoch 26/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.1621 - acc: 0.9432\n",
      "Epoch 00026: val_loss improved from 0.21029 to 0.20599, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 102us/sample - loss: 0.1613 - acc: 0.9434 - val_loss: 0.2060 - val_acc: 0.9336\n",
      "Epoch 27/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9461\n",
      "Epoch 00027: val_loss did not improve from 0.20599\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.1511 - acc: 0.9467 - val_loss: 0.2155 - val_acc: 0.9390\n",
      "Epoch 28/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9501\n",
      "Epoch 00028: val_loss did not improve from 0.20599\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.1450 - acc: 0.9502 - val_loss: 0.2222 - val_acc: 0.9290\n",
      "Epoch 29/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1470 - acc: 0.9475\n",
      "Epoch 00029: val_loss improved from 0.20599 to 0.20361, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 100us/sample - loss: 0.1475 - acc: 0.9464 - val_loss: 0.2036 - val_acc: 0.9345\n",
      "Epoch 30/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9476\n",
      "Epoch 00030: val_loss did not improve from 0.20361\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1466 - acc: 0.9476 - val_loss: 0.2642 - val_acc: 0.9126\n",
      "Epoch 31/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9458\n",
      "Epoch 00031: val_loss did not improve from 0.20361\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.1469 - acc: 0.9458 - val_loss: 0.2063 - val_acc: 0.9318\n",
      "Epoch 32/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1325 - acc: 0.9512\n",
      "Epoch 00032: val_loss did not improve from 0.20361\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1338 - acc: 0.9512 - val_loss: 0.2565 - val_acc: 0.9172\n",
      "Epoch 33/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9489\n",
      "Epoch 00033: val_loss did not improve from 0.20361\n",
      "7914/7914 [==============================] - 1s 99us/sample - loss: 0.1362 - acc: 0.9487 - val_loss: 0.2041 - val_acc: 0.9372\n",
      "Epoch 34/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.1424 - acc: 0.9486\n",
      "Epoch 00034: val_loss did not improve from 0.20361\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.1439 - acc: 0.9481 - val_loss: 0.2210 - val_acc: 0.9272\n",
      "Epoch 35/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1335 - acc: 0.9529\n",
      "Epoch 00035: val_loss improved from 0.20361 to 0.20312, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 100us/sample - loss: 0.1351 - acc: 0.9524 - val_loss: 0.2031 - val_acc: 0.9427\n",
      "Epoch 36/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1317 - acc: 0.9538\n",
      "Epoch 00036: val_loss did not improve from 0.20312\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.1306 - acc: 0.9539 - val_loss: 0.2285 - val_acc: 0.9263\n",
      "Epoch 37/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1276 - acc: 0.9568\n",
      "Epoch 00037: val_loss did not improve from 0.20312\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.1285 - acc: 0.9564 - val_loss: 0.2163 - val_acc: 0.9290\n",
      "Epoch 38/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1289 - acc: 0.9535\n",
      "Epoch 00038: val_loss did not improve from 0.20312\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.1289 - acc: 0.9536 - val_loss: 0.2091 - val_acc: 0.9327\n",
      "Epoch 39/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9490\n",
      "Epoch 00039: val_loss improved from 0.20312 to 0.19600, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 102us/sample - loss: 0.1360 - acc: 0.9492 - val_loss: 0.1960 - val_acc: 0.9418\n",
      "Epoch 40/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1090 - acc: 0.9612\n",
      "Epoch 00040: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.1100 - acc: 0.9608 - val_loss: 0.1974 - val_acc: 0.9418\n",
      "Epoch 41/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9554\n",
      "Epoch 00041: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.1249 - acc: 0.9555 - val_loss: 0.2156 - val_acc: 0.9327\n",
      "Epoch 42/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9609\n",
      "Epoch 00042: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.1097 - acc: 0.9610 - val_loss: 0.1997 - val_acc: 0.9436\n",
      "Epoch 43/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1013 - acc: 0.9642\n",
      "Epoch 00043: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1030 - acc: 0.9634 - val_loss: 0.2276 - val_acc: 0.9272\n",
      "Epoch 44/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1073 - acc: 0.9615\n",
      "Epoch 00044: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.1064 - acc: 0.9616 - val_loss: 0.2128 - val_acc: 0.9372\n",
      "Epoch 45/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1076 - acc: 0.9637\n",
      "Epoch 00045: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.1077 - acc: 0.9630 - val_loss: 0.2016 - val_acc: 0.9354\n",
      "Epoch 46/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0997 - acc: 0.9651\n",
      "Epoch 00046: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0986 - acc: 0.9655 - val_loss: 0.1993 - val_acc: 0.9409\n",
      "Epoch 47/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0947 - acc: 0.9653\n",
      "Epoch 00047: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0956 - acc: 0.9647 - val_loss: 0.2074 - val_acc: 0.9436\n",
      "Epoch 48/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1093 - acc: 0.9616\n",
      "Epoch 00048: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.1088 - acc: 0.9616 - val_loss: 0.2151 - val_acc: 0.9336\n",
      "Epoch 49/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9615\n",
      "Epoch 00049: val_loss did not improve from 0.19600\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1094 - acc: 0.9615 - val_loss: 0.2102 - val_acc: 0.9381\n",
      "Epoch 50/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1047 - acc: 0.9629\n",
      "Epoch 00050: val_loss improved from 0.19600 to 0.19523, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.1059 - acc: 0.9627 - val_loss: 0.1952 - val_acc: 0.9418\n",
      "Epoch 51/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0909 - acc: 0.9695\n",
      "Epoch 00051: val_loss improved from 0.19523 to 0.19191, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 99us/sample - loss: 0.0937 - acc: 0.9685 - val_loss: 0.1919 - val_acc: 0.9427\n",
      "Epoch 52/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9719\n",
      "Epoch 00052: val_loss did not improve from 0.19191\n",
      "7914/7914 [==============================] - 1s 99us/sample - loss: 0.0891 - acc: 0.9714 - val_loss: 0.2012 - val_acc: 0.9427\n",
      "Epoch 53/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9673\n",
      "Epoch 00053: val_loss did not improve from 0.19191\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0970 - acc: 0.9673 - val_loss: 0.1976 - val_acc: 0.9445\n",
      "Epoch 54/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0853 - acc: 0.9707\n",
      "Epoch 00054: val_loss improved from 0.19191 to 0.18900, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 100us/sample - loss: 0.0863 - acc: 0.9694 - val_loss: 0.1890 - val_acc: 0.9472\n",
      "Epoch 55/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0931 - acc: 0.9672\n",
      "Epoch 00055: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0935 - acc: 0.9670 - val_loss: 0.2221 - val_acc: 0.9372\n",
      "Epoch 56/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0837 - acc: 0.9703\n",
      "Epoch 00056: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0847 - acc: 0.9698 - val_loss: 0.2057 - val_acc: 0.9427\n",
      "Epoch 57/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9688\n",
      "Epoch 00057: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0877 - acc: 0.9687 - val_loss: 0.2073 - val_acc: 0.9409\n",
      "Epoch 58/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9732\n",
      "Epoch 00058: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0773 - acc: 0.9732 - val_loss: 0.2022 - val_acc: 0.9427\n",
      "Epoch 59/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0881 - acc: 0.9685\n",
      "Epoch 00059: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0870 - acc: 0.9688 - val_loss: 0.2095 - val_acc: 0.9418\n",
      "Epoch 60/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0813 - acc: 0.9719\n",
      "Epoch 00060: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0801 - acc: 0.9723 - val_loss: 0.2090 - val_acc: 0.9399\n",
      "Epoch 61/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9778\n",
      "Epoch 00061: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0674 - acc: 0.9778 - val_loss: 0.2217 - val_acc: 0.9390\n",
      "Epoch 62/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1185 - acc: 0.9557\n",
      "Epoch 00062: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.1177 - acc: 0.9559 - val_loss: 0.2100 - val_acc: 0.9399\n",
      "Epoch 63/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9696\n",
      "Epoch 00063: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.0812 - acc: 0.9695 - val_loss: 0.2076 - val_acc: 0.9372\n",
      "Epoch 64/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9723\n",
      "Epoch 00064: val_loss did not improve from 0.18900\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0808 - acc: 0.9723 - val_loss: 0.2100 - val_acc: 0.9399\n",
      "Epoch 65/2000\n",
      "7300/7914 [==========================>...] - ETA: 0s - loss: 0.0645 - acc: 0.9777\n",
      "Epoch 00065: val_loss improved from 0.18900 to 0.18730, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_1.hdf5\n",
      "7914/7914 [==============================] - 1s 99us/sample - loss: 0.0668 - acc: 0.9774 - val_loss: 0.1873 - val_acc: 0.9490\n",
      "Epoch 66/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0780 - acc: 0.9713\n",
      "Epoch 00066: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0778 - acc: 0.9714 - val_loss: 0.2076 - val_acc: 0.9427\n",
      "Epoch 67/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0681 - acc: 0.9768\n",
      "Epoch 00067: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0677 - acc: 0.9770 - val_loss: 0.2032 - val_acc: 0.9427\n",
      "Epoch 68/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0781 - acc: 0.9718\n",
      "Epoch 00068: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0787 - acc: 0.9717 - val_loss: 0.2150 - val_acc: 0.9354\n",
      "Epoch 69/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9727\n",
      "Epoch 00069: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0737 - acc: 0.9727 - val_loss: 0.2052 - val_acc: 0.9399\n",
      "Epoch 70/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0601 - acc: 0.9793\n",
      "Epoch 00070: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0595 - acc: 0.9797 - val_loss: 0.2185 - val_acc: 0.9427\n",
      "Epoch 71/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0677 - acc: 0.9783\n",
      "Epoch 00071: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0674 - acc: 0.9783 - val_loss: 0.2074 - val_acc: 0.9436\n",
      "Epoch 72/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9800\n",
      "Epoch 00072: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0569 - acc: 0.9799 - val_loss: 0.2240 - val_acc: 0.9390\n",
      "Epoch 73/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0799 - acc: 0.9724\n",
      "Epoch 00073: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0804 - acc: 0.9722 - val_loss: 0.2214 - val_acc: 0.9327\n",
      "Epoch 74/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9763\n",
      "Epoch 00074: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0638 - acc: 0.9764 - val_loss: 0.2247 - val_acc: 0.9372\n",
      "Epoch 75/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0733 - acc: 0.9728\n",
      "Epoch 00075: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0718 - acc: 0.9733 - val_loss: 0.2224 - val_acc: 0.9381\n",
      "Epoch 76/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0705 - acc: 0.9761\n",
      "Epoch 00076: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0686 - acc: 0.9770 - val_loss: 0.2090 - val_acc: 0.9472\n",
      "Epoch 77/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0527 - acc: 0.9823\n",
      "Epoch 00077: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0531 - acc: 0.9822 - val_loss: 0.2127 - val_acc: 0.9472\n",
      "Epoch 78/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0518 - acc: 0.9815\n",
      "Epoch 00078: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0518 - acc: 0.9817 - val_loss: 0.2268 - val_acc: 0.9427\n",
      "Epoch 79/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9777\n",
      "Epoch 00079: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0619 - acc: 0.9778 - val_loss: 0.2217 - val_acc: 0.9427\n",
      "Epoch 80/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0606 - acc: 0.9764\n",
      "Epoch 00080: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0603 - acc: 0.9768 - val_loss: 0.2366 - val_acc: 0.9345\n",
      "Epoch 81/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9788\n",
      "Epoch 00081: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0572 - acc: 0.9789 - val_loss: 0.2067 - val_acc: 0.9463\n",
      "Epoch 82/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0525 - acc: 0.9814\n",
      "Epoch 00082: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0532 - acc: 0.9809 - val_loss: 0.2092 - val_acc: 0.9390\n",
      "Epoch 83/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0584 - acc: 0.9780\n",
      "Epoch 00083: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0574 - acc: 0.9785 - val_loss: 0.2115 - val_acc: 0.9481\n",
      "Epoch 84/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0492 - acc: 0.9835\n",
      "Epoch 00084: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0499 - acc: 0.9831 - val_loss: 0.2082 - val_acc: 0.9490\n",
      "Epoch 85/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9801\n",
      "Epoch 00085: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0566 - acc: 0.9802 - val_loss: 0.2229 - val_acc: 0.9445\n",
      "Epoch 86/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0503 - acc: 0.9825\n",
      "Epoch 00086: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0509 - acc: 0.9824 - val_loss: 0.2280 - val_acc: 0.9363\n",
      "Epoch 87/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0549 - acc: 0.9822\n",
      "Epoch 00087: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0548 - acc: 0.9822 - val_loss: 0.2328 - val_acc: 0.9390\n",
      "Epoch 88/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0667 - acc: 0.9752\n",
      "Epoch 00088: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0663 - acc: 0.9754 - val_loss: 0.2460 - val_acc: 0.9372\n",
      "Epoch 89/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0526 - acc: 0.9815\n",
      "Epoch 00089: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0519 - acc: 0.9817 - val_loss: 0.2187 - val_acc: 0.9454\n",
      "Epoch 90/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9779\n",
      "Epoch 00090: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0591 - acc: 0.9774 - val_loss: 0.2211 - val_acc: 0.9390\n",
      "Epoch 91/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0607 - acc: 0.9785\n",
      "Epoch 00091: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0597 - acc: 0.9790 - val_loss: 0.2110 - val_acc: 0.9418\n",
      "Epoch 92/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0416 - acc: 0.9853\n",
      "Epoch 00092: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0417 - acc: 0.9850 - val_loss: 0.2252 - val_acc: 0.9436\n",
      "Epoch 93/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0610 - acc: 0.9773\n",
      "Epoch 00093: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0609 - acc: 0.9776 - val_loss: 0.2334 - val_acc: 0.9390\n",
      "Epoch 94/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0480 - acc: 0.9838\n",
      "Epoch 00094: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0481 - acc: 0.9837 - val_loss: 0.2217 - val_acc: 0.9445\n",
      "Epoch 95/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0412 - acc: 0.9855\n",
      "Epoch 00095: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0414 - acc: 0.9856 - val_loss: 0.2337 - val_acc: 0.9363\n",
      "Epoch 96/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9796\n",
      "Epoch 00096: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0533 - acc: 0.9793 - val_loss: 0.2218 - val_acc: 0.9436\n",
      "Epoch 97/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0536 - acc: 0.9799\n",
      "Epoch 00097: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0537 - acc: 0.9802 - val_loss: 0.2274 - val_acc: 0.9427\n",
      "Epoch 98/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9853\n",
      "Epoch 00098: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0414 - acc: 0.9853 - val_loss: 0.2310 - val_acc: 0.9399\n",
      "Epoch 99/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0455 - acc: 0.9830\n",
      "Epoch 00099: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0462 - acc: 0.9832 - val_loss: 0.2370 - val_acc: 0.9454\n",
      "Epoch 100/2000\n",
      "7300/7914 [==========================>...] - ETA: 0s - loss: 0.0478 - acc: 0.9823\n",
      "Epoch 00100: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0483 - acc: 0.9822 - val_loss: 0.2533 - val_acc: 0.9381\n",
      "Epoch 101/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9815\n",
      "Epoch 00101: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0505 - acc: 0.9814 - val_loss: 0.2412 - val_acc: 0.9390\n",
      "Epoch 102/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0702 - acc: 0.9745\n",
      "Epoch 00102: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0692 - acc: 0.9749 - val_loss: 0.2416 - val_acc: 0.9399\n",
      "Epoch 103/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9837\n",
      "Epoch 00103: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0454 - acc: 0.9837 - val_loss: 0.2432 - val_acc: 0.9436\n",
      "Epoch 104/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9816\n",
      "Epoch 00104: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0518 - acc: 0.9817 - val_loss: 0.2337 - val_acc: 0.9427\n",
      "Epoch 105/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9874\n",
      "Epoch 00105: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0363 - acc: 0.9875 - val_loss: 0.2380 - val_acc: 0.9381\n",
      "Epoch 106/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9850\n",
      "Epoch 00106: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0401 - acc: 0.9851 - val_loss: 0.2356 - val_acc: 0.9436\n",
      "Epoch 107/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0386 - acc: 0.9855\n",
      "Epoch 00107: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0391 - acc: 0.9851 - val_loss: 0.2212 - val_acc: 0.9472\n",
      "Epoch 108/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0418 - acc: 0.9851\n",
      "Epoch 00108: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0430 - acc: 0.9842 - val_loss: 0.2470 - val_acc: 0.9327\n",
      "Epoch 109/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0842 - acc: 0.9722\n",
      "Epoch 00109: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0833 - acc: 0.9723 - val_loss: 0.2204 - val_acc: 0.9436\n",
      "Epoch 110/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0398 - acc: 0.9864\n",
      "Epoch 00110: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0396 - acc: 0.9865 - val_loss: 0.2473 - val_acc: 0.9363\n",
      "Epoch 111/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9871\n",
      "Epoch 00111: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0383 - acc: 0.9871 - val_loss: 0.2259 - val_acc: 0.9472\n",
      "Epoch 112/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9848\n",
      "Epoch 00112: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0444 - acc: 0.9848 - val_loss: 0.2514 - val_acc: 0.9390\n",
      "Epoch 113/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0318 - acc: 0.9884\n",
      "Epoch 00113: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0337 - acc: 0.9880 - val_loss: 0.2414 - val_acc: 0.9372\n",
      "Epoch 114/2000\n",
      "7300/7914 [==========================>...] - ETA: 0s - loss: 0.0343 - acc: 0.9879\n",
      "Epoch 00114: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0354 - acc: 0.9876 - val_loss: 0.2542 - val_acc: 0.9409\n",
      "Epoch 115/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0511 - acc: 0.9820\n",
      "Epoch 00115: val_loss did not improve from 0.18730\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0523 - acc: 0.9819 - val_loss: 0.2343 - val_acc: 0.9418\n",
      "Training time: 88.83707237243652 s\n",
      "1979/1979 [==============================] - 0s 105us/sample - loss: 0.2045 - acc: 0.9358\n",
      "Fold: 2\n",
      "\n",
      "Train on 7914 samples, validate on 1099 samples\n",
      "Epoch 1/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1391 - acc: 0.9535\n",
      "Epoch 00001: val_loss improved from inf to 0.24597, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_2.hdf5\n",
      "7914/7914 [==============================] - 1s 100us/sample - loss: 0.1385 - acc: 0.9536 - val_loss: 0.2460 - val_acc: 0.9308\n",
      "Epoch 2/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.1173 - acc: 0.9580\n",
      "Epoch 00002: val_loss did not improve from 0.24597\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.1166 - acc: 0.9588 - val_loss: 0.2471 - val_acc: 0.9299\n",
      "Epoch 3/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.1112 - acc: 0.9589\n",
      "Epoch 00003: val_loss improved from 0.24597 to 0.20426, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_2.hdf5\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.1097 - acc: 0.9601 - val_loss: 0.2043 - val_acc: 0.9409\n",
      "Epoch 4/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.1025 - acc: 0.9643\n",
      "Epoch 00004: val_loss did not improve from 0.20426\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.1033 - acc: 0.9642 - val_loss: 0.2108 - val_acc: 0.9354\n",
      "Epoch 5/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0950 - acc: 0.9649\n",
      "Epoch 00005: val_loss did not improve from 0.20426\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0934 - acc: 0.9656 - val_loss: 0.2131 - val_acc: 0.9454\n",
      "Epoch 6/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0786 - acc: 0.9734\n",
      "Epoch 00006: val_loss did not improve from 0.20426\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0781 - acc: 0.9736 - val_loss: 0.2053 - val_acc: 0.9418\n",
      "Epoch 7/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9704\n",
      "Epoch 00007: val_loss did not improve from 0.20426\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0824 - acc: 0.9702 - val_loss: 0.2238 - val_acc: 0.9336\n",
      "Epoch 8/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0878 - acc: 0.9673\n",
      "Epoch 00008: val_loss improved from 0.20426 to 0.20130, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_2.hdf5\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0879 - acc: 0.9671 - val_loss: 0.2013 - val_acc: 0.9363\n",
      "Epoch 9/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0859 - acc: 0.9699\n",
      "Epoch 00009: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0866 - acc: 0.9693 - val_loss: 0.2104 - val_acc: 0.9418\n",
      "Epoch 10/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0845 - acc: 0.9704\n",
      "Epoch 00010: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0851 - acc: 0.9704 - val_loss: 0.2207 - val_acc: 0.9336\n",
      "Epoch 11/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9668\n",
      "Epoch 00011: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0931 - acc: 0.9668 - val_loss: 0.2152 - val_acc: 0.9372\n",
      "Epoch 12/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0719 - acc: 0.9735\n",
      "Epoch 00012: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0741 - acc: 0.9723 - val_loss: 0.2056 - val_acc: 0.9418\n",
      "Epoch 13/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0714 - acc: 0.9745\n",
      "Epoch 00013: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0716 - acc: 0.9745 - val_loss: 0.2072 - val_acc: 0.9399\n",
      "Epoch 14/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9771\n",
      "Epoch 00014: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0654 - acc: 0.9771 - val_loss: 0.2456 - val_acc: 0.9299\n",
      "Epoch 15/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0711 - acc: 0.9742\n",
      "Epoch 00015: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0710 - acc: 0.9743 - val_loss: 0.2259 - val_acc: 0.9418\n",
      "Epoch 16/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0664 - acc: 0.9753\n",
      "Epoch 00016: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0657 - acc: 0.9754 - val_loss: 0.2102 - val_acc: 0.9372\n",
      "Epoch 17/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9796\n",
      "Epoch 00017: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0575 - acc: 0.9797 - val_loss: 0.2486 - val_acc: 0.9327\n",
      "Epoch 18/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9747\n",
      "Epoch 00018: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0670 - acc: 0.9742 - val_loss: 0.2461 - val_acc: 0.9281\n",
      "Epoch 19/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0683 - acc: 0.9755\n",
      "Epoch 00019: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0686 - acc: 0.9754 - val_loss: 0.2220 - val_acc: 0.9363\n",
      "Epoch 20/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0570 - acc: 0.9804\n",
      "Epoch 00020: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0563 - acc: 0.9808 - val_loss: 0.2209 - val_acc: 0.9381\n",
      "Epoch 21/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9783\n",
      "Epoch 00021: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0599 - acc: 0.9783 - val_loss: 0.2178 - val_acc: 0.9409\n",
      "Epoch 22/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0551 - acc: 0.9801\n",
      "Epoch 00022: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0552 - acc: 0.9798 - val_loss: 0.2160 - val_acc: 0.9445\n",
      "Epoch 23/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0581 - acc: 0.9779\n",
      "Epoch 00023: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0580 - acc: 0.9780 - val_loss: 0.2526 - val_acc: 0.9327\n",
      "Epoch 24/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9782\n",
      "Epoch 00024: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0582 - acc: 0.9783 - val_loss: 0.2150 - val_acc: 0.9336\n",
      "Epoch 25/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9827\n",
      "Epoch 00025: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 89us/sample - loss: 0.0464 - acc: 0.9828 - val_loss: 0.2138 - val_acc: 0.9427\n",
      "Epoch 26/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0433 - acc: 0.9856\n",
      "Epoch 00026: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0434 - acc: 0.9856 - val_loss: 0.2159 - val_acc: 0.9390\n",
      "Epoch 27/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0556 - acc: 0.9800\n",
      "Epoch 00027: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0559 - acc: 0.9800 - val_loss: 0.2343 - val_acc: 0.9354\n",
      "Epoch 28/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0544 - acc: 0.9804\n",
      "Epoch 00028: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0540 - acc: 0.9804 - val_loss: 0.2435 - val_acc: 0.9318\n",
      "Epoch 29/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0556 - acc: 0.9799\n",
      "Epoch 00029: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0552 - acc: 0.9798 - val_loss: 0.2296 - val_acc: 0.9427\n",
      "Epoch 30/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9804\n",
      "Epoch 00030: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0564 - acc: 0.9807 - val_loss: 0.2259 - val_acc: 0.9354\n",
      "Epoch 31/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9797\n",
      "Epoch 00031: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0565 - acc: 0.9798 - val_loss: 0.2333 - val_acc: 0.9372\n",
      "Epoch 32/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0540 - acc: 0.9816\n",
      "Epoch 00032: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0536 - acc: 0.9818 - val_loss: 0.2328 - val_acc: 0.9390\n",
      "Epoch 33/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0397 - acc: 0.9869\n",
      "Epoch 00033: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0408 - acc: 0.9858 - val_loss: 0.2242 - val_acc: 0.9327\n",
      "Epoch 34/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0339 - acc: 0.9887\n",
      "Epoch 00034: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0343 - acc: 0.9886 - val_loss: 0.2294 - val_acc: 0.9372\n",
      "Epoch 35/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0407 - acc: 0.9862\n",
      "Epoch 00035: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0405 - acc: 0.9864 - val_loss: 0.2344 - val_acc: 0.9418\n",
      "Epoch 36/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0395 - acc: 0.9863\n",
      "Epoch 00036: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0394 - acc: 0.9866 - val_loss: 0.2561 - val_acc: 0.9354\n",
      "Epoch 37/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0349 - acc: 0.9882\n",
      "Epoch 00037: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0350 - acc: 0.9882 - val_loss: 0.2282 - val_acc: 0.9345\n",
      "Epoch 38/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0471 - acc: 0.9838\n",
      "Epoch 00038: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0478 - acc: 0.9836 - val_loss: 0.2435 - val_acc: 0.9272\n",
      "Epoch 39/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0541 - acc: 0.9805\n",
      "Epoch 00039: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0546 - acc: 0.9800 - val_loss: 0.2777 - val_acc: 0.9345\n",
      "Epoch 40/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0574 - acc: 0.9784\n",
      "Epoch 00040: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0564 - acc: 0.9789 - val_loss: 0.2590 - val_acc: 0.9363\n",
      "Epoch 41/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0473 - acc: 0.9837\n",
      "Epoch 00041: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0464 - acc: 0.9841 - val_loss: 0.2424 - val_acc: 0.9327\n",
      "Epoch 42/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9875\n",
      "Epoch 00042: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0353 - acc: 0.9874 - val_loss: 0.2397 - val_acc: 0.9427\n",
      "Epoch 43/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0398 - acc: 0.9858\n",
      "Epoch 00043: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0400 - acc: 0.9855 - val_loss: 0.2509 - val_acc: 0.9354\n",
      "Epoch 44/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9883\n",
      "Epoch 00044: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0349 - acc: 0.9882 - val_loss: 0.2575 - val_acc: 0.9327\n",
      "Epoch 45/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9853\n",
      "Epoch 00045: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0422 - acc: 0.9853 - val_loss: 0.2483 - val_acc: 0.9363\n",
      "Epoch 46/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0363 - acc: 0.9886\n",
      "Epoch 00046: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0361 - acc: 0.9888 - val_loss: 0.2770 - val_acc: 0.9345\n",
      "Epoch 47/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0462 - acc: 0.9841\n",
      "Epoch 00047: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0470 - acc: 0.9838 - val_loss: 0.2513 - val_acc: 0.9381\n",
      "Epoch 48/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9758\n",
      "Epoch 00048: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.0678 - acc: 0.9759 - val_loss: 0.2756 - val_acc: 0.9345\n",
      "Epoch 49/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0471 - acc: 0.9832\n",
      "Epoch 00049: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0466 - acc: 0.9834 - val_loss: 0.2500 - val_acc: 0.9336\n",
      "Epoch 50/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9890\n",
      "Epoch 00050: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0291 - acc: 0.9891 - val_loss: 0.2656 - val_acc: 0.9281\n",
      "Epoch 51/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9901\n",
      "Epoch 00051: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0303 - acc: 0.9901 - val_loss: 0.2463 - val_acc: 0.9436\n",
      "Epoch 52/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9840\n",
      "Epoch 00052: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0428 - acc: 0.9838 - val_loss: 0.2745 - val_acc: 0.9363\n",
      "Epoch 53/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0495 - acc: 0.9833\n",
      "Epoch 00053: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0492 - acc: 0.9831 - val_loss: 0.2522 - val_acc: 0.9318\n",
      "Epoch 54/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9851\n",
      "Epoch 00054: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0417 - acc: 0.9850 - val_loss: 0.2553 - val_acc: 0.9381\n",
      "Epoch 55/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0320 - acc: 0.9879\n",
      "Epoch 00055: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0318 - acc: 0.9880 - val_loss: 0.2476 - val_acc: 0.9336\n",
      "Epoch 56/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9712\n",
      "Epoch 00056: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0751 - acc: 0.9717 - val_loss: 0.2681 - val_acc: 0.9327\n",
      "Epoch 57/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9862\n",
      "Epoch 00057: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0402 - acc: 0.9865 - val_loss: 0.2453 - val_acc: 0.9409\n",
      "Epoch 58/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0322 - acc: 0.9887\n",
      "Epoch 00058: val_loss did not improve from 0.20130\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0329 - acc: 0.9880 - val_loss: 0.2553 - val_acc: 0.9363\n",
      "Training time: 43.187214612960815 s\n",
      "1979/1979 [==============================] - 0s 101us/sample - loss: 0.0987 - acc: 0.9631\n",
      "Fold: 3\n",
      "\n",
      "Train on 7914 samples, validate on 1099 samples\n",
      "Epoch 1/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.1028 - acc: 0.9641\n",
      "Epoch 00001: val_loss improved from inf to 0.23278, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_3.hdf5\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1036 - acc: 0.9631 - val_loss: 0.2328 - val_acc: 0.9308\n",
      "Epoch 2/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9619\n",
      "Epoch 00002: val_loss did not improve from 0.23278\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.1033 - acc: 0.9617 - val_loss: 0.2343 - val_acc: 0.9272\n",
      "Epoch 3/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.1003 - acc: 0.9633\n",
      "Epoch 00003: val_loss did not improve from 0.23278\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.1017 - acc: 0.9626 - val_loss: 0.2506 - val_acc: 0.9236\n",
      "Epoch 4/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.1185 - acc: 0.9562\n",
      "Epoch 00004: val_loss improved from 0.23278 to 0.20600, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_3.hdf5\n",
      "7914/7914 [==============================] - 1s 96us/sample - loss: 0.1193 - acc: 0.9564 - val_loss: 0.2060 - val_acc: 0.9427\n",
      "Epoch 5/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9704\n",
      "Epoch 00005: val_loss did not improve from 0.20600\n",
      "7914/7914 [==============================] - 1s 98us/sample - loss: 0.0783 - acc: 0.9703 - val_loss: 0.2067 - val_acc: 0.9354\n",
      "Epoch 6/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9709\n",
      "Epoch 00006: val_loss improved from 0.20600 to 0.20167, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_3.hdf5\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0805 - acc: 0.9707 - val_loss: 0.2017 - val_acc: 0.9372\n",
      "Epoch 7/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9630\n",
      "Epoch 00007: val_loss improved from 0.20167 to 0.18792, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_3.hdf5\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0961 - acc: 0.9634 - val_loss: 0.1879 - val_acc: 0.9427\n",
      "Epoch 8/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0706 - acc: 0.9749\n",
      "Epoch 00008: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 88us/sample - loss: 0.0706 - acc: 0.9750 - val_loss: 0.2227 - val_acc: 0.9381\n",
      "Epoch 9/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0595 - acc: 0.9796\n",
      "Epoch 00009: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0605 - acc: 0.9792 - val_loss: 0.2013 - val_acc: 0.9427\n",
      "Epoch 10/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9762\n",
      "Epoch 00010: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 88us/sample - loss: 0.0674 - acc: 0.9762 - val_loss: 0.1903 - val_acc: 0.9490\n",
      "Epoch 11/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0576 - acc: 0.9799\n",
      "Epoch 00011: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0573 - acc: 0.9799 - val_loss: 0.2192 - val_acc: 0.9445\n",
      "Epoch 12/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9701\n",
      "Epoch 00012: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0833 - acc: 0.9701 - val_loss: 0.2012 - val_acc: 0.9472\n",
      "Epoch 13/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9768\n",
      "Epoch 00013: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0644 - acc: 0.9769 - val_loss: 0.1963 - val_acc: 0.9454\n",
      "Epoch 14/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9785\n",
      "Epoch 00014: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0633 - acc: 0.9785 - val_loss: 0.2031 - val_acc: 0.9409\n",
      "Epoch 15/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0588 - acc: 0.9788\n",
      "Epoch 00015: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0588 - acc: 0.9789 - val_loss: 0.1951 - val_acc: 0.9472\n",
      "Epoch 16/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9744\n",
      "Epoch 00016: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0674 - acc: 0.9746 - val_loss: 0.2036 - val_acc: 0.9454\n",
      "Epoch 17/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9803\n",
      "Epoch 00017: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0551 - acc: 0.9807 - val_loss: 0.2068 - val_acc: 0.9463\n",
      "Epoch 18/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9818\n",
      "Epoch 00018: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0497 - acc: 0.9821 - val_loss: 0.1889 - val_acc: 0.9490\n",
      "Epoch 19/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9705\n",
      "Epoch 00019: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0784 - acc: 0.9708 - val_loss: 0.2138 - val_acc: 0.9445\n",
      "Epoch 20/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9737\n",
      "Epoch 00020: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0726 - acc: 0.9738 - val_loss: 0.2003 - val_acc: 0.9454\n",
      "Epoch 21/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0557 - acc: 0.9804\n",
      "Epoch 00021: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 88us/sample - loss: 0.0564 - acc: 0.9798 - val_loss: 0.2218 - val_acc: 0.9354\n",
      "Epoch 22/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9812\n",
      "Epoch 00022: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0530 - acc: 0.9812 - val_loss: 0.2386 - val_acc: 0.9308\n",
      "Epoch 23/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9806\n",
      "Epoch 00023: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0545 - acc: 0.9807 - val_loss: 0.2131 - val_acc: 0.9418\n",
      "Epoch 24/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0531 - acc: 0.9795\n",
      "Epoch 00024: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0533 - acc: 0.9794 - val_loss: 0.2061 - val_acc: 0.9436\n",
      "Epoch 25/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9822\n",
      "Epoch 00025: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0479 - acc: 0.9822 - val_loss: 0.2138 - val_acc: 0.9481\n",
      "Epoch 26/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9851\n",
      "Epoch 00026: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0431 - acc: 0.9851 - val_loss: 0.2115 - val_acc: 0.9463\n",
      "Epoch 27/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9826\n",
      "Epoch 00027: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0497 - acc: 0.9824 - val_loss: 0.2034 - val_acc: 0.9500\n",
      "Epoch 28/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9858\n",
      "Epoch 00028: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 89us/sample - loss: 0.0427 - acc: 0.9858 - val_loss: 0.2130 - val_acc: 0.9454\n",
      "Epoch 29/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9845\n",
      "Epoch 00029: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0459 - acc: 0.9842 - val_loss: 0.2014 - val_acc: 0.9436\n",
      "Epoch 30/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0439 - acc: 0.9829\n",
      "Epoch 00030: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0437 - acc: 0.9833 - val_loss: 0.2173 - val_acc: 0.9409\n",
      "Epoch 31/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9790\n",
      "Epoch 00031: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0512 - acc: 0.9790 - val_loss: 0.2439 - val_acc: 0.9427\n",
      "Epoch 32/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9847\n",
      "Epoch 00032: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0409 - acc: 0.9846 - val_loss: 0.2094 - val_acc: 0.9500\n",
      "Epoch 33/2000\n",
      "7300/7914 [==========================>...] - ETA: 0s - loss: 0.0400 - acc: 0.9866\n",
      "Epoch 00033: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0411 - acc: 0.9861 - val_loss: 0.2282 - val_acc: 0.9418\n",
      "Epoch 34/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9780\n",
      "Epoch 00034: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0656 - acc: 0.9780 - val_loss: 0.2301 - val_acc: 0.9436\n",
      "Epoch 35/2000\n",
      "7400/7914 [===========================>..] - ETA: 0s - loss: 0.0675 - acc: 0.9758\n",
      "Epoch 00035: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 97us/sample - loss: 0.0657 - acc: 0.9764 - val_loss: 0.2322 - val_acc: 0.9436\n",
      "Epoch 36/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0381 - acc: 0.9867\n",
      "Epoch 00036: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0376 - acc: 0.9867 - val_loss: 0.1968 - val_acc: 0.9527\n",
      "Epoch 37/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0409 - acc: 0.9863\n",
      "Epoch 00037: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0405 - acc: 0.9865 - val_loss: 0.2078 - val_acc: 0.9490\n",
      "Epoch 38/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0378 - acc: 0.9872\n",
      "Epoch 00038: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0387 - acc: 0.9869 - val_loss: 0.2141 - val_acc: 0.9500\n",
      "Epoch 39/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9875\n",
      "Epoch 00039: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0367 - acc: 0.9874 - val_loss: 0.2456 - val_acc: 0.9345\n",
      "Epoch 40/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9863\n",
      "Epoch 00040: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0386 - acc: 0.9864 - val_loss: 0.2224 - val_acc: 0.9399\n",
      "Epoch 41/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9759\n",
      "Epoch 00041: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0613 - acc: 0.9760 - val_loss: 0.2185 - val_acc: 0.9463\n",
      "Epoch 42/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0471 - acc: 0.9819\n",
      "Epoch 00042: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0470 - acc: 0.9818 - val_loss: 0.2044 - val_acc: 0.9509\n",
      "Epoch 43/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9906\n",
      "Epoch 00043: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0301 - acc: 0.9906 - val_loss: 0.2076 - val_acc: 0.9463\n",
      "Epoch 44/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0263 - acc: 0.9921\n",
      "Epoch 00044: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0269 - acc: 0.9917 - val_loss: 0.2215 - val_acc: 0.9427\n",
      "Epoch 45/2000\n",
      "7900/7914 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9911\n",
      "Epoch 00045: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 89us/sample - loss: 0.0277 - acc: 0.9910 - val_loss: 0.2222 - val_acc: 0.9500\n",
      "Epoch 46/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0421 - acc: 0.9858\n",
      "Epoch 00046: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 93us/sample - loss: 0.0425 - acc: 0.9855 - val_loss: 0.2184 - val_acc: 0.9472\n",
      "Epoch 47/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0388 - acc: 0.9861\n",
      "Epoch 00047: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0404 - acc: 0.9851 - val_loss: 0.2619 - val_acc: 0.9354\n",
      "Epoch 48/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0544 - acc: 0.9803\n",
      "Epoch 00048: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0539 - acc: 0.9804 - val_loss: 0.2342 - val_acc: 0.9399\n",
      "Epoch 49/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9745\n",
      "Epoch 00049: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0676 - acc: 0.9751 - val_loss: 0.2324 - val_acc: 0.9409\n",
      "Epoch 50/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9862\n",
      "Epoch 00050: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 89us/sample - loss: 0.0366 - acc: 0.9861 - val_loss: 0.2294 - val_acc: 0.9472\n",
      "Epoch 51/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9887\n",
      "Epoch 00051: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0332 - acc: 0.9884 - val_loss: 0.2245 - val_acc: 0.9399\n",
      "Epoch 52/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9865\n",
      "Epoch 00052: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 94us/sample - loss: 0.0418 - acc: 0.9865 - val_loss: 0.2311 - val_acc: 0.9318\n",
      "Epoch 53/2000\n",
      "7500/7914 [===========================>..] - ETA: 0s - loss: 0.0591 - acc: 0.9771\n",
      "Epoch 00053: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 95us/sample - loss: 0.0578 - acc: 0.9779 - val_loss: 0.2252 - val_acc: 0.9463\n",
      "Epoch 54/2000\n",
      "7300/7914 [==========================>...] - ETA: 0s - loss: 0.0287 - acc: 0.9903\n",
      "Epoch 00054: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 90us/sample - loss: 0.0299 - acc: 0.9900 - val_loss: 0.2303 - val_acc: 0.9399\n",
      "Epoch 55/2000\n",
      "7600/7914 [===========================>..] - ETA: 0s - loss: 0.0346 - acc: 0.9882\n",
      "Epoch 00055: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 92us/sample - loss: 0.0351 - acc: 0.9877 - val_loss: 0.2286 - val_acc: 0.9436\n",
      "Epoch 56/2000\n",
      "7800/7914 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9837\n",
      "Epoch 00056: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 89us/sample - loss: 0.0499 - acc: 0.9838 - val_loss: 0.2246 - val_acc: 0.9436\n",
      "Epoch 57/2000\n",
      "7700/7914 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9909\n",
      "Epoch 00057: val_loss did not improve from 0.18792\n",
      "7914/7914 [==============================] - 1s 91us/sample - loss: 0.0282 - acc: 0.9909 - val_loss: 0.2187 - val_acc: 0.9454\n",
      "Training time: 41.623162508010864 s\n",
      "1979/1979 [==============================] - 0s 103us/sample - loss: 0.0951 - acc: 0.9641\n",
      "Fold: 4\n",
      "\n",
      "Train on 7915 samples, validate on 1099 samples\n",
      "Epoch 1/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0792 - acc: 0.9723\n",
      "Epoch 00001: val_loss improved from inf to 0.21245, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_4.hdf5\n",
      "7915/7915 [==============================] - 1s 99us/sample - loss: 0.0806 - acc: 0.9714 - val_loss: 0.2124 - val_acc: 0.9345\n",
      "Epoch 2/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9678\n",
      "Epoch 00002: val_loss improved from 0.21245 to 0.20446, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_4.hdf5\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0868 - acc: 0.9679 - val_loss: 0.2045 - val_acc: 0.9409\n",
      "Epoch 3/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9706\n",
      "Epoch 00003: val_loss did not improve from 0.20446\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0824 - acc: 0.9711 - val_loss: 0.2236 - val_acc: 0.9399\n",
      "Epoch 4/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0861 - acc: 0.9691\n",
      "Epoch 00004: val_loss did not improve from 0.20446\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0856 - acc: 0.9697 - val_loss: 0.2232 - val_acc: 0.9445\n",
      "Epoch 5/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0787 - acc: 0.9688\n",
      "Epoch 00005: val_loss did not improve from 0.20446\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0794 - acc: 0.9685 - val_loss: 0.2198 - val_acc: 0.9427\n",
      "Epoch 6/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9688\n",
      "Epoch 00006: val_loss did not improve from 0.20446\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0851 - acc: 0.9688 - val_loss: 0.2222 - val_acc: 0.9363\n",
      "Epoch 7/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9746\n",
      "Epoch 00007: val_loss did not improve from 0.20446\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0683 - acc: 0.9746 - val_loss: 0.2055 - val_acc: 0.9409\n",
      "Epoch 8/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9797\n",
      "Epoch 00008: val_loss did not improve from 0.20446\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0573 - acc: 0.9798 - val_loss: 0.2051 - val_acc: 0.9463\n",
      "Epoch 9/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9805\n",
      "Epoch 00009: val_loss improved from 0.20446 to 0.20086, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_4.hdf5\n",
      "7915/7915 [==============================] - 1s 94us/sample - loss: 0.0538 - acc: 0.9804 - val_loss: 0.2009 - val_acc: 0.9509\n",
      "Epoch 10/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0681 - acc: 0.9739\n",
      "Epoch 00010: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0690 - acc: 0.9736 - val_loss: 0.2595 - val_acc: 0.9263\n",
      "Epoch 11/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9686\n",
      "Epoch 00011: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0820 - acc: 0.9687 - val_loss: 0.2373 - val_acc: 0.9327\n",
      "Epoch 12/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9787\n",
      "Epoch 00012: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0582 - acc: 0.9790 - val_loss: 0.2142 - val_acc: 0.9454\n",
      "Epoch 13/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0453 - acc: 0.9851\n",
      "Epoch 00013: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0457 - acc: 0.9848 - val_loss: 0.2016 - val_acc: 0.9454\n",
      "Epoch 14/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0595 - acc: 0.9784\n",
      "Epoch 00014: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 94us/sample - loss: 0.0593 - acc: 0.9783 - val_loss: 0.2250 - val_acc: 0.9454\n",
      "Epoch 15/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0614 - acc: 0.9758\n",
      "Epoch 00015: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 94us/sample - loss: 0.0617 - acc: 0.9755 - val_loss: 0.2100 - val_acc: 0.9445\n",
      "Epoch 16/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9823\n",
      "Epoch 00016: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0470 - acc: 0.9822 - val_loss: 0.2484 - val_acc: 0.9390\n",
      "Epoch 17/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9828\n",
      "Epoch 00017: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0519 - acc: 0.9828 - val_loss: 0.2254 - val_acc: 0.9454\n",
      "Epoch 18/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9844\n",
      "Epoch 00018: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0459 - acc: 0.9841 - val_loss: 0.2170 - val_acc: 0.9409\n",
      "Epoch 19/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0408 - acc: 0.9863\n",
      "Epoch 00019: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 87us/sample - loss: 0.0407 - acc: 0.9865 - val_loss: 0.2322 - val_acc: 0.9399\n",
      "Epoch 20/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0412 - acc: 0.9859\n",
      "Epoch 00020: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 87us/sample - loss: 0.0429 - acc: 0.9856 - val_loss: 0.2387 - val_acc: 0.9363\n",
      "Epoch 21/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0588 - acc: 0.9797\n",
      "Epoch 00021: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0588 - acc: 0.9798 - val_loss: 0.2261 - val_acc: 0.9454\n",
      "Epoch 22/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9848\n",
      "Epoch 00022: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0430 - acc: 0.9848 - val_loss: 0.2130 - val_acc: 0.9490\n",
      "Epoch 23/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9885\n",
      "Epoch 00023: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0383 - acc: 0.9885 - val_loss: 0.2368 - val_acc: 0.9454\n",
      "Epoch 24/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9853\n",
      "Epoch 00024: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0412 - acc: 0.9851 - val_loss: 0.2177 - val_acc: 0.9481\n",
      "Epoch 25/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0330 - acc: 0.9893\n",
      "Epoch 00025: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0332 - acc: 0.9893 - val_loss: 0.2200 - val_acc: 0.9463\n",
      "Epoch 26/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0315 - acc: 0.9899\n",
      "Epoch 00026: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0314 - acc: 0.9898 - val_loss: 0.2416 - val_acc: 0.9399\n",
      "Epoch 27/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9853\n",
      "Epoch 00027: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0445 - acc: 0.9850 - val_loss: 0.2414 - val_acc: 0.9381\n",
      "Epoch 28/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9671\n",
      "Epoch 00028: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0828 - acc: 0.9670 - val_loss: 0.2613 - val_acc: 0.9254\n",
      "Epoch 29/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0639 - acc: 0.9743\n",
      "Epoch 00029: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0638 - acc: 0.9746 - val_loss: 0.2498 - val_acc: 0.9372\n",
      "Epoch 30/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0503 - acc: 0.9821\n",
      "Epoch 00030: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 87us/sample - loss: 0.0493 - acc: 0.9826 - val_loss: 0.2414 - val_acc: 0.9427\n",
      "Epoch 31/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0413 - acc: 0.9853\n",
      "Epoch 00031: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0423 - acc: 0.9846 - val_loss: 0.2233 - val_acc: 0.9427\n",
      "Epoch 32/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0506 - acc: 0.9815\n",
      "Epoch 00032: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0519 - acc: 0.9809 - val_loss: 0.2496 - val_acc: 0.9436\n",
      "Epoch 33/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0576 - acc: 0.9786\n",
      "Epoch 00033: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0563 - acc: 0.9794 - val_loss: 0.2403 - val_acc: 0.9399\n",
      "Epoch 34/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9857\n",
      "Epoch 00034: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0423 - acc: 0.9857 - val_loss: 0.2474 - val_acc: 0.9390\n",
      "Epoch 35/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0304 - acc: 0.9900\n",
      "Epoch 00035: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0308 - acc: 0.9898 - val_loss: 0.2348 - val_acc: 0.9472\n",
      "Epoch 36/2000\n",
      "7200/7915 [==========================>...] - ETA: 0s - loss: 0.0291 - acc: 0.9900\n",
      "Epoch 00036: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0289 - acc: 0.9898 - val_loss: 0.2480 - val_acc: 0.9399\n",
      "Epoch 37/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9899\n",
      "Epoch 00037: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0310 - acc: 0.9899 - val_loss: 0.2289 - val_acc: 0.9409\n",
      "Epoch 38/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9910\n",
      "Epoch 00038: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0283 - acc: 0.9910 - val_loss: 0.2264 - val_acc: 0.9463\n",
      "Epoch 39/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9922\n",
      "Epoch 00039: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0254 - acc: 0.9920 - val_loss: 0.2447 - val_acc: 0.9418\n",
      "Epoch 40/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0359 - acc: 0.9887\n",
      "Epoch 00040: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0358 - acc: 0.9885 - val_loss: 0.2625 - val_acc: 0.9390\n",
      "Epoch 41/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9881\n",
      "Epoch 00041: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0337 - acc: 0.9879 - val_loss: 0.2398 - val_acc: 0.9472\n",
      "Epoch 42/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0306 - acc: 0.9893\n",
      "Epoch 00042: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0309 - acc: 0.9891 - val_loss: 0.2389 - val_acc: 0.9481\n",
      "Epoch 43/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0326 - acc: 0.9888\n",
      "Epoch 00043: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0326 - acc: 0.9888 - val_loss: 0.2649 - val_acc: 0.9390\n",
      "Epoch 44/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9871\n",
      "Epoch 00044: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0363 - acc: 0.9871 - val_loss: 0.2703 - val_acc: 0.9336\n",
      "Epoch 45/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0356 - acc: 0.9863\n",
      "Epoch 00045: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0355 - acc: 0.9865 - val_loss: 0.2538 - val_acc: 0.9445\n",
      "Epoch 46/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9891\n",
      "Epoch 00046: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0314 - acc: 0.9891 - val_loss: 0.2383 - val_acc: 0.9390\n",
      "Epoch 47/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9849\n",
      "Epoch 00047: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0414 - acc: 0.9848 - val_loss: 0.2866 - val_acc: 0.9308\n",
      "Epoch 48/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0542 - acc: 0.9811\n",
      "Epoch 00048: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0540 - acc: 0.9810 - val_loss: 0.2540 - val_acc: 0.9454\n",
      "Epoch 49/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0286 - acc: 0.9907\n",
      "Epoch 00049: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 87us/sample - loss: 0.0290 - acc: 0.9904 - val_loss: 0.2593 - val_acc: 0.9409\n",
      "Epoch 50/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0325 - acc: 0.9893\n",
      "Epoch 00050: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0321 - acc: 0.9895 - val_loss: 0.2297 - val_acc: 0.9445\n",
      "Epoch 51/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0238 - acc: 0.9922\n",
      "Epoch 00051: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0244 - acc: 0.9918 - val_loss: 0.2587 - val_acc: 0.9354\n",
      "Epoch 52/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9884\n",
      "Epoch 00052: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0379 - acc: 0.9884 - val_loss: 0.2421 - val_acc: 0.9463\n",
      "Epoch 53/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0367 - acc: 0.9869\n",
      "Epoch 00053: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 87us/sample - loss: 0.0405 - acc: 0.9855 - val_loss: 0.2685 - val_acc: 0.9445\n",
      "Epoch 54/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0435 - acc: 0.9830\n",
      "Epoch 00054: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 93us/sample - loss: 0.0431 - acc: 0.9834 - val_loss: 0.2477 - val_acc: 0.9436\n",
      "Epoch 55/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9900\n",
      "Epoch 00055: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0300 - acc: 0.9900 - val_loss: 0.2418 - val_acc: 0.9445\n",
      "Epoch 56/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9914\n",
      "Epoch 00056: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 93us/sample - loss: 0.0254 - acc: 0.9915 - val_loss: 0.2377 - val_acc: 0.9445\n",
      "Epoch 57/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9955\n",
      "Epoch 00057: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0160 - acc: 0.9956 - val_loss: 0.2446 - val_acc: 0.9445\n",
      "Epoch 58/2000\n",
      "7200/7915 [==========================>...] - ETA: 0s - loss: 0.0214 - acc: 0.9935\n",
      "Epoch 00058: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0219 - acc: 0.9932 - val_loss: 0.2515 - val_acc: 0.9418\n",
      "Epoch 59/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9903\n",
      "Epoch 00059: val_loss did not improve from 0.20086\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0287 - acc: 0.9903 - val_loss: 0.2511 - val_acc: 0.9399\n",
      "Training time: 42.31861686706543 s\n",
      "1978/1978 [==============================] - 0s 98us/sample - loss: 0.0697 - acc: 0.9757\n",
      "Fold: 5\n",
      "\n",
      "Train on 7915 samples, validate on 1099 samples\n",
      "Epoch 1/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9732\n",
      "Epoch 00001: val_loss improved from inf to 0.22810, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_5.hdf5\n",
      "7915/7915 [==============================] - 1s 94us/sample - loss: 0.0731 - acc: 0.9731 - val_loss: 0.2281 - val_acc: 0.9372\n",
      "Epoch 2/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9696\n",
      "Epoch 00002: val_loss improved from 0.22810 to 0.22259, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_5.hdf5\n",
      "7915/7915 [==============================] - 1s 94us/sample - loss: 0.0834 - acc: 0.9697 - val_loss: 0.2226 - val_acc: 0.9381\n",
      "Epoch 3/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0831 - acc: 0.9701\n",
      "Epoch 00003: val_loss did not improve from 0.22259\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0821 - acc: 0.9697 - val_loss: 0.2451 - val_acc: 0.9354\n",
      "Epoch 4/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9765\n",
      "Epoch 00004: val_loss improved from 0.22259 to 0.20563, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_5.hdf5\n",
      "7915/7915 [==============================] - 1s 95us/sample - loss: 0.0662 - acc: 0.9762 - val_loss: 0.2056 - val_acc: 0.9490\n",
      "Epoch 5/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0940 - acc: 0.9657\n",
      "Epoch 00005: val_loss did not improve from 0.20563\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0932 - acc: 0.9659 - val_loss: 0.2231 - val_acc: 0.9336\n",
      "Epoch 6/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9733\n",
      "Epoch 00006: val_loss improved from 0.20563 to 0.19803, saving model to /data/home/dorads/Documents/GitHub_Repositories/01_Maintained/NeuralODE/models/PenDigits/PenDigits-Laguerre_5.hdf5\n",
      "7915/7915 [==============================] - 1s 93us/sample - loss: 0.0727 - acc: 0.9733 - val_loss: 0.1980 - val_acc: 0.9500\n",
      "Epoch 7/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9796\n",
      "Epoch 00007: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0541 - acc: 0.9795 - val_loss: 0.2252 - val_acc: 0.9390\n",
      "Epoch 8/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0496 - acc: 0.9832\n",
      "Epoch 00008: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0507 - acc: 0.9826 - val_loss: 0.2019 - val_acc: 0.9418\n",
      "Epoch 9/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9800\n",
      "Epoch 00009: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0538 - acc: 0.9800 - val_loss: 0.2028 - val_acc: 0.9509\n",
      "Epoch 10/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0468 - acc: 0.9828\n",
      "Epoch 00010: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0476 - acc: 0.9824 - val_loss: 0.2093 - val_acc: 0.9436\n",
      "Epoch 11/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0629 - acc: 0.9779\n",
      "Epoch 00011: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 87us/sample - loss: 0.0631 - acc: 0.9776 - val_loss: 0.2136 - val_acc: 0.9481\n",
      "Epoch 12/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0473 - acc: 0.9833\n",
      "Epoch 00012: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 93us/sample - loss: 0.0474 - acc: 0.9832 - val_loss: 0.2065 - val_acc: 0.9436\n",
      "Epoch 13/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9812\n",
      "Epoch 00013: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0500 - acc: 0.9814 - val_loss: 0.1983 - val_acc: 0.9518\n",
      "Epoch 14/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9844\n",
      "Epoch 00014: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0423 - acc: 0.9841 - val_loss: 0.2115 - val_acc: 0.9399\n",
      "Epoch 15/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0429 - acc: 0.9841\n",
      "Epoch 00015: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0427 - acc: 0.9838 - val_loss: 0.2158 - val_acc: 0.9418\n",
      "Epoch 16/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9838\n",
      "Epoch 00016: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0458 - acc: 0.9840 - val_loss: 0.2214 - val_acc: 0.9436\n",
      "Epoch 17/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0503 - acc: 0.9812\n",
      "Epoch 00017: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0502 - acc: 0.9814 - val_loss: 0.2301 - val_acc: 0.9427\n",
      "Epoch 18/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9831\n",
      "Epoch 00018: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 93us/sample - loss: 0.0445 - acc: 0.9832 - val_loss: 0.2197 - val_acc: 0.9399\n",
      "Epoch 19/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9816\n",
      "Epoch 00019: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0514 - acc: 0.9817 - val_loss: 0.2070 - val_acc: 0.9509\n",
      "Epoch 20/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9853\n",
      "Epoch 00020: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 87us/sample - loss: 0.0420 - acc: 0.9853 - val_loss: 0.2293 - val_acc: 0.9390\n",
      "Epoch 21/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9868\n",
      "Epoch 00021: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0407 - acc: 0.9865 - val_loss: 0.2148 - val_acc: 0.9490\n",
      "Epoch 22/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9834\n",
      "Epoch 00022: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0458 - acc: 0.9834 - val_loss: 0.2476 - val_acc: 0.9363\n",
      "Epoch 23/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0418 - acc: 0.9861\n",
      "Epoch 00023: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0419 - acc: 0.9858 - val_loss: 0.2260 - val_acc: 0.9445\n",
      "Epoch 24/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9804\n",
      "Epoch 00024: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0565 - acc: 0.9800 - val_loss: 0.2312 - val_acc: 0.9381\n",
      "Epoch 25/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0382 - acc: 0.9869\n",
      "Epoch 00025: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0382 - acc: 0.9870 - val_loss: 0.2341 - val_acc: 0.9463\n",
      "Epoch 26/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9897\n",
      "Epoch 00026: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0305 - acc: 0.9896 - val_loss: 0.2259 - val_acc: 0.9409\n",
      "Epoch 27/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9855\n",
      "Epoch 00027: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0386 - acc: 0.9855 - val_loss: 0.2145 - val_acc: 0.9472\n",
      "Epoch 28/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0338 - acc: 0.9884\n",
      "Epoch 00028: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0336 - acc: 0.9886 - val_loss: 0.2290 - val_acc: 0.9436\n",
      "Epoch 29/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0334 - acc: 0.9879\n",
      "Epoch 00029: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0327 - acc: 0.9884 - val_loss: 0.2188 - val_acc: 0.9490\n",
      "Epoch 30/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0314 - acc: 0.9892\n",
      "Epoch 00030: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0322 - acc: 0.9889 - val_loss: 0.2356 - val_acc: 0.9390\n",
      "Epoch 31/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9833\n",
      "Epoch 00031: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0455 - acc: 0.9833 - val_loss: 0.2241 - val_acc: 0.9454\n",
      "Epoch 32/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9832\n",
      "Epoch 00032: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0486 - acc: 0.9832 - val_loss: 0.2275 - val_acc: 0.9463\n",
      "Epoch 33/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9865\n",
      "Epoch 00033: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0380 - acc: 0.9867 - val_loss: 0.2356 - val_acc: 0.9354\n",
      "Epoch 34/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9838\n",
      "Epoch 00034: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0420 - acc: 0.9837 - val_loss: 0.2603 - val_acc: 0.9399\n",
      "Epoch 35/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9863\n",
      "Epoch 00035: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0376 - acc: 0.9865 - val_loss: 0.2282 - val_acc: 0.9381\n",
      "Epoch 36/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9895\n",
      "Epoch 00036: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0306 - acc: 0.9894 - val_loss: 0.2390 - val_acc: 0.9463\n",
      "Epoch 37/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0409 - acc: 0.9858\n",
      "Epoch 00037: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0406 - acc: 0.9857 - val_loss: 0.2443 - val_acc: 0.9372\n",
      "Epoch 38/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9771\n",
      "Epoch 00038: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 92us/sample - loss: 0.0609 - acc: 0.9771 - val_loss: 0.2501 - val_acc: 0.9308\n",
      "Epoch 39/2000\n",
      "7600/7915 [===========================>..] - ETA: 0s - loss: 0.0406 - acc: 0.9855\n",
      "Epoch 00039: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 85us/sample - loss: 0.0404 - acc: 0.9853 - val_loss: 0.2274 - val_acc: 0.9436\n",
      "Epoch 40/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0291 - acc: 0.9900\n",
      "Epoch 00040: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0285 - acc: 0.9901 - val_loss: 0.2319 - val_acc: 0.9445\n",
      "Epoch 41/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9929\n",
      "Epoch 00041: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0234 - acc: 0.9929 - val_loss: 0.2297 - val_acc: 0.9427\n",
      "Epoch 42/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9915\n",
      "Epoch 00042: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0259 - acc: 0.9914 - val_loss: 0.2281 - val_acc: 0.9454\n",
      "Epoch 43/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0185 - acc: 0.9939\n",
      "Epoch 00043: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0198 - acc: 0.9933 - val_loss: 0.2290 - val_acc: 0.9454\n",
      "Epoch 44/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0304 - acc: 0.9897\n",
      "Epoch 00044: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 86us/sample - loss: 0.0298 - acc: 0.9899 - val_loss: 0.2618 - val_acc: 0.9336\n",
      "Epoch 45/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0702 - acc: 0.9751\n",
      "Epoch 00045: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0706 - acc: 0.9757 - val_loss: 0.2653 - val_acc: 0.9381\n",
      "Epoch 46/2000\n",
      "7800/7915 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9827\n",
      "Epoch 00046: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 90us/sample - loss: 0.0489 - acc: 0.9828 - val_loss: 0.2254 - val_acc: 0.9454\n",
      "Epoch 47/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9889\n",
      "Epoch 00047: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0328 - acc: 0.9889 - val_loss: 0.2376 - val_acc: 0.9418\n",
      "Epoch 48/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0241 - acc: 0.9921\n",
      "Epoch 00048: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0248 - acc: 0.9917 - val_loss: 0.2594 - val_acc: 0.9363\n",
      "Epoch 49/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0220 - acc: 0.9930\n",
      "Epoch 00049: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0228 - acc: 0.9928 - val_loss: 0.2359 - val_acc: 0.9481\n",
      "Epoch 50/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9938\n",
      "Epoch 00050: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0201 - acc: 0.9937 - val_loss: 0.2331 - val_acc: 0.9427\n",
      "Epoch 51/2000\n",
      "7300/7915 [==========================>...] - ETA: 0s - loss: 0.0449 - acc: 0.9847\n",
      "Epoch 00051: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0434 - acc: 0.9851 - val_loss: 0.2382 - val_acc: 0.9436\n",
      "Epoch 52/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9891\n",
      "Epoch 00052: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 89us/sample - loss: 0.0302 - acc: 0.9891 - val_loss: 0.2540 - val_acc: 0.9427\n",
      "Epoch 53/2000\n",
      "7400/7915 [===========================>..] - ETA: 0s - loss: 0.0282 - acc: 0.9891\n",
      "Epoch 00053: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 87us/sample - loss: 0.0288 - acc: 0.9886 - val_loss: 0.2373 - val_acc: 0.9445\n",
      "Epoch 54/2000\n",
      "7700/7915 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9927\n",
      "Epoch 00054: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 85us/sample - loss: 0.0218 - acc: 0.9928 - val_loss: 0.2555 - val_acc: 0.9445\n",
      "Epoch 55/2000\n",
      "7500/7915 [===========================>..] - ETA: 0s - loss: 0.0293 - acc: 0.9903\n",
      "Epoch 00055: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 88us/sample - loss: 0.0297 - acc: 0.9899 - val_loss: 0.2616 - val_acc: 0.9390\n",
      "Epoch 56/2000\n",
      "7900/7915 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9895\n",
      "Epoch 00056: val_loss did not improve from 0.19803\n",
      "7915/7915 [==============================] - 1s 91us/sample - loss: 0.0296 - acc: 0.9895 - val_loss: 0.2296 - val_acc: 0.9436\n",
      "Training time: 39.67315363883972 s\n",
      "1978/1978 [==============================] - 0s 105us/sample - loss: 0.0700 - acc: 0.9727\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.abspath(os.path.join('models', dataset))):\n",
    "    os.mkdir(os.path.abspath(os.path.join('models', dataset)))\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "sdk = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    \n",
    "n_fold = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "epoch_per_fold = []\n",
    "loss_per_fold = []\n",
    "rec_per_fold = []\n",
    "prec_per_fold = []\n",
    "f1_per_fold = []\n",
    "\n",
    "for train, test in sdk.split(x_all, y_all):\n",
    "    \n",
    "    file_path = os.path.abspath(os.path.join('models', dataset, f'{dataset}-Laguerre_{n_fold}.hdf5'))\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=file_path, monitor='val_loss', save_best_only = True, mode = 'min', verbose = 1), \n",
    "        EarlyStopping(monitor = 'val_loss', patience = 50, mode = 'min')]\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    print(f\"Fold: {n_fold}\\n\")\n",
    "    result = model.fit(x_all[train], \n",
    "                       to_categorical(y_all[train]),\n",
    "                       epochs = 2000, \n",
    "                       batch_size = 100, \n",
    "                       validation_data = (x_valid, to_categorical(y_valid)), \n",
    "                       callbacks = callbacks)\n",
    "\n",
    "    print(f\"Training time: {time.time() - t} s\")\n",
    "\n",
    "    df_results = pd.DataFrame(result.history)\n",
    "    df_results.to_csv(os.path.abspath(os.path.join('models', dataset, f'Laguerre_results_{n_fold}.csv')))\n",
    "    \n",
    "    model.load_weights(file_path)\n",
    "    scores = model.evaluate(x_all[test], to_categorical(y_all[test]))\n",
    "    loss_per_fold.append(scores[0])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    epoch_per_fold.append(np.argmin(result.history['val_loss']))\n",
    "    \n",
    "    # Computing predictions\n",
    "    y_pred_test = np.argmax(model.predict(x_all[test]), axis = 1)\n",
    "    \n",
    "    f1_per_fold.append(f1_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    rec_per_fold.append(recall_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    prec_per_fold.append(precision_score(y_all[test], y_pred_test, average = 'macro'))\n",
    "    \n",
    "    n_fold += 1\n",
    "    \n",
    "df_scores = pd.DataFrame(columns = ['F1', 'Loss', 'Accuracy', 'Precision', 'Recall'])\n",
    "df_scores['F1'] = f1_per_fold\n",
    "df_scores['Loss'] = loss_per_fold\n",
    "df_scores['Accuracy'] = acc_per_fold\n",
    "df_scores['Precision'] = prec_per_fold\n",
    "df_scores['Recall'] = rec_per_fold\n",
    "\n",
    "df_scores.to_csv(os.path.abspath(os.path.join('models', dataset, f'Laguerre_results_k-Folds.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
